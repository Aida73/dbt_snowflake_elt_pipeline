[2025-04-14T18:23:07.670+0200] {processor.py:186} INFO - Started process (PID=31242) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:23:07.671+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:23:07.673+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:07.672+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:23:07.924+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:23:08.026+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.025+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_producer
[2025-04-14T18:23:08.035+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.034+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_producer
[2025-04-14T18:23:08.041+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.041+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_producer
[2025-04-14T18:23:08.049+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.049+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_producer
[2025-04-14T18:23:08.055+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.055+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_producer
[2025-04-14T18:23:08.062+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.062+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_producer
[2025-04-14T18:23:08.070+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.069+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_producer
[2025-04-14T18:23:08.082+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.082+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_consumer
[2025-04-14T18:23:08.089+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.088+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_consumer
[2025-04-14T18:23:08.095+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.094+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_consumer
[2025-04-14T18:23:08.105+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.104+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_consumer
[2025-04-14T18:23:08.111+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.111+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_consumer
[2025-04-14T18:23:08.117+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.117+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_consumer
[2025-04-14T18:23:08.124+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.123+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_consumer
[2025-04-14T18:23:08.136+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.136+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_producer
[2025-04-14T18:23:08.143+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.142+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_producer
[2025-04-14T18:23:08.149+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.149+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_producer
[2025-04-14T18:23:08.158+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.158+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_producer
[2025-04-14T18:23:08.166+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.165+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_producer
[2025-04-14T18:23:08.173+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.173+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_producer
[2025-04-14T18:23:08.181+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.181+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_producer
[2025-04-14T18:23:08.198+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.198+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_consumer
[2025-04-14T18:23:08.207+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.206+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_consumer
[2025-04-14T18:23:08.214+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.214+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_consumer
[2025-04-14T18:23:08.227+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.227+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_consumer
[2025-04-14T18:23:08.238+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.237+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_consumer
[2025-04-14T18:23:08.245+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.245+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_consumer
[2025-04-14T18:23:08.256+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.256+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_consumer
[2025-04-14T18:23:08.257+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.257+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:23:08.274+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.273+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2025-04-14T18:23:08.275+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.275+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2025-04-14T18:23:08.276+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.276+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2025-04-14T18:23:08.277+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.277+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2025-04-14T18:23:08.288+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.287+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:23:08.288+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.288+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:23:08.289+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.289+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:23:08.290+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:08.289+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:23:09.060+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 1.395 seconds
[2025-04-14T18:23:48.679+0200] {processor.py:186} INFO - Started process (PID=32353) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:23:48.681+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:23:48.683+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:48.683+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:23:49.096+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:23:49.137+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:49.136+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:23:49.171+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:49.171+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:23:49.179+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:49.179+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:23:49.181+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:49.181+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:23:49.183+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:49.183+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:23:49.213+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.541 seconds
[2025-04-14T18:24:51.156+0200] {processor.py:186} INFO - Started process (PID=33939) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:24:51.158+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:24:51.160+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:51.160+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:24:51.504+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:24:51.554+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:51.553+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:24:51.582+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:51.581+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:24:51.585+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:51.585+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:24:51.587+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:51.587+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:24:51.589+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:51.588+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:24:51.616+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.466 seconds
[2025-04-14T18:27:10.264+0200] {processor.py:186} INFO - Started process (PID=37402) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:27:10.266+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:27:10.268+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.267+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:27:10.422+0200] {processor.py:186} INFO - Started process (PID=37404) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:27:10.423+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:27:10.425+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.424+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:27:10.633+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:27:10.665+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.665+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:27:10.693+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.693+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:27:10.696+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.696+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:27:10.699+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.699+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:27:10.701+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.700+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:27:10.728+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.470 seconds
[2025-04-14T18:27:10.734+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:27:10.771+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.771+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:27:10.801+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.801+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:27:10.804+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.804+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:27:10.806+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.806+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:27:10.808+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:10.807+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:27:10.838+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.422 seconds
[2025-04-14T18:27:47.315+0200] {processor.py:186} INFO - Started process (PID=39440) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:27:47.317+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:27:47.319+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:47.319+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:27:47.565+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:27:47.590+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:47.590+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:27:47.610+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:47.609+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:27:47.612+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:47.612+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:27:47.613+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:47.613+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:27:47.614+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:47.614+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:27:47.635+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.326 seconds
[2025-04-14T18:28:40.849+0200] {processor.py:186} INFO - Started process (PID=41011) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:28:40.851+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:28:40.852+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:40.852+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:28:41.075+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:28:41.107+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:41.107+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:28:41.133+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:41.133+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:28:41.136+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:41.135+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:28:41.137+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:41.137+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:28:41.138+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:41.138+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:28:41.163+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.320 seconds
[2025-04-14T18:30:55.645+0200] {processor.py:186} INFO - Started process (PID=44881) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:30:55.646+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:30:55.648+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:55.647+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:30:55.861+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:30:55.884+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:55.884+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:30:55.903+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:55.902+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:30:55.905+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:55.904+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:30:55.906+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:55.905+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:30:55.907+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:55.906+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:30:55.927+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.287 seconds
[2025-04-14T18:33:50.435+0200] {processor.py:186} INFO - Started process (PID=48823) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:33:50.437+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:33:50.439+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:50.438+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:33:50.703+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:33:50.728+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:50.728+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:33:50.753+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:50.752+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:33:50.756+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:50.755+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:33:50.757+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:50.757+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:33:50.758+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:50.758+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:33:50.780+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.352 seconds
[2025-04-14T18:34:20.935+0200] {processor.py:186} INFO - Started process (PID=49405) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:34:20.937+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:34:20.939+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:20.938+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:34:21.302+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:34:21.479+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:21.478+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:34:21.515+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:21.514+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:34:21.518+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:21.518+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:34:21.520+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:21.520+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:34:21.522+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:21.521+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:34:21.556+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.628 seconds
[2025-04-14T18:35:41.666+0200] {processor.py:186} INFO - Started process (PID=50928) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:35:41.680+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:35:41.682+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:41.681+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:35:41.981+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:35:42.056+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:42.056+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:35:42.079+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:42.079+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:35:42.082+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:42.082+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:35:42.100+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:42.100+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:35:42.119+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:42.119+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:35:42.208+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.548 seconds
[2025-04-14T18:36:42.976+0200] {processor.py:186} INFO - Started process (PID=52230) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:36:42.978+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:36:42.980+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:42.980+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:36:43.232+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:36:43.262+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:43.261+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:36:43.288+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:43.287+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:36:43.291+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:43.291+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:36:43.293+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:43.292+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:36:43.294+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:43.294+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:36:43.324+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.354 seconds
[2025-04-14T18:38:29.017+0200] {processor.py:186} INFO - Started process (PID=55049) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:38:29.019+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:38:29.021+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:29.021+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:38:29.399+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:38:29.447+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:29.447+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:38:29.492+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:29.492+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:38:29.495+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:29.495+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:38:29.528+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:29.527+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:38:29.549+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:29.549+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:38:29.594+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.583 seconds
[2025-04-14T18:42:17.986+0200] {processor.py:186} INFO - Started process (PID=61559) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:42:17.988+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:42:17.990+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:17.990+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:42:18.297+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:42:18.333+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:18.333+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:42:18.364+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:18.363+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:42:18.367+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:18.367+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:42:18.369+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:18.369+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:42:18.371+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:18.370+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:42:18.403+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.423 seconds
[2025-04-14T18:42:19.596+0200] {processor.py:186} INFO - Started process (PID=61572) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:42:19.597+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:42:19.599+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:19.599+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:42:19.950+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:42:19.986+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:19.986+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:42:20.019+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:20.019+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:42:20.024+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:20.023+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:42:20.026+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:20.025+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:42:20.028+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:20.028+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:42:20.061+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.472 seconds
[2025-04-14T18:42:41.965+0200] {processor.py:186} INFO - Started process (PID=62102) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:42:41.967+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:42:41.969+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.968+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:42:42.326+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:42:42.364+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:42.364+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:42:42.396+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:42.396+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:42:42.401+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:42.400+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:42:42.403+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:42.402+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:42:42.404+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:42.404+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:42:42.439+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.480 seconds
[2025-04-14T18:44:04.925+0200] {processor.py:186} INFO - Started process (PID=64170) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:44:04.928+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:44:04.930+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:04.929+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:44:05.303+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:44:05.341+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:05.340+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:44:05.378+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:05.378+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:44:05.383+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:05.382+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:44:05.385+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:05.385+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:44:05.387+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:05.386+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:44:05.423+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.504 seconds
[2025-04-14T18:46:56.360+0200] {processor.py:186} INFO - Started process (PID=68265) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:46:56.362+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:46:56.364+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:56.364+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:46:56.604+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:46:56.631+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:56.631+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:46:56.652+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:56.651+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:46:56.654+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:56.654+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:46:56.656+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:56.656+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:46:56.657+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:56.657+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:46:56.680+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.327 seconds
[2025-04-14T18:46:58.867+0200] {processor.py:186} INFO - Started process (PID=68285) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:46:58.869+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:46:58.871+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:58.871+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:46:59.246+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:46:59.285+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:59.284+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:46:59.318+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:59.318+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:46:59.321+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:59.321+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:46:59.333+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:59.333+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:46:59.335+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:59.334+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:46:59.396+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.535 seconds
[2025-04-14T18:50:29.266+0200] {processor.py:186} INFO - Started process (PID=73162) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:50:29.268+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:50:29.269+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:29.269+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:50:29.494+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:50:29.645+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:29.644+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:50:29.662+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:29.662+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:50:29.664+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:29.664+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:50:29.665+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:29.665+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:50:29.666+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:29.666+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:50:29.690+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.431 seconds
[2025-04-14T18:50:42.616+0200] {processor.py:186} INFO - Started process (PID=73444) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:50:42.618+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:50:42.620+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:42.620+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:50:42.917+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:50:42.924+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:42.923+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:50:42.948+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:42.947+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:50:42.950+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:42.950+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:50:42.951+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:42.951+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:50:42.952+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:42.952+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:50:42.977+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.366 seconds
[2025-04-14T18:51:48.138+0200] {processor.py:186} INFO - Started process (PID=74858) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:51:48.140+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:51:48.142+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:48.141+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:51:48.406+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:51:48.438+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:48.438+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:51:48.470+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:48.470+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:51:48.472+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:48.472+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:51:48.474+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:48.474+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:51:48.476+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:48.475+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:51:48.512+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.381 seconds
[2025-04-14T18:53:48.400+0200] {processor.py:186} INFO - Started process (PID=77787) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:53:48.402+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:53:48.404+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:48.403+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:53:48.699+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:53:48.921+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:48.921+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:53:48.941+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:48.941+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:53:48.944+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:48.944+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:53:48.946+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:48.946+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:53:48.947+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:48.947+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:53:48.970+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.576 seconds
[2025-04-14T18:57:28.953+0200] {processor.py:186} INFO - Started process (PID=82204) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:57:28.955+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:57:28.957+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:28.957+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:57:29.321+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:57:29.361+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:29.360+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:57:29.393+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:29.393+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:57:29.396+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:29.396+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:57:29.398+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:29.398+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:57:29.400+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:29.400+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:57:29.433+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.487 seconds
[2025-04-14T18:57:31.312+0200] {processor.py:186} INFO - Started process (PID=82319) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:57:31.313+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:57:31.316+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:31.315+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:57:31.711+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:57:31.756+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:31.755+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:57:31.786+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:31.786+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:57:31.790+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:31.789+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:57:31.792+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:31.791+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:57:31.793+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:31.793+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:57:31.828+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.523 seconds
[2025-04-14T18:59:15.885+0200] {processor.py:186} INFO - Started process (PID=84629) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:59:15.887+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T18:59:15.889+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:15.888+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:59:16.233+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T18:59:16.466+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:16.466+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:59:16.489+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:16.489+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T18:59:16.493+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:16.493+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T18:59:16.495+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:16.494+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T18:59:16.496+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:16.496+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T18:59:16.532+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.654 seconds
[2025-04-14T19:01:48.483+0200] {processor.py:186} INFO - Started process (PID=87630) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:01:48.485+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:01:48.487+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:48.487+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:01:48.755+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:01:48.782+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:48.782+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:01:48.806+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:48.805+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:01:48.809+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:48.808+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:01:48.810+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:48.810+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:01:48.811+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:48.811+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:01:48.838+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.361 seconds
[2025-04-14T19:05:03.438+0200] {processor.py:186} INFO - Started process (PID=91962) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:05:03.455+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:05:03.456+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:03.456+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:05:03.811+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:05:03.985+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:03.984+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:05:03.986+0200] {processor.py:186} INFO - Started process (PID=92064) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:05:03.987+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:05:03.988+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:03.988+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:05:04.003+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:04.003+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:05:04.005+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:04.005+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:05:04.006+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:04.006+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:05:04.008+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:04.007+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:05:04.036+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.606 seconds
[2025-04-14T19:05:04.222+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:05:04.227+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:04.227+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:05:04.246+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:04.245+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:05:04.248+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:04.248+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:05:04.249+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:04.249+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:05:04.250+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:04.250+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:05:04.280+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.301 seconds
[2025-04-14T19:06:52.089+0200] {processor.py:186} INFO - Started process (PID=95106) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:06:52.091+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:06:52.092+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.092+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:06:52.334+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:06:52.458+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.458+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_consumer
[2025-04-14T19:06:52.472+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.472+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_consumer
[2025-04-14T19:06:52.482+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.482+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_consumer
[2025-04-14T19:06:52.497+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.496+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_consumer
[2025-04-14T19:06:52.506+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.505+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_consumer
[2025-04-14T19:06:52.516+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.515+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_consumer
[2025-04-14T19:06:52.527+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.527+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_consumer
[2025-04-14T19:06:52.548+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.547+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_producer
[2025-04-14T19:06:52.557+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.556+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_producer
[2025-04-14T19:06:52.567+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.566+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_producer
[2025-04-14T19:06:52.582+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.582+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_producer
[2025-04-14T19:06:52.593+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.592+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_producer
[2025-04-14T19:06:52.601+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.601+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_producer
[2025-04-14T19:06:52.611+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.611+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_producer
[2025-04-14T19:06:52.633+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.633+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_producer
[2025-04-14T19:06:52.642+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.642+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_producer
[2025-04-14T19:06:52.650+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.650+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_producer
[2025-04-14T19:06:52.661+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.661+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_producer
[2025-04-14T19:06:52.669+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.668+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_producer
[2025-04-14T19:06:52.678+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.677+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_producer
[2025-04-14T19:06:52.689+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.688+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_producer
[2025-04-14T19:06:52.714+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.714+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_consumer
[2025-04-14T19:06:52.726+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.725+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_consumer
[2025-04-14T19:06:52.737+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.737+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_consumer
[2025-04-14T19:06:52.750+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.750+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_consumer
[2025-04-14T19:06:52.761+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.761+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_consumer
[2025-04-14T19:06:52.773+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.772+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_consumer
[2025-04-14T19:06:52.784+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.784+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_consumer
[2025-04-14T19:06:52.785+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.785+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:06:52.806+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.806+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer
[2025-04-14T19:06:52.807+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.807+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_producer
[2025-04-14T19:06:52.808+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.807+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_producer
[2025-04-14T19:06:52.808+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.808+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_consumer
[2025-04-14T19:06:52.819+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.819+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:06:52.820+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.820+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:06:52.821+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.821+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:06:52.823+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:52.822+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:06:52.871+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.789 seconds
[2025-04-14T19:08:55.692+0200] {processor.py:186} INFO - Started process (PID=99110) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:08:55.694+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:08:55.696+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:55.696+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:08:56.048+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:08:56.086+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:56.085+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:08:56.117+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:56.116+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:08:56.120+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:56.120+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:08:56.122+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:56.122+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:08:56.124+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:56.124+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:08:56.159+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.472 seconds
[2025-04-14T19:13:03.542+0200] {processor.py:186} INFO - Started process (PID=5013) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:13:03.544+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:13:03.547+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:03.546+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:13:03.831+0200] {processor.py:186} INFO - Started process (PID=5014) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:13:03.833+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:13:03.835+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:03.834+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:13:03.908+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:13:04.149+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.149+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:13:04.170+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:13:04.175+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.175+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:13:04.178+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.178+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:13:04.180+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.180+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:13:04.181+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.181+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:13:04.213+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.681 seconds
[2025-04-14T19:13:04.329+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.328+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:13:04.356+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.356+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:13:04.359+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.359+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:13:04.361+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.360+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:13:04.362+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.362+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:13:04.741+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.736+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_producer", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_air ... (1533 characters truncated) ... [{"source": "dataset_s3_bucket_producer", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2025-04-14 17:13:04.175711', '0563f3809e93b9608ae61c0186f77656', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:13:04.744+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.743+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_producer", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_air ... (1533 characters truncated) ... [{"source": "dataset_s3_bucket_producer", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2025-04-14 17:13:04.175711', '0563f3809e93b9608ae61c0186f77656', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:13:04.746+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.745+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_producer", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_air ... (1533 characters truncated) ... [{"source": "dataset_s3_bucket_producer", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2025-04-14 17:13:04.175711', '0563f3809e93b9608ae61c0186f77656', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:13:04.748+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.747+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_producer", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_air ... (1533 characters truncated) ... [{"source": "dataset_s3_bucket_producer", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2025-04-14 17:13:04.175711', '0563f3809e93b9608ae61c0186f77656', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:13:04.749+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:04.749+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:13:04.750+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_dag_id": "dataset_s3_bucket_producer", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_air ... (1533 characters truncated) ... [{"source": "dataset_s3_bucket_producer", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task"}], "params": []}}', None, '2025-04-14 17:13:04.175711', '0563f3809e93b9608ae61c0186f77656', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:15:02.555+0200] {processor.py:186} INFO - Started process (PID=7743) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:15:02.556+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:15:02.558+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:15:02.557+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:15:02.853+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:15:03.061+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:15:03.060+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:15:03.082+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:15:03.081+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:15:03.085+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:15:03.085+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:15:03.086+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:15:03.086+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:15:03.088+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:15:03.088+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:15:03.114+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.565 seconds
[2025-04-14T19:16:44.633+0200] {processor.py:186} INFO - Started process (PID=10039) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:16:44.636+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:16:44.638+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:44.637+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:16:44.986+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:16:45.022+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:45.022+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:16:45.057+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:45.057+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:16:45.061+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:45.061+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:16:45.063+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:45.062+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:16:45.064+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:45.064+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:16:45.102+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.475 seconds
[2025-04-14T19:21:45.518+0200] {processor.py:186} INFO - Started process (PID=16899) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:21:45.520+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:21:45.521+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:45.521+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:21:45.777+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:21:45.973+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:45.972+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:21:45.993+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:45.993+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:21:45.996+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:45.996+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:21:45.997+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:45.997+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:21:45.998+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:45.998+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:21:46.026+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.513 seconds
[2025-04-14T19:23:13.163+0200] {processor.py:186} INFO - Started process (PID=18667) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:23:13.165+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:23:13.167+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:13.166+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:23:13.460+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:23:13.506+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:13.505+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:23:13.552+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:13.551+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:23:13.556+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:13.555+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:23:13.558+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:13.558+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:23:13.560+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:13.560+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:23:13.598+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.441 seconds
[2025-04-14T19:28:20.248+0200] {processor.py:186} INFO - Started process (PID=25514) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:28:20.250+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:28:20.252+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:20.252+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:28:20.607+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:28:20.785+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:20.784+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:28:20.806+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:20.805+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:28:20.808+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:20.808+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:28:20.809+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:20.809+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:28:20.810+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:20.810+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:28:20.835+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.594 seconds
[2025-04-14T19:29:58.343+0200] {processor.py:186} INFO - Started process (PID=27595) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:29:58.345+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:29:58.347+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:58.347+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:29:58.671+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:29:58.874+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:58.873+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:29:58.895+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:58.894+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:29:58.897+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:58.897+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:29:58.898+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:58.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:29:58.899+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:58.899+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:29:58.925+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.588 seconds
[2025-04-14T19:34:51.638+0200] {processor.py:186} INFO - Started process (PID=34260) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:34:51.640+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:34:51.642+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:51.641+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:34:52.011+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:34:52.248+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:52.248+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:34:52.276+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:52.276+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:34:52.280+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:52.280+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:34:52.281+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:52.281+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:34:52.283+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:52.282+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:34:52.319+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.689 seconds
[2025-04-14T19:36:10.832+0200] {processor.py:186} INFO - Started process (PID=35880) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:36:10.835+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:36:10.836+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:10.836+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:36:11.113+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:36:11.141+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:11.141+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:36:11.162+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:11.162+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:36:11.165+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:11.165+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:36:11.166+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:11.166+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:36:11.168+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:11.167+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:36:11.190+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.365 seconds
[2025-04-14T19:41:48.037+0200] {processor.py:186} INFO - Started process (PID=43103) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:41:48.039+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:41:48.041+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:48.040+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:41:48.351+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:41:48.556+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:48.555+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:41:48.577+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:48.576+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:41:48.580+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:48.579+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:41:48.581+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:48.581+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:41:48.583+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:48.583+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:41:48.612+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.581 seconds
[2025-04-14T19:42:46.694+0200] {processor.py:186} INFO - Started process (PID=44484) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:42:46.696+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:42:46.697+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:46.697+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:42:46.950+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:42:46.979+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:46.978+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:42:46.999+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:46.999+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:42:47.002+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:47.002+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:42:47.003+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:47.003+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:42:47.004+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:47.004+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:42:47.027+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.340 seconds
[2025-04-14T19:47:53.930+0200] {processor.py:186} INFO - Started process (PID=51607) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:47:53.933+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:47:53.935+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:53.934+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:47:54.220+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:47:54.399+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:54.398+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:47:54.417+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:54.417+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:47:54.419+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:54.419+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:47:54.420+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:54.420+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:47:54.421+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:54.421+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:47:54.446+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.522 seconds
[2025-04-14T19:48:49.298+0200] {processor.py:186} INFO - Started process (PID=52877) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:48:49.300+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:48:49.302+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:49.301+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:48:49.627+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:48:49.666+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:49.666+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:48:49.697+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:49.697+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:48:49.701+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:49.701+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:48:49.703+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:49.703+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:48:49.705+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:49.704+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:48:49.732+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.440 seconds
[2025-04-14T19:53:59.221+0200] {processor.py:186} INFO - Started process (PID=60051) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:53:59.223+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:53:59.224+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:59.224+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:53:59.464+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:53:59.645+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:59.645+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:53:59.664+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:59.663+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:53:59.666+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:59.666+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:53:59.667+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:59.667+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:53:59.668+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:59.668+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:53:59.692+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.478 seconds
[2025-04-14T19:54:58.822+0200] {processor.py:186} INFO - Started process (PID=61438) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:54:58.824+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T19:54:58.826+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:58.825+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:54:59.046+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T19:54:59.194+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:59.194+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:54:59.211+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:59.211+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T19:54:59.213+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:59.213+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T19:54:59.214+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:59.214+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T19:54:59.215+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:59.215+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T19:54:59.239+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.423 seconds
[2025-04-14T20:00:11.588+0200] {processor.py:186} INFO - Started process (PID=68607) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:00:11.591+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:00:11.592+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:11.592+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:00:11.850+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:00:12.011+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:12.011+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:00:12.030+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:12.030+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:00:12.033+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:12.032+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:00:12.034+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:12.034+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:00:12.035+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:12.035+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:00:12.059+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.477 seconds
[2025-04-14T20:01:06.241+0200] {processor.py:186} INFO - Started process (PID=69787) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:01:06.243+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:01:06.245+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:06.244+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:01:06.548+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:01:06.581+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:06.580+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:01:06.605+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:06.604+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:01:06.608+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:06.608+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:01:06.610+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:06.610+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:01:06.611+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:06.611+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:01:06.636+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.403 seconds
[2025-04-14T20:06:55.098+0200] {processor.py:186} INFO - Started process (PID=77429) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:06:55.100+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:06:55.102+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:55.102+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:06:55.373+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:06:55.539+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:55.538+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:06:55.557+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:55.557+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:06:55.559+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:55.559+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:06:55.560+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:55.560+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:06:55.561+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:55.561+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:06:55.586+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.495 seconds
[2025-04-14T20:07:26.279+0200] {processor.py:186} INFO - Started process (PID=78184) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:07:26.283+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:07:26.285+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:26.285+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:07:26.814+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:07:26.857+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:26.856+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:07:26.892+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:26.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:07:26.896+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:26.895+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:07:26.897+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:26.897+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:07:26.899+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:26.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:07:26.931+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.659 seconds
[2025-04-14T20:12:59.433+0200] {processor.py:186} INFO - Started process (PID=85580) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:12:59.434+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:12:59.436+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:59.435+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:12:59.637+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:12:59.806+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:59.806+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:12:59.828+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:59.828+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:12:59.831+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:59.830+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:12:59.832+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:59.832+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:12:59.833+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:59.833+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:12:59.861+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.434 seconds
[2025-04-14T20:13:21.518+0200] {processor.py:186} INFO - Started process (PID=86099) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:13:21.520+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:13:21.522+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:21.521+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:13:21.776+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:13:21.781+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:21.781+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:13:21.800+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:21.800+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:13:21.802+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:21.802+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:13:21.803+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:21.803+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:13:21.804+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:21.804+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:13:21.829+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.318 seconds
[2025-04-14T20:18:52.126+0200] {processor.py:186} INFO - Started process (PID=93430) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:18:52.128+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:18:52.129+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:52.129+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:18:52.412+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:18:52.563+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:52.563+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:18:52.583+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:52.583+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:18:52.586+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:52.586+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:18:52.587+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:52.587+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:18:52.589+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:52.588+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:18:52.614+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.493 seconds
[2025-04-14T20:19:14.132+0200] {processor.py:186} INFO - Started process (PID=93940) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:19:14.134+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:19:14.136+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:14.136+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:19:14.450+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:19:14.460+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:14.459+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:19:14.490+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:14.490+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:19:14.494+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:14.493+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:19:14.496+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:14.495+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:19:14.498+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:14.497+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:19:14.551+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.425 seconds
[2025-04-14T20:25:03.297+0200] {processor.py:186} INFO - Started process (PID=2257) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:25:03.299+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:25:03.301+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:03.300+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:25:03.553+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:25:03.768+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:03.768+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:25:03.790+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:03.790+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:25:03.793+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:03.793+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:25:03.794+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:03.794+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:25:03.795+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:03.795+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:25:03.826+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.535 seconds
[2025-04-14T20:25:10.622+0200] {processor.py:186} INFO - Started process (PID=2405) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:25:10.623+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:25:10.624+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:10.624+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:25:10.867+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:25:10.872+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:10.872+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:25:10.891+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:10.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:25:10.895+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:10.895+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:25:10.897+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:10.896+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:25:10.898+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:10.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:25:10.922+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.306 seconds
[2025-04-14T20:30:42.790+0200] {processor.py:186} INFO - Started process (PID=10167) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:30:42.792+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:30:42.793+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:42.793+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:30:42.996+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:30:43.127+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.127+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:30:43.143+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.143+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:30:43.145+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.144+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:30:43.145+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.145+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:30:43.146+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.146+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:30:43.168+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.383 seconds
[2025-04-14T20:30:43.230+0200] {processor.py:186} INFO - Started process (PID=10168) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:30:43.232+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:30:43.235+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.234+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:30:43.484+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:30:43.490+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.489+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:30:43.508+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.508+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:30:43.511+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.511+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:30:43.513+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.512+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:30:43.514+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:43.514+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:30:43.546+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.323 seconds
[2025-04-14T20:35:56.729+0200] {processor.py:186} INFO - Started process (PID=17545) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:35:56.731+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:35:56.732+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:56.732+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:35:56.921+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:35:57.044+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:57.044+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:35:57.058+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:57.058+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:35:57.060+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:57.060+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:35:57.060+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:57.060+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:35:57.061+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:57.061+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:35:57.079+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.355 seconds
[2025-04-14T20:35:58.916+0200] {processor.py:186} INFO - Started process (PID=17556) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:35:58.918+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:35:58.920+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:58.919+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:35:59.209+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:35:59.218+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:59.217+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:35:59.243+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:59.243+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:35:59.246+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:59.246+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:35:59.247+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:59.247+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:35:59.248+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:59.248+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:35:59.271+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.360 seconds
[2025-04-14T20:41:16.429+0200] {processor.py:186} INFO - Started process (PID=24932) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:41:16.431+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:41:16.432+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:16.432+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:41:16.624+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:41:16.752+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:16.751+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:41:16.767+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:16.766+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:41:16.769+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:16.768+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:41:16.770+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:16.769+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:41:16.770+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:16.770+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:41:16.791+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.368 seconds
[2025-04-14T20:41:18.794+0200] {processor.py:186} INFO - Started process (PID=24944) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:41:18.795+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:41:18.797+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:18.797+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:41:19.023+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:41:19.028+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:19.028+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:41:19.048+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:19.047+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:41:19.050+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:19.050+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:41:19.051+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:19.051+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:41:19.052+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:19.052+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:41:19.078+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.290 seconds
[2025-04-14T20:46:33.525+0200] {processor.py:186} INFO - Started process (PID=32398) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:46:33.527+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:46:33.528+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:33.528+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:46:33.783+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:46:33.932+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:33.931+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:46:33.956+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:33.956+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:46:33.959+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:33.959+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:46:33.960+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:33.960+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:46:33.962+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:33.961+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:46:33.989+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.469 seconds
[2025-04-14T20:46:34.210+0200] {processor.py:186} INFO - Started process (PID=32401) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:46:34.211+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:46:34.213+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:34.213+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:46:34.431+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:46:34.436+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:34.435+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:46:34.451+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:34.451+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:46:34.453+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:34.453+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:46:34.454+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:34.454+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:46:34.455+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:34.455+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:46:34.475+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.271 seconds
[2025-04-14T20:51:46.985+0200] {processor.py:186} INFO - Started process (PID=39598) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:51:46.987+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:51:46.988+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:46.988+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:51:47.200+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:51:47.347+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:47.347+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:51:47.364+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:47.364+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:51:47.366+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:47.366+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:51:47.367+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:47.367+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:51:47.368+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:47.368+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:51:47.388+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.408 seconds
[2025-04-14T20:51:48.836+0200] {processor.py:186} INFO - Started process (PID=39609) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:51:48.837+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:51:48.839+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:48.838+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:51:49.032+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:51:49.036+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:49.036+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:51:49.052+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:49.051+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:51:49.054+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:49.054+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:51:49.055+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:49.054+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:51:49.055+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:49.055+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:51:49.075+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.244 seconds
[2025-04-14T20:56:56.080+0200] {processor.py:186} INFO - Started process (PID=46747) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:56:56.082+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:56:56.084+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.084+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:56:56.425+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:56:56.583+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.582+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:56:56.605+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.605+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:56:56.607+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.607+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:56:56.609+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.609+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:56:56.610+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.610+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:56:56.638+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.564 seconds
[2025-04-14T20:56:59.862+0200] {processor.py:186} INFO - Started process (PID=46954) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:56:59.864+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T20:56:59.865+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:59.865+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:57:00.117+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T20:57:00.123+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:57:00.122+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:57:00.141+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:57:00.141+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T20:57:00.144+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:57:00.143+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T20:57:00.145+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:57:00.145+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T20:57:00.146+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:57:00.146+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T20:57:00.169+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.314 seconds
[2025-04-14T21:02:05.447+0200] {processor.py:186} INFO - Started process (PID=54082) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:02:05.448+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:02:05.450+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:05.450+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:02:05.676+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:02:05.805+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:05.805+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:02:05.820+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:05.820+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:02:05.822+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:05.822+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:02:05.823+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:05.823+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:02:05.824+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:05.823+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:02:05.844+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.403 seconds
[2025-04-14T21:02:06.650+0200] {processor.py:186} INFO - Started process (PID=54189) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:02:06.651+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:02:06.652+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:06.652+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:02:06.850+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:02:06.855+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:06.854+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:02:06.870+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:06.870+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:02:06.873+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:06.872+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:02:06.873+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:06.873+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:02:06.874+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:06.874+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:02:06.894+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.250 seconds
[2025-04-14T21:07:29.461+0200] {processor.py:186} INFO - Started process (PID=61844) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:07:29.462+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:07:29.463+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.463+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:07:29.665+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:07:29.762+0200] {processor.py:186} INFO - Started process (PID=61855) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:07:29.763+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:07:29.765+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.764+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:07:29.807+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.807+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:07:29.823+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.822+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:07:29.825+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.824+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:07:29.825+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.825+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:07:29.826+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.826+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:07:29.848+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.392 seconds
[2025-04-14T21:07:29.972+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:07:29.977+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.977+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:07:29.996+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.995+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:07:29.998+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.998+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:07:29.999+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:29.999+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:07:30.000+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:30.000+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:07:30.021+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.264 seconds
[2025-04-14T21:13:10.492+0200] {processor.py:186} INFO - Started process (PID=69555) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:13:10.494+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:13:10.495+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:10.495+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:13:10.789+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:13:10.942+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:10.942+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:13:10.958+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:10.958+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:13:10.960+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:10.960+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:13:10.961+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:10.961+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:13:10.962+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:10.962+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:13:10.983+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.497 seconds
[2025-04-14T21:13:11.911+0200] {processor.py:186} INFO - Started process (PID=69658) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:13:11.912+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:13:11.913+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:11.913+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:13:12.138+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:13:12.143+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:12.142+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:13:12.159+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:12.159+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:13:12.161+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:12.161+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:13:12.163+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:12.162+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:13:12.164+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:12.163+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:13:12.191+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.286 seconds
[2025-04-14T21:18:12.346+0200] {processor.py:186} INFO - Started process (PID=76920) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:18:12.348+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:18:12.349+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.349+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:18:12.487+0200] {processor.py:186} INFO - Started process (PID=76921) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:18:12.489+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:18:12.490+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.490+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:18:12.580+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:18:12.709+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:18:12.728+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.727+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:18:12.743+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.743+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:18:12.745+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.745+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:18:12.746+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.746+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:18:12.747+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.747+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:18:12.769+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.428 seconds
[2025-04-14T21:18:12.813+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.812+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:18:12.828+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.828+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:18:12.831+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.830+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:18:12.832+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.831+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:18:12.833+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:12.833+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:18:13.094+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:13.088+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1617 characters truncated) ... aset_alias_example_alias_producer", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias"}], "params": []}}', None, '2025-04-14 19:18:12.713191', 'e0c9ba97a377ca49fc80c88b9b356a76', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:18:13.096+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:13.095+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1617 characters truncated) ... aset_alias_example_alias_producer", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias"}], "params": []}}', None, '2025-04-14 19:18:12.713191', 'e0c9ba97a377ca49fc80c88b9b356a76', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:18:13.097+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:13.097+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1617 characters truncated) ... aset_alias_example_alias_producer", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias"}], "params": []}}', None, '2025-04-14 19:18:12.713191', 'e0c9ba97a377ca49fc80c88b9b356a76', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:18:13.099+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:13.098+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1617 characters truncated) ... aset_alias_example_alias_producer", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias"}], "params": []}}', None, '2025-04-14 19:18:12.713191', 'e0c9ba97a377ca49fc80c88b9b356a76', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:18:13.100+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:13.099+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:18:13.101+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1617 characters truncated) ... aset_alias_example_alias_producer", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias"}], "params": []}}', None, '2025-04-14 19:18:12.713191', 'e0c9ba97a377ca49fc80c88b9b356a76', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:23:18.014+0200] {processor.py:186} INFO - Started process (PID=84385) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:23:18.016+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:23:18.018+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:18.017+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:23:18.298+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:23:18.520+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:18.520+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:23:18.547+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:18.547+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:23:18.551+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:18.550+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:23:18.552+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:18.552+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:23:18.554+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:18.554+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:23:18.588+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.581 seconds
[2025-04-14T21:23:18.913+0200] {processor.py:186} INFO - Started process (PID=84386) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:23:18.915+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:23:18.916+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:18.916+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:23:19.187+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:23:19.198+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:19.198+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:23:19.241+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:19.240+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:23:19.256+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:19.256+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:23:19.258+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:19.257+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:23:19.259+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:19.259+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:23:19.292+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.385 seconds
[2025-04-14T21:28:38.070+0200] {processor.py:186} INFO - Started process (PID=91879) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:28:38.073+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:28:38.074+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.074+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:28:38.293+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:28:38.437+0200] {processor.py:186} INFO - Started process (PID=91880) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:28:38.439+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:28:38.440+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.440+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:28:38.488+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.488+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:28:38.505+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.505+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:28:38.507+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.507+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:28:38.508+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.508+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:28:38.509+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.509+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:28:38.530+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.465 seconds
[2025-04-14T21:28:38.658+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:28:38.663+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.662+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:28:38.680+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.680+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:28:38.683+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.683+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:28:38.684+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.684+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:28:38.685+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:38.685+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:28:38.709+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.277 seconds
[2025-04-14T21:33:45.881+0200] {processor.py:186} INFO - Started process (PID=99174) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:33:45.883+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:33:45.884+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:45.884+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:33:46.111+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:33:46.257+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.257+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:33:46.274+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.274+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:33:46.276+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.276+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:33:46.277+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.277+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:33:46.278+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.278+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:33:46.301+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.427 seconds
[2025-04-14T21:33:46.416+0200] {processor.py:186} INFO - Started process (PID=99177) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:33:46.418+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:33:46.419+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.419+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:33:46.640+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:33:46.645+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.644+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:33:46.662+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.661+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:33:46.664+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.664+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:33:46.665+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.665+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:33:46.666+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:46.665+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:33:46.686+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.277 seconds
[2025-04-14T21:38:59.216+0200] {processor.py:186} INFO - Started process (PID=6918) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:38:59.218+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:38:59.220+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:59.220+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:38:59.458+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:38:59.611+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:59.610+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:38:59.632+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:59.632+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:38:59.634+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:59.634+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:38:59.635+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:59.635+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:38:59.636+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:59.636+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:38:59.659+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.449 seconds
[2025-04-14T21:39:01.354+0200] {processor.py:186} INFO - Started process (PID=6929) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:39:01.356+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:39:01.358+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:01.357+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:39:01.674+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:39:01.681+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:01.680+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:39:01.707+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:01.706+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:39:01.710+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:01.710+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:39:01.712+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:01.711+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:39:01.713+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:01.713+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:39:01.743+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.395 seconds
[2025-04-14T21:44:01.637+0200] {processor.py:186} INFO - Started process (PID=14276) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:44:01.638+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:44:01.639+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:01.639+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:44:01.834+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:44:01.971+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:01.970+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:44:01.986+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:01.985+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:44:01.987+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:01.987+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:44:01.988+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:01.988+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:44:01.989+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:01.989+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:44:02.010+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.379 seconds
[2025-04-14T21:44:03.238+0200] {processor.py:186} INFO - Started process (PID=14483) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:44:03.239+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:44:03.240+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:03.240+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:44:03.471+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_producer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:44:03.475+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:03.475+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:44:03.492+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:03.491+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:44:03.494+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:03.494+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:44:03.495+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:03.495+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:44:03.496+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:03.495+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:44:03.517+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.284 seconds
[2025-04-14T21:49:23.741+0200] {processor.py:186} INFO - Started process (PID=21882) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:49:23.743+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:49:23.744+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:23.744+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:49:23.825+0200] {processor.py:186} INFO - Started process (PID=21883) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:49:23.827+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:49:23.829+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:23.828+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:49:24.080+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_alias_example_alias_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:49:24.123+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:49:24.223+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.223+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:49:24.239+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.239+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:49:24.241+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.241+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:49:24.242+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.242+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:49:24.243+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.243+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:49:24.243+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.223+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.IntegrityError: UNIQUE constraint failed: serialized_dag.dag_id

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1660, in serialize_dag
    dag_deps = [
               ^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1663, in <listcomp>
    for dep in SerializedBaseOperator.detect_dependencies(task)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1465, in detect_dependencies
    deps = set(dependency_detector.detect_task_dependencies(op))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1059, in detect_task_dependencies
    cond = _DatasetAliasCondition(obj.name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/datasets/__init__.py", line 393, in __init__
    self.objects = expand_alias_to_datasets(name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 96, in wrapper
    with create_session() as session:
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 57, in create_session
    session.commit()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_consumer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow- ... (1771 characters truncated) ... aset-alias", "target": "dataset_alias_example_alias_consumer", "dependency_type": "dataset-alias", "dependency_id": "example-alias"}], "params": []}}', None, '2025-04-14 19:49:24.126549', '30be0837000783dd84d9bd8147e72044', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'dataset_alias_example_alias_producer': (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_consumer', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py', 325248783860325, '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow- ... (1771 characters truncated) ... aset-alias", "target": "dataset_alias_example_alias_consumer", "dependency_type": "dataset-alias", "dependency_id": "example-alias"}], "params": []}}', None, '2025-04-14 19:49:24.126549', '30be0837000783dd84d9bd8147e72044', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2025-04-14T21:49:24.248+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.247+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:49:24.264+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.529 seconds
[2025-04-14T21:49:24.264+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.264+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:49:24.266+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.266+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:49:24.267+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.267+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:49:24.268+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:24.268+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:49:24.905+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 1.086 seconds
[2025-04-14T21:54:37.057+0200] {processor.py:186} INFO - Started process (PID=29531) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:54:37.059+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:54:37.060+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.060+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:54:37.312+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer', 'dataset_s3_bucket_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:54:37.450+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.450+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:54:37.467+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.467+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:54:37.469+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.469+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:54:37.470+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.470+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:54:37.471+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.471+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:54:37.494+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.443 seconds
[2025-04-14T21:54:37.584+0200] {processor.py:186} INFO - Started process (PID=29534) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:54:37.585+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py for tasks to queue
[2025-04-14T21:54:37.587+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.587+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:54:37.793+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer', 'dataset_alias_example_alias_producer', 'dataset_s3_bucket_producer', 'dataset_alias_example_alias_consumer' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py
[2025-04-14T21:54:37.797+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.797+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:54:37.814+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.814+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer to None, run_after=None
[2025-04-14T21:54:37.816+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.816+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer to None, run_after=None
[2025-04-14T21:54:37.817+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.817+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer to None, run_after=None
[2025-04-14T21:54:37.818+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:37.817+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer to None, run_after=None
[2025-04-14T21:54:37.837+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias.py took 0.259 seconds
