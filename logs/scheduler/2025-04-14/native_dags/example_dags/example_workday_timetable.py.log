[2025-04-14T18:20:55.589+0200] {processor.py:186} INFO - Started process (PID=27761) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:20:55.590+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:20:55.592+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:55.592+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:20:56.020+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:20:56.216+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.216+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:example_workday_timetable
[2025-04-14T18:20:56.225+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.224+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:example_workday_timetable
[2025-04-14T18:20:56.231+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.230+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:example_workday_timetable
[2025-04-14T18:20:56.239+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.238+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:example_workday_timetable
[2025-04-14T18:20:56.245+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.244+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:example_workday_timetable
[2025-04-14T18:20:56.251+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.250+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:example_workday_timetable
[2025-04-14T18:20:56.257+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.256+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:example_workday_timetable
[2025-04-14T18:20:56.257+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.257+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:20:56.268+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.267+0200] {dag.py:3262} INFO - Creating ORM DAG for example_workday_timetable
[2025-04-14T18:20:56.333+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:20:56.332+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:20:56.348+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.765 seconds
[2025-04-14T18:21:31.789+0200] {processor.py:186} INFO - Started process (PID=28877) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:21:31.791+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:21:31.793+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:21:31.793+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:21:32.312+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:21:32.442+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:21:32.441+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:21:32.500+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:21:32.500+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:21:32.518+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.735 seconds
[2025-04-14T18:22:29.576+0200] {processor.py:186} INFO - Started process (PID=30338) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:22:29.578+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:22:29.581+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:29.580+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:22:30.249+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:22:30.450+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:30.450+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:22:30.543+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:30.542+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:22:30.580+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.010 seconds
[2025-04-14T18:24:51.390+0200] {processor.py:186} INFO - Started process (PID=33940) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:24:51.392+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:24:51.394+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:51.394+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:24:52.128+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:24:52.262+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:52.262+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:24:52.322+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:52.322+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:24:52.343+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.959 seconds
[2025-04-14T18:24:53.124+0200] {processor.py:186} INFO - Started process (PID=34051) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:24:53.126+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:24:53.128+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:53.127+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:24:53.693+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:24:53.836+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:53.835+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:24:53.904+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:53.903+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:24:53.924+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.806 seconds
[2025-04-14T18:25:31.634+0200] {processor.py:186} INFO - Started process (PID=34967) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:25:31.636+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:25:31.638+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:25:31.638+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:25:32.333+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:25:32.535+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:25:32.534+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:25:32.623+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:25:32.622+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:25:32.651+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.024 seconds
[2025-04-14T18:26:30.412+0200] {processor.py:186} INFO - Started process (PID=36463) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:26:30.414+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:26:30.416+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:26:30.415+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:26:30.869+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:26:30.983+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:26:30.983+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:26:31.036+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:26:31.036+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:26:31.055+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.649 seconds
[2025-04-14T18:28:24.040+0200] {processor.py:186} INFO - Started process (PID=40463) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:28:24.042+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:28:24.044+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:24.043+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:28:24.587+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:28:24.712+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:24.711+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:28:24.769+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:24.769+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:28:24.789+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.755 seconds
[2025-04-14T18:28:46.519+0200] {processor.py:186} INFO - Started process (PID=41158) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:28:46.520+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:28:46.522+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:46.521+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:28:46.755+0200] {processor.py:186} INFO - Started process (PID=41159) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:28:46.757+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:28:46.758+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:46.758+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:28:46.950+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:28:47.059+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:47.058+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:28:47.108+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:47.108+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:28:47.126+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.612 seconds
[2025-04-14T18:28:47.178+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:28:47.296+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:47.296+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:28:47.354+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:47.353+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:28:47.416+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.666 seconds
[2025-04-14T18:29:47.966+0200] {processor.py:186} INFO - Started process (PID=43070) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:29:47.968+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:29:47.969+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:29:47.969+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:29:48.398+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:29:48.506+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:29:48.506+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:29:48.556+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:29:48.556+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:29:48.574+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.613 seconds
[2025-04-14T18:31:32.811+0200] {processor.py:186} INFO - Started process (PID=45804) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:31:32.813+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:31:32.815+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:31:32.814+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:31:33.361+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:31:33.504+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:31:33.503+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:31:33.555+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:31:33.555+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:31:33.573+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.767 seconds
[2025-04-14T18:31:49.218+0200] {processor.py:186} INFO - Started process (PID=46199) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:31:49.220+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:31:49.221+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:31:49.221+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:31:49.639+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:31:49.747+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:31:49.747+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:31:49.798+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:31:49.798+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:31:49.819+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.606 seconds
[2025-04-14T18:31:50.317+0200] {processor.py:186} INFO - Started process (PID=46209) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:31:50.318+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:31:50.321+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:31:50.320+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:31:50.814+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:31:50.926+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:31:50.925+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:31:50.985+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:31:50.984+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:31:51.008+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.697 seconds
[2025-04-14T18:32:56.704+0200] {processor.py:186} INFO - Started process (PID=47746) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:32:56.706+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:32:56.708+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:32:56.708+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:32:57.383+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:32:57.558+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:32:57.557+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:32:57.641+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:32:57.641+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:32:57.669+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.972 seconds
[2025-04-14T18:33:58.707+0200] {processor.py:186} INFO - Started process (PID=48979) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:33:58.710+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:33:58.711+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:58.711+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:33:59.393+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:33:59.580+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:59.580+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:33:59.654+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:59.654+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:33:59.679+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.978 seconds
[2025-04-14T18:35:22.143+0200] {processor.py:186} INFO - Started process (PID=50608) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:35:22.145+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:35:22.147+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:22.147+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:35:23.111+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:35:23.403+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:23.402+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:35:23.603+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:23.603+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:35:23.639+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.502 seconds
[2025-04-14T18:35:44.431+0200] {processor.py:186} INFO - Started process (PID=51051) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:35:44.461+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:35:44.464+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:44.463+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:35:45.137+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:35:45.339+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:45.338+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:35:45.423+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:45.423+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:35:45.462+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.037 seconds
[2025-04-14T18:35:49.545+0200] {processor.py:186} INFO - Started process (PID=51085) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:35:49.547+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:35:49.549+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:49.548+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:35:50.449+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:35:50.667+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:50.666+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:35:50.746+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:50.745+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:35:50.772+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.234 seconds
[2025-04-14T18:37:02.002+0200] {processor.py:186} INFO - Started process (PID=52564) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:37:02.004+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:37:02.006+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:02.006+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:37:02.680+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:37:02.889+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:02.888+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:37:03.039+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:03.038+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:37:03.161+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.165 seconds
[2025-04-14T18:39:27.515+0200] {processor.py:186} INFO - Started process (PID=56228) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:39:27.518+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:39:27.520+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:39:27.519+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:39:28.518+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:39:28.719+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:39:28.718+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:39:28.832+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:39:28.832+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:39:28.881+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.373 seconds
[2025-04-14T18:39:30.669+0200] {processor.py:186} INFO - Started process (PID=56331) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:39:30.671+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:39:30.673+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:39:30.672+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:39:31.408+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:39:31.590+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:39:31.590+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:39:31.653+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:39:31.653+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:39:31.673+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.010 seconds
[2025-04-14T18:39:55.057+0200] {processor.py:186} INFO - Started process (PID=56980) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:39:55.058+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:39:55.060+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:39:55.059+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:39:55.717+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:39:55.873+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:39:55.873+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:39:55.953+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:39:55.953+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:39:55.980+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.930 seconds
[2025-04-14T18:40:01.787+0200] {processor.py:186} INFO - Started process (PID=57174) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:40:01.789+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:40:01.791+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:40:01.791+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:40:02.553+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:40:02.728+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:40:02.727+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:40:02.811+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:40:02.811+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:40:02.868+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.087 seconds
[2025-04-14T18:41:12.036+0200] {processor.py:186} INFO - Started process (PID=59581) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:41:12.039+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:41:12.041+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:41:12.040+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:41:12.709+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:41:12.893+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:41:12.892+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:41:12.966+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:41:12.966+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:41:12.995+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.965 seconds
[2025-04-14T18:43:41.226+0200] {processor.py:186} INFO - Started process (PID=63427) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:43:41.229+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:43:41.232+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:41.231+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:43:43.089+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:43:43.633+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:43.619+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:43:43.636+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:43.635+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:43:43.851+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:43.850+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:43:43.893+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 2.670 seconds
[2025-04-14T18:44:17.069+0200] {processor.py:186} INFO - Started process (PID=64441) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:44:17.071+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:44:17.073+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:17.072+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:44:18.123+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:44:18.321+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:18.309+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:44:18.323+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:18.323+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:44:18.412+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:18.412+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:44:18.456+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.394 seconds
[2025-04-14T18:44:20.905+0200] {processor.py:186} INFO - Started process (PID=64658) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:44:20.907+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:44:20.909+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:20.909+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:44:21.739+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:44:21.911+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:21.906+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:44:21.913+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:21.913+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:44:21.993+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:21.993+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:44:22.034+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.135 seconds
[2025-04-14T18:44:24.853+0200] {processor.py:186} INFO - Started process (PID=64686) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:44:24.854+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:44:24.856+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:24.856+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:44:25.602+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:44:25.757+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:25.753+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:44:25.759+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:25.758+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:44:25.828+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:25.828+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:44:25.866+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.020 seconds
[2025-04-14T18:45:23.466+0200] {processor.py:186} INFO - Started process (PID=66122) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:45:23.469+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:45:23.471+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:45:23.470+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:45:24.346+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:45:24.520+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:45:24.509+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:45:24.522+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:45:24.522+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:45:24.601+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:45:24.601+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:45:24.643+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.183 seconds
[2025-04-14T18:47:38.530+0200] {processor.py:186} INFO - Started process (PID=69476) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:47:38.532+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:47:38.534+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:47:38.533+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:47:39.402+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:47:39.581+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:47:39.569+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:47:39.583+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:47:39.582+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:47:39.670+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:47:39.670+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:47:39.705+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.183 seconds
[2025-04-14T18:48:01.876+0200] {processor.py:186} INFO - Started process (PID=70122) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:48:01.879+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:48:01.881+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:01.881+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:48:02.766+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:48:02.940+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:02.928+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:48:02.942+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:02.941+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:48:03.027+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:03.027+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:48:03.072+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.203 seconds
[2025-04-14T18:48:11.764+0200] {processor.py:186} INFO - Started process (PID=70260) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:48:11.766+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:48:11.768+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:11.768+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:48:12.722+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:48:12.920+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:12.903+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:48:12.922+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:12.921+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:48:13.011+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:13.011+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:48:13.054+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.296 seconds
[2025-04-14T18:48:14.874+0200] {processor.py:186} INFO - Started process (PID=70400) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:48:14.876+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:48:14.878+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:14.878+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:48:16.200+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:48:16.487+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:16.481+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:48:16.489+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:16.488+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:48:16.573+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:48:16.573+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:48:16.614+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.749 seconds
[2025-04-14T18:49:30.723+0200] {processor.py:186} INFO - Started process (PID=71889) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:49:30.725+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:49:30.727+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:49:30.727+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:49:31.611+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:49:31.794+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:49:31.783+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:49:31.796+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:49:31.796+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:49:31.882+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:49:31.881+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:49:31.923+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.206 seconds
[2025-04-14T18:51:41.990+0200] {processor.py:186} INFO - Started process (PID=74789) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:51:41.992+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:51:41.994+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.993+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:51:42.745+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:51:42.919+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:42.910+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:51:42.921+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:42.921+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:51:42.999+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:42.999+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:51:43.038+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.054 seconds
[2025-04-14T18:51:50.598+0200] {processor.py:186} INFO - Started process (PID=74899) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:51:50.599+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:51:50.600+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:50.600+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:51:51.060+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:51:51.210+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:51.206+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:51:51.212+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:51.212+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:51:51.285+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:51.285+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:51:51.320+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.728 seconds
[2025-04-14T18:51:56.943+0200] {processor.py:186} INFO - Started process (PID=75105) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:51:56.945+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:51:56.947+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:56.946+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:51:57.514+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:51:57.678+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:57.672+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:51:57.680+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:57.679+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:51:57.758+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:57.757+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:51:57.795+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.858 seconds
[2025-04-14T18:52:56.815+0200] {processor.py:186} INFO - Started process (PID=76481) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:52:56.816+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:52:56.818+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:52:56.817+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:52:57.422+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:52:57.536+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:52:57.526+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:52:57.537+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:52:57.537+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:52:57.594+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:52:57.594+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:52:57.626+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.817 seconds
[2025-04-14T18:54:53.494+0200] {processor.py:186} INFO - Started process (PID=79024) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:54:53.496+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:54:53.497+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:54:53.497+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:54:54.206+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:54:54.346+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:54:54.336+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:54:54.348+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:54:54.347+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:54:54.436+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:54:54.436+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:54:54.482+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.994 seconds
[2025-04-14T18:54:59.384+0200] {processor.py:186} INFO - Started process (PID=79111) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:54:59.386+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:54:59.388+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:54:59.387+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:55:00.228+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:55:00.437+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:55:00.422+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:55:00.439+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:55:00.438+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:55:00.559+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:55:00.559+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:55:00.603+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.225 seconds
[2025-04-14T18:55:10.004+0200] {processor.py:186} INFO - Started process (PID=79330) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:55:10.006+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:55:10.008+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:55:10.008+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:55:10.843+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:55:11.027+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:55:11.016+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:55:11.029+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:55:11.028+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:55:11.186+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:55:11.186+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:55:11.230+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.232 seconds
[2025-04-14T18:56:37.789+0200] {processor.py:186} INFO - Started process (PID=81053) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:56:37.791+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:56:37.793+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:56:37.793+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:56:38.681+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:56:38.884+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:56:38.871+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:56:38.886+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:56:38.886+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:56:38.976+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:56:38.976+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:56:39.019+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.238 seconds
[2025-04-14T18:58:54.475+0200] {processor.py:186} INFO - Started process (PID=84132) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:58:54.477+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:58:54.479+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:58:54.479+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:58:54.915+0200] {processor.py:186} INFO - Started process (PID=84169) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:58:54.916+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:58:54.917+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:58:54.917+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:58:55.341+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:58:55.522+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:58:55.512+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:58:55.524+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:58:55.523+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:58:55.551+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:58:55.608+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:58:55.608+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:58:55.650+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.183 seconds
[2025-04-14T18:58:55.730+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:58:55.725+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:58:55.732+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:58:55.732+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:58:55.820+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:58:55.819+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:58:55.863+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.955 seconds
[2025-04-14T18:59:19.294+0200] {processor.py:186} INFO - Started process (PID=84718) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:59:19.296+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T18:59:19.298+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:19.298+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:59:20.449+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T18:59:20.647+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:20.637+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T18:59:20.648+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:20.648+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T18:59:20.756+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:20.756+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T18:59:20.802+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.517 seconds
[2025-04-14T19:00:43.936+0200] {processor.py:186} INFO - Started process (PID=86344) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:00:43.938+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:00:43.941+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:00:43.940+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:00:45.046+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:00:45.235+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:00:45.224+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:00:45.236+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:00:45.236+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:00:45.328+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:00:45.328+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:00:45.372+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.443 seconds
[2025-04-14T19:02:41.590+0200] {processor.py:186} INFO - Started process (PID=89025) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:02:41.591+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:02:41.592+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:41.592+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:02:41.863+0200] {processor.py:186} INFO - Started process (PID=89026) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:02:41.865+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:02:41.868+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:41.867+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:02:42.261+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:02:42.433+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:02:42.443+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:42.433+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:02:42.445+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:42.444+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:02:42.517+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:42.517+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:02:42.553+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.969 seconds
[2025-04-14T19:02:42.582+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:42.577+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:02:42.584+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:42.583+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:02:42.652+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:42.651+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:02:42.685+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.829 seconds
[2025-04-14T19:02:59.923+0200] {processor.py:186} INFO - Started process (PID=89433) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:02:59.925+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:02:59.927+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:59.926+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:03:00.815+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:03:01.025+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:03:01.016+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:03:01.027+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:03:01.027+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:03:01.107+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:03:01.106+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:03:01.150+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.234 seconds
[2025-04-14T19:04:33.376+0200] {processor.py:186} INFO - Started process (PID=91300) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:04:33.378+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:04:33.381+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:33.380+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:04:34.116+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:04:34.242+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:34.233+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:04:34.243+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:34.243+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:04:34.298+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:34.298+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:04:34.329+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.959 seconds
[2025-04-14T19:06:25.024+0200] {processor.py:186} INFO - Started process (PID=94188) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:06:25.025+0200] {processor.py:186} INFO - Started process (PID=94189) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:06:25.026+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:06:25.027+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:06:25.028+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:25.028+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:06:25.029+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:25.029+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:06:25.930+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:06:25.930+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:06:26.163+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:26.149+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:06:26.163+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:26.152+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:06:26.165+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:26.164+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:06:26.165+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:26.164+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:06:26.252+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:26.250+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:06:26.255+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:26.254+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:06:26.305+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.288 seconds
[2025-04-14T19:06:26.324+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.306 seconds
[2025-04-14T19:06:34.197+0200] {processor.py:186} INFO - Started process (PID=94377) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:06:34.214+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:06:34.217+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:34.216+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:06:34.925+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:06:35.163+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:35.158+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:06:35.165+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:35.165+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:06:35.253+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:35.252+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:06:35.663+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.474 seconds
[2025-04-14T19:08:22.993+0200] {processor.py:186} INFO - Started process (PID=97819) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:08:22.996+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:08:22.998+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:22.997+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:08:23.773+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:08:23.906+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:23.899+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:08:23.907+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:23.907+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:08:23.919+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:23.919+0200] {dag.py:3262} INFO - Creating ORM DAG for example_workday_timetable
[2025-04-14T19:08:23.972+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:23.971+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:08:24.007+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.021 seconds
[2025-04-14T19:10:29.813+0200] {processor.py:186} INFO - Started process (PID=1677) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:10:29.815+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:10:29.817+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:29.817+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:10:30.708+0200] {processor.py:186} INFO - Started process (PID=1722) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:10:30.710+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:10:30.712+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:30.712+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:10:30.784+0200] {processor.py:186} INFO - Started process (PID=1723) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:10:30.785+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:10:30.787+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:30.787+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:10:30.932+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:10:31.145+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:31.134+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:10:31.147+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:31.146+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:10:31.245+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:31.245+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:10:31.288+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.483 seconds
[2025-04-14T19:10:31.562+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:10:31.596+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:10:31.761+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:31.756+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:10:31.763+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:31.763+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:10:31.792+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:31.787+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:10:31.794+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:31.793+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:10:31.853+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:31.853+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:10:31.885+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:31.884+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:10:31.895+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.194 seconds
[2025-04-14T19:10:31.924+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.146 seconds
[2025-04-14T19:12:35.843+0200] {processor.py:186} INFO - Started process (PID=4460) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:12:35.848+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:12:35.850+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:35.849+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:12:36.774+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:12:36.931+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:36.917+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:12:36.949+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:36.948+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:12:37.016+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:37.016+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:12:37.133+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.296 seconds
[2025-04-14T19:14:30.225+0200] {processor.py:186} INFO - Started process (PID=6957) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:14:30.227+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:14:30.229+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:30.229+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:14:31.112+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:14:31.258+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:31.247+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:14:31.259+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:31.259+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:14:31.324+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:31.324+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:14:31.359+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.141 seconds
[2025-04-14T19:14:34.077+0200] {processor.py:186} INFO - Started process (PID=7069) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:14:34.079+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:14:34.081+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:34.081+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:14:34.670+0200] {processor.py:186} INFO - Started process (PID=7071) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:14:34.673+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:14:34.675+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:34.674+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:14:34.675+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:14:34.840+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:34.834+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:14:34.842+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:34.841+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:14:34.917+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:34.917+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:14:34.955+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.885 seconds
[2025-04-14T19:14:35.298+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:14:35.424+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:35.421+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:14:35.426+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:35.425+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:14:35.484+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:35.484+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:14:35.512+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.848 seconds
[2025-04-14T19:16:22.733+0200] {processor.py:186} INFO - Started process (PID=9515) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:16:22.735+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:16:22.737+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:22.737+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:16:23.633+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:16:23.821+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:23.812+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1647, in serialize_dag
    serialized_dag = cls.serialize_to_json(dag, cls._decorated_fields)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 612, in serialize_to_json
    serialized_object[key] = encode_timetable(value)
                             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 322, in encode_timetable
    raise _TimetableNotRegistered(importable_string)
airflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'example_workday_timetable': Timetable class 'airflow.example_dags.plugins.workday.AfterWorkdayTimetable' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.
[2025-04-14T19:16:23.829+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:23.829+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:16:23.917+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:23.916+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:16:23.957+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.230 seconds
[2025-04-14T19:18:23.850+0200] {processor.py:186} INFO - Started process (PID=12154) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:18:23.851+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:18:23.853+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:23.853+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:18:24.524+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:18:24.873+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:24.873+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:example_workday_timetable
[2025-04-14T19:18:24.887+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:24.886+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:example_workday_timetable
[2025-04-14T19:18:24.896+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:24.896+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:example_workday_timetable
[2025-04-14T19:18:24.906+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:24.906+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:example_workday_timetable
[2025-04-14T19:18:24.914+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:24.913+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:example_workday_timetable
[2025-04-14T19:18:24.921+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:24.921+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:example_workday_timetable
[2025-04-14T19:18:24.928+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:24.927+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:example_workday_timetable
[2025-04-14T19:18:24.928+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:24.928+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:18:25.000+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:24.999+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:18:25.023+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.180 seconds
[2025-04-14T19:19:57.573+0200] {processor.py:186} INFO - Started process (PID=14524) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:19:57.574+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:19:57.575+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:19:57.575+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:19:58.151+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:19:58.348+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:19:58.347+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:19:58.397+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:19:58.397+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:19:58.415+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.848 seconds
[2025-04-14T19:21:19.425+0200] {processor.py:186} INFO - Started process (PID=16370) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:21:19.426+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:21:19.427+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:19.427+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:21:19.842+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:21:19.953+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:19.952+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:21:20.001+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:20.000+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:21:20.018+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.599 seconds
[2025-04-14T19:22:55.897+0200] {processor.py:186} INFO - Started process (PID=18477) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:22:55.900+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:22:55.902+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:22:55.901+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:22:56.591+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:22:56.742+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:22:56.742+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:22:56.802+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:22:56.801+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:22:56.822+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.931 seconds
[2025-04-14T19:24:20.525+0200] {processor.py:186} INFO - Started process (PID=20225) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:24:20.527+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:24:20.528+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:20.528+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:24:21.241+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:24:21.391+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:21.390+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:24:21.532+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:21.531+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:24:21.552+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.033 seconds
[2025-04-14T19:26:05.421+0200] {processor.py:186} INFO - Started process (PID=22546) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:26:05.423+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:26:05.425+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:05.424+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:26:06.237+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:26:06.554+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:06.553+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:26:06.627+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:06.627+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:26:06.656+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.241 seconds
[2025-04-14T19:27:47.787+0200] {processor.py:186} INFO - Started process (PID=24646) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:27:47.789+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:27:47.791+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:27:47.790+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:27:48.701+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:27:48.914+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:27:48.914+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:27:49.007+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:27:49.007+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:27:49.036+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.258 seconds
[2025-04-14T19:29:42.010+0200] {processor.py:186} INFO - Started process (PID=27306) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:29:42.013+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:29:42.015+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:42.015+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:29:42.804+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:29:43.097+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:43.096+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:29:43.179+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:43.178+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:29:43.208+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.205 seconds
[2025-04-14T19:31:14.131+0200] {processor.py:186} INFO - Started process (PID=29169) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:31:14.133+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:31:14.135+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:14.135+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:31:14.686+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:31:14.839+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:14.838+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:31:14.911+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:14.911+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:31:14.935+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.809 seconds
[2025-04-14T19:32:56.046+0200] {processor.py:186} INFO - Started process (PID=31488) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:32:56.048+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:32:56.049+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:32:56.049+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:32:56.476+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:32:56.585+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:32:56.585+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:32:56.641+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:32:56.641+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:32:56.660+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.621 seconds
[2025-04-14T19:34:12.752+0200] {processor.py:186} INFO - Started process (PID=33365) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:34:12.755+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:34:12.757+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:12.756+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:34:13.405+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:34:13.536+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:13.535+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:34:13.601+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:13.600+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:34:13.619+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.873 seconds
[2025-04-14T19:36:09.919+0200] {processor.py:186} INFO - Started process (PID=35879) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:36:09.921+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:36:09.923+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:09.923+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:36:10.629+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:36:10.907+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:10.907+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:36:10.966+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:10.966+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:36:10.989+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.075 seconds
[2025-04-14T19:37:26.485+0200] {processor.py:186} INFO - Started process (PID=37477) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:37:26.487+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:37:26.490+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:37:26.489+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:37:27.371+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:37:27.578+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:37:27.578+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:37:27.718+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:37:27.718+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:37:27.748+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.270 seconds
[2025-04-14T19:39:26.836+0200] {processor.py:186} INFO - Started process (PID=40277) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:39:26.838+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:39:26.840+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:26.840+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:39:27.485+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:39:27.608+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:27.607+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:39:27.664+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:27.664+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:39:27.684+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.854 seconds
[2025-04-14T19:40:48.095+0200] {processor.py:186} INFO - Started process (PID=41798) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:40:48.097+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:40:48.098+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:40:48.098+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:40:48.844+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:40:49.221+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:40:49.220+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:40:49.321+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:40:49.321+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:40:49.357+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.270 seconds
[2025-04-14T19:42:56.594+0200] {processor.py:186} INFO - Started process (PID=44725) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:42:56.595+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:42:56.597+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:56.596+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:42:57.248+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:42:57.365+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:57.364+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:42:57.424+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:57.423+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:42:57.453+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.865 seconds
[2025-04-14T19:43:52.344+0200] {processor.py:186} INFO - Started process (PID=46110) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:43:52.346+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:43:52.347+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:43:52.347+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:43:52.838+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:43:52.970+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:43:52.969+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:43:53.033+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:43:53.033+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:43:53.059+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.720 seconds
[2025-04-14T19:45:54.374+0200] {processor.py:186} INFO - Started process (PID=48971) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:45:54.376+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:45:54.378+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:54.377+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:45:55.204+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:45:55.540+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:55.539+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:45:55.622+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:55.621+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:45:55.651+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.284 seconds
[2025-04-14T19:46:53.007+0200] {processor.py:186} INFO - Started process (PID=50288) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:46:53.009+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:46:53.011+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:46:53.010+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:46:53.459+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:46:53.587+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:46:53.586+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:46:53.643+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:46:53.643+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:46:53.663+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.661 seconds
[2025-04-14T19:49:02.367+0200] {processor.py:186} INFO - Started process (PID=53150) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:49:02.369+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:49:02.370+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:49:02.370+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:49:03.020+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:49:03.167+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:49:03.167+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:49:03.242+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:49:03.242+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:49:03.271+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.911 seconds
[2025-04-14T19:50:06.332+0200] {processor.py:186} INFO - Started process (PID=54500) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:50:06.334+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:50:06.336+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:50:06.336+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:50:07.059+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:50:07.362+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:50:07.362+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:50:07.424+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:50:07.423+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:50:07.446+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.121 seconds
[2025-04-14T19:52:13.249+0200] {processor.py:186} INFO - Started process (PID=57503) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:52:13.251+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:52:13.252+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:52:13.252+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:52:13.917+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:52:14.032+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:52:14.032+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:52:14.085+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:52:14.085+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:52:14.103+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.860 seconds
[2025-04-14T19:53:09.453+0200] {processor.py:186} INFO - Started process (PID=58807) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:53:09.455+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:53:09.456+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:09.456+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:53:09.916+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:53:10.031+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:10.030+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:53:10.087+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:10.087+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:53:10.106+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.658 seconds
[2025-04-14T19:55:07.056+0200] {processor.py:186} INFO - Started process (PID=61671) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:55:07.058+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:55:07.060+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:55:07.060+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:55:07.804+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:55:08.035+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:55:08.035+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:55:08.092+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:55:08.092+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:55:08.113+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.064 seconds
[2025-04-14T19:56:05.900+0200] {processor.py:186} INFO - Started process (PID=63054) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:56:05.902+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:56:05.903+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:05.903+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:56:06.378+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:56:06.491+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:06.490+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:56:06.543+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:06.543+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:56:06.562+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.668 seconds
[2025-04-14T19:58:10.183+0200] {processor.py:186} INFO - Started process (PID=65970) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:58:10.184+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:58:10.186+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:58:10.186+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:58:10.990+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:58:11.132+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:58:11.132+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:58:11.202+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:58:11.201+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:58:11.228+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.052 seconds
[2025-04-14T19:59:06.275+0200] {processor.py:186} INFO - Started process (PID=67263) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:59:06.276+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T19:59:06.278+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:59:06.278+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:59:06.798+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T19:59:06.930+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:59:06.930+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T19:59:06.991+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:59:06.990+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T19:59:07.013+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.745 seconds
[2025-04-14T20:01:26.130+0200] {processor.py:186} INFO - Started process (PID=70182) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:01:26.132+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:01:26.134+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:26.133+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:01:26.992+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:01:27.388+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:27.387+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:01:27.489+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:27.488+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:01:27.523+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.400 seconds
[2025-04-14T20:02:21.172+0200] {processor.py:186} INFO - Started process (PID=71276) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:02:21.175+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:02:21.177+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:02:21.176+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:02:22.212+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:02:22.413+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:02:22.412+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:02:22.499+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:02:22.499+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:02:22.525+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.359 seconds
[2025-04-14T20:04:51.596+0200] {processor.py:186} INFO - Started process (PID=74554) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:04:51.597+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:04:51.599+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:51.598+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:04:52.113+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:04:52.356+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:52.356+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:04:52.410+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:52.409+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:04:52.429+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.840 seconds
[2025-04-14T20:05:31.273+0200] {processor.py:186} INFO - Started process (PID=75460) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:05:31.275+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:05:31.277+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:05:31.276+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:05:31.943+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:05:32.086+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:05:32.086+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:05:32.146+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:05:32.145+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:05:32.166+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.900 seconds
[2025-04-14T20:08:05.148+0200] {processor.py:186} INFO - Started process (PID=79178) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:08:05.150+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:08:05.151+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:08:05.151+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:08:05.761+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:08:05.878+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:08:05.878+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:08:05.932+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:08:05.932+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:08:05.949+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.806 seconds
[2025-04-14T20:08:35.429+0200] {processor.py:186} INFO - Started process (PID=79855) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:08:35.431+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:08:35.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:08:35.432+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:08:36.206+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:08:36.395+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:08:36.394+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:08:36.468+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:08:36.468+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:08:36.506+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.084 seconds
[2025-04-14T20:11:14.606+0200] {processor.py:186} INFO - Started process (PID=83228) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:11:14.608+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:11:14.609+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:11:14.609+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:11:15.024+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:11:15.218+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:11:15.217+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:11:15.275+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:11:15.275+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:11:15.296+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.696 seconds
[2025-04-14T20:11:41.314+0200] {processor.py:186} INFO - Started process (PID=83869) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:11:41.316+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:11:41.317+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:11:41.317+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:11:41.782+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:11:41.788+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:11:41.787+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:11:41.936+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:11:41.936+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:11:41.954+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.646 seconds
[2025-04-14T20:14:14.171+0200] {processor.py:186} INFO - Started process (PID=87179) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:14:14.173+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:14:14.175+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:14:14.174+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:14:15.000+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:14:15.198+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:14:15.198+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:14:15.289+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:14:15.289+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:14:15.319+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.155 seconds
[2025-04-14T20:14:40.474+0200] {processor.py:186} INFO - Started process (PID=87725) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:14:40.475+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:14:40.477+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:14:40.477+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:14:40.937+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:14:41.138+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:14:41.137+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:14:41.187+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:14:41.186+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:14:41.206+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.738 seconds
[2025-04-14T20:17:08.433+0200] {processor.py:186} INFO - Started process (PID=91080) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:17:08.435+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:17:08.436+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:17:08.436+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:17:08.866+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:17:08.968+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:17:08.968+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:17:09.015+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:17:09.014+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:17:09.030+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.602 seconds
[2025-04-14T20:17:30.561+0200] {processor.py:186} INFO - Started process (PID=91502) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:17:30.580+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:17:30.602+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:17:30.602+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:17:31.204+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:17:31.379+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:17:31.378+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:17:31.449+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:17:31.449+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:17:31.537+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.982 seconds
[2025-04-14T20:19:54.366+0200] {processor.py:186} INFO - Started process (PID=94946) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:19:54.367+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:19:54.368+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:54.368+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:19:54.938+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:19:55.125+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:55.125+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:19:55.171+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:55.171+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:19:55.189+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.829 seconds
[2025-04-14T20:20:19.020+0200] {processor.py:186} INFO - Started process (PID=95386) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:20:19.022+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:20:19.024+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:20:19.023+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:20:19.662+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:20:19.670+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:20:19.669+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:20:19.896+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:20:19.895+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:20:19.924+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.910 seconds
[2025-04-14T20:23:02.527+0200] {processor.py:186} INFO - Started process (PID=99198) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:23:02.529+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:23:02.530+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:23:02.530+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:23:03.185+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:23:03.304+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:23:03.304+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:23:03.355+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:23:03.355+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:23:03.374+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.853 seconds
[2025-04-14T20:23:15.284+0200] {processor.py:186} INFO - Started process (PID=99520) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:23:15.285+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:23:15.286+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:23:15.286+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:23:15.742+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:23:15.852+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:23:15.851+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:23:15.901+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:23:15.901+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:23:15.919+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.641 seconds
[2025-04-14T20:26:07.000+0200] {processor.py:186} INFO - Started process (PID=3869) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:26:07.001+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:26:07.003+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:26:07.002+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:26:07.646+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:26:07.916+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:26:07.915+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:26:07.993+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:26:07.993+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:26:08.025+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.031 seconds
[2025-04-14T20:26:13.055+0200] {processor.py:186} INFO - Started process (PID=3912) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:26:13.057+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:26:13.059+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:26:13.058+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:26:13.543+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:26:13.551+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:26:13.550+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:26:13.694+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:26:13.694+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:26:13.711+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.662 seconds
[2025-04-14T20:29:07.116+0200] {processor.py:186} INFO - Started process (PID=7873) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:29:07.117+0200] {processor.py:186} INFO - Started process (PID=7874) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:29:07.130+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:29:07.130+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:29:07.132+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:29:07.131+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:29:07.132+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:29:07.131+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:29:07.816+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:29:07.816+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:29:07.978+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:29:07.977+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:29:07.979+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:29:07.979+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:29:08.054+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:29:08.053+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:29:08.055+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:29:08.055+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:29:08.150+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.039 seconds
[2025-04-14T20:29:08.192+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.082 seconds
[2025-04-14T20:31:41.229+0200] {processor.py:186} INFO - Started process (PID=11503) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:31:41.231+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:31:41.233+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:31:41.232+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:31:41.524+0200] {processor.py:186} INFO - Started process (PID=11571) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:31:41.526+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:31:41.527+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:31:41.527+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:31:41.955+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:31:42.108+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:31:42.239+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:31:42.238+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:31:42.312+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:31:42.312+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:31:42.339+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.116 seconds
[2025-04-14T20:31:42.406+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:31:42.405+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:31:42.477+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:31:42.477+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:31:42.921+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:31:42.917+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"_dag_id": "example_workday_timetable", "edge_info": {}, "timetable": {"__type": "airflow.example_dags.plugins.workday.After ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 18:31:42.243563', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:31:42.922+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:31:42.922+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:31:42.924+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"_dag_id": "example_workday_timetable", "edge_info": {}, "timetable": {"__type": "airflow.example_dags.plugins.workday.After ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 18:31:42.243563', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:34:23.197+0200] {processor.py:186} INFO - Started process (PID=15253) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:34:23.198+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:34:23.200+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:34:23.199+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:34:23.849+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:34:23.968+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:34:23.968+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:34:24.026+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:34:24.025+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:34:24.051+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.860 seconds
[2025-04-14T20:34:25.023+0200] {processor.py:186} INFO - Started process (PID=15263) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:34:25.024+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:34:25.026+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:34:25.026+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:34:25.544+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:34:25.682+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:34:25.681+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:34:25.740+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:34:25.740+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:34:25.758+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.740 seconds
[2025-04-14T20:36:57.916+0200] {processor.py:186} INFO - Started process (PID=18969) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:36:57.918+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:36:57.919+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:36:57.919+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:36:58.578+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:36:58.875+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:36:58.874+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:36:58.955+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:36:58.954+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:36:58.986+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.076 seconds
[2025-04-14T20:36:59.533+0200] {processor.py:186} INFO - Started process (PID=18979) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:36:59.545+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:36:59.565+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:36:59.565+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:37:00.081+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:37:00.095+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:37:00.095+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:37:00.305+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:37:00.305+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:37:00.444+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.917 seconds
[2025-04-14T20:39:45.068+0200] {processor.py:186} INFO - Started process (PID=22675) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:39:45.069+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:39:45.071+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:39:45.071+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:39:45.496+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:39:45.684+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:39:45.684+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:39:45.765+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:39:45.765+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:39:45.783+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.721 seconds
[2025-04-14T20:39:46.830+0200] {processor.py:186} INFO - Started process (PID=22685) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:39:46.832+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:39:46.834+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:39:46.833+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:39:47.338+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:39:47.343+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:39:47.343+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:39:47.497+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:39:47.497+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:39:47.514+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.689 seconds
[2025-04-14T20:42:22.542+0200] {processor.py:186} INFO - Started process (PID=26457) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:42:22.543+0200] {processor.py:186} INFO - Started process (PID=26456) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:42:22.544+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:42:22.544+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:42:22.546+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:42:22.546+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:42:22.546+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:42:22.546+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:42:23.192+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:42:23.192+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:42:23.315+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:42:23.315+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:42:23.316+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:42:23.316+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:42:23.391+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:42:23.391+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:42:23.391+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:42:23.391+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:42:23.412+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.876 seconds
[2025-04-14T20:42:23.416+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.879 seconds
[2025-04-14T20:44:55.792+0200] {processor.py:186} INFO - Started process (PID=30071) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:44:55.794+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:44:55.795+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:44:55.795+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:44:56.487+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:44:56.730+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:44:56.729+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:44:56.784+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:44:56.784+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:44:56.812+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.025 seconds
[2025-04-14T20:44:57.904+0200] {processor.py:186} INFO - Started process (PID=30182) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:44:57.905+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:44:57.907+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:44:57.906+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:44:58.322+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:44:58.327+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:44:58.327+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:44:58.451+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:44:58.451+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:44:58.468+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.569 seconds
[2025-04-14T20:47:29.786+0200] {processor.py:186} INFO - Started process (PID=33693) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:47:29.787+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:47:29.789+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:47:29.788+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:47:30.205+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:47:30.306+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:47:30.305+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:47:30.358+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:47:30.358+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:47:30.378+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.598 seconds
[2025-04-14T20:47:31.516+0200] {processor.py:186} INFO - Started process (PID=33804) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:47:31.518+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:47:31.519+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:47:31.518+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:47:31.902+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:47:31.998+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:47:31.997+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:47:32.042+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:47:32.042+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:47:32.059+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.547 seconds
[2025-04-14T20:50:09.764+0200] {processor.py:186} INFO - Started process (PID=37356) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:50:09.766+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:50:09.768+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:50:09.768+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:50:10.249+0200] {processor.py:186} INFO - Started process (PID=37365) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:50:10.251+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:50:10.252+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:50:10.252+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:50:10.356+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:50:10.571+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:50:10.571+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:50:10.635+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:50:10.634+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:50:10.654+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.895 seconds
[2025-04-14T20:50:10.704+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:50:10.709+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:50:10.709+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:50:10.847+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:50:10.847+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:50:10.868+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.624 seconds
[2025-04-14T20:52:48.435+0200] {processor.py:186} INFO - Started process (PID=40929) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:52:48.437+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:52:48.438+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:52:48.438+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:52:49.118+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:52:49.293+0200] {processor.py:186} INFO - Started process (PID=40952) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:52:49.294+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:52:49.296+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:52:49.296+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:52:49.302+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:52:49.302+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:52:49.380+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:52:49.380+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:52:49.405+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.976 seconds
[2025-04-14T20:52:49.881+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:52:49.999+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:52:49.999+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:52:50.061+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:52:50.061+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:52:50.082+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.795 seconds
[2025-04-14T20:55:25.921+0200] {processor.py:186} INFO - Started process (PID=44683) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:55:25.923+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:55:25.924+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:55:25.924+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:55:26.029+0200] {processor.py:186} INFO - Started process (PID=44690) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:55:26.030+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:55:26.031+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:55:26.030+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:55:26.339+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:55:26.401+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:55:26.532+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:55:26.532+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:55:26.582+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:55:26.582+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:55:26.599+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.683 seconds
[2025-04-14T20:55:26.611+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:55:26.610+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:55:26.662+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:55:26.662+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:55:26.770+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:55:26.768+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"timezone": "UTC", "start_date": 1609459200.0, "edge_info": {}, "timetable": {"__type": "airflow.example_dags.plugins.workda ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 18:55:26.493923', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:55:26.771+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:55:26.771+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:55:26.773+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"timezone": "UTC", "start_date": 1609459200.0, "edge_info": {}, "timetable": {"__type": "airflow.example_dags.plugins.workda ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 18:55:26.493923', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:58:00.339+0200] {processor.py:186} INFO - Started process (PID=48299) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:58:00.341+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:58:00.342+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:58:00.342+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:58:00.733+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:58:00.831+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:58:00.830+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:58:00.875+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:58:00.875+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:58:00.891+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.557 seconds
[2025-04-14T20:58:01.040+0200] {processor.py:186} INFO - Started process (PID=48313) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:58:01.041+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T20:58:01.043+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:58:01.042+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:58:01.508+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T20:58:01.649+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:58:01.649+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T20:58:01.708+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:58:01.708+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T20:58:01.733+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.698 seconds
[2025-04-14T21:00:29.438+0200] {processor.py:186} INFO - Started process (PID=51877) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:00:29.440+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:00:29.442+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:00:29.441+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:00:29.709+0200] {processor.py:186} INFO - Started process (PID=51878) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:00:29.710+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:00:29.711+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:00:29.711+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:00:29.904+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:00:30.128+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:00:30.128+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:00:30.187+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:00:30.191+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:00:30.190+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:00:30.213+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.780 seconds
[2025-04-14T21:00:30.308+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:00:30.308+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:00:30.355+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:00:30.355+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:00:30.372+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.669 seconds
[2025-04-14T21:03:04.132+0200] {processor.py:186} INFO - Started process (PID=55574) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:03:04.134+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:03:04.135+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:03:04.135+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:03:04.524+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:03:04.623+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:03:04.622+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:03:04.677+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:03:04.677+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:03:04.696+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.570 seconds
[2025-04-14T21:03:05.565+0200] {processor.py:186} INFO - Started process (PID=55582) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:03:05.566+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:03:05.567+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:03:05.567+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:03:06.093+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:03:06.242+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:03:06.242+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:03:06.314+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:03:06.314+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:03:06.339+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.779 seconds
[2025-04-14T21:05:45.354+0200] {processor.py:186} INFO - Started process (PID=59317) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:05:45.356+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:05:45.358+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:05:45.357+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:05:45.977+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:05:46.197+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:05:46.196+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:05:46.251+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:05:46.251+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:05:46.274+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.926 seconds
[2025-04-14T21:05:46.730+0200] {processor.py:186} INFO - Started process (PID=59326) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:05:46.732+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:05:46.734+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:05:46.733+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:05:47.182+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:05:47.187+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:05:47.187+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:05:47.312+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:05:47.312+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:05:47.329+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.605 seconds
[2025-04-14T21:08:41.347+0200] {processor.py:186} INFO - Started process (PID=63323) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:08:41.349+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:08:41.351+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:08:41.351+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:08:41.589+0200] {processor.py:186} INFO - Started process (PID=63324) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:08:41.591+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:08:41.593+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:08:41.593+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:08:42.378+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:08:42.378+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:08:42.568+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:08:42.568+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:08:42.569+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:08:42.569+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:08:42.656+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:08:42.656+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:08:42.657+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:08:42.657+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:08:42.689+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.351 seconds
[2025-04-14T21:08:42.693+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.112 seconds
[2025-04-14T21:11:32.371+0200] {processor.py:186} INFO - Started process (PID=67233) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:11:32.372+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:11:32.373+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:11:32.373+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:11:32.943+0200] {processor.py:186} INFO - Started process (PID=67244) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:11:32.945+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:11:32.946+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:11:32.946+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:11:32.980+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:11:33.179+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:11:33.178+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:11:33.224+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:11:33.224+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:11:33.241+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.876 seconds
[2025-04-14T21:11:33.360+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:11:33.365+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:11:33.365+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:11:33.499+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:11:33.499+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:11:33.517+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.579 seconds
[2025-04-14T21:14:07.762+0200] {processor.py:186} INFO - Started process (PID=71044) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:14:07.763+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:14:07.764+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:14:07.764+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:14:08.329+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:14:08.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:14:08.432+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:14:08.480+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:14:08.480+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:14:08.496+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.740 seconds
[2025-04-14T21:14:08.710+0200] {processor.py:186} INFO - Started process (PID=71046) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:14:08.711+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:14:08.712+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:14:08.712+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:14:09.101+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:14:09.199+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:14:09.198+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:14:09.243+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:14:09.243+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:14:09.260+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.556 seconds
[2025-04-14T21:16:39.077+0200] {processor.py:186} INFO - Started process (PID=74815) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:16:39.078+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:16:39.080+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:16:39.080+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:16:39.377+0200] {processor.py:186} INFO - Started process (PID=74817) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:16:39.378+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:16:39.380+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:16:39.380+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:16:39.665+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:16:39.789+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:16:39.862+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:16:39.862+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:16:39.907+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:16:39.907+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:16:39.924+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.853 seconds
[2025-04-14T21:16:39.976+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:16:39.976+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:16:40.021+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:16:40.021+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:16:40.431+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:16:40.420+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "start_date": 1609459200.0, "timetable": {"__type": "airflow.example_dags.plugins.workda ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 19:16:39.877500', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:16:40.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:16:40.432+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:16:40.435+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "start_date": 1609459200.0, "timetable": {"__type": "airflow.example_dags.plugins.workda ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 19:16:39.877500', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:19:07.958+0200] {processor.py:186} INFO - Started process (PID=78221) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:19:07.960+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:19:07.961+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:19:07.961+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:19:08.541+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:19:08.655+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:19:08.655+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:19:08.705+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:19:08.705+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:19:08.722+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.770 seconds
[2025-04-14T21:19:09.603+0200] {processor.py:186} INFO - Started process (PID=78320) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:19:09.604+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:19:09.605+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:19:09.605+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:19:10.002+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:19:10.102+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:19:10.101+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:19:10.149+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:19:10.149+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:19:10.169+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.571 seconds
[2025-04-14T21:21:38.087+0200] {processor.py:186} INFO - Started process (PID=81911) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:21:38.089+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:21:38.091+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:21:38.091+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:21:38.192+0200] {processor.py:186} INFO - Started process (PID=81938) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:21:38.193+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:21:38.195+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:21:38.195+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:21:38.757+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:21:38.757+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:21:38.944+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:21:38.944+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:21:38.945+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:21:38.944+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:21:38.988+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:21:38.988+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:21:38.988+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:21:38.988+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:21:39.005+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.924 seconds
[2025-04-14T21:21:39.455+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:21:39.445+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.example_dags.plugins.workday.AfterWorkdayTimetable", "__var": {}}, "start_date": 1609459200 ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 19:21:38.840609', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:21:39.456+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:21:39.456+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:21:39.458+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.example_dags.plugins.workday.AfterWorkdayTimetable", "__var": {}}, "start_date": 1609459200 ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 19:21:38.840609', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:24:25.014+0200] {processor.py:186} INFO - Started process (PID=85855) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:24:25.016+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:24:25.018+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:24:25.017+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:24:25.137+0200] {processor.py:186} INFO - Started process (PID=85856) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:24:25.138+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:24:25.139+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:24:25.139+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:24:25.644+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:24:25.644+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:24:25.747+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:24:25.747+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:24:25.748+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:24:25.747+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:24:25.795+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:24:25.795+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:24:25.798+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:24:25.797+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:24:25.814+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.683 seconds
[2025-04-14T21:24:25.816+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.807 seconds
[2025-04-14T21:27:01.045+0200] {processor.py:186} INFO - Started process (PID=89663) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:27:01.046+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:27:01.048+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:27:01.047+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:27:01.572+0200] {processor.py:186} INFO - Started process (PID=89672) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:27:01.573+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:27:01.575+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:27:01.575+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:27:01.610+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:27:01.800+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:27:01.800+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:27:01.847+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:27:01.847+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:27:01.865+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.825 seconds
[2025-04-14T21:27:01.978+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:27:01.983+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:27:01.983+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:27:02.119+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:27:02.119+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:27:02.137+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.571 seconds
[2025-04-14T21:29:35.795+0200] {processor.py:186} INFO - Started process (PID=93304) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:29:35.796+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:29:35.798+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:29:35.797+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:29:36.134+0200] {processor.py:186} INFO - Started process (PID=93313) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:29:36.135+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:29:36.136+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:29:36.136+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:29:36.382+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:29:36.492+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:29:36.491+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:29:36.539+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:29:36.538+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:29:36.548+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:29:36.556+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.766 seconds
[2025-04-14T21:29:36.674+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:29:36.673+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:29:36.735+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:29:36.734+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:29:36.753+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.625 seconds
[2025-04-14T21:32:04.514+0200] {processor.py:186} INFO - Started process (PID=96980) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:32:04.516+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:32:04.517+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:32:04.517+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:32:05.084+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:32:05.150+0200] {processor.py:186} INFO - Started process (PID=96981) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:32:05.151+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:32:05.152+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:32:05.152+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:32:05.281+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:32:05.280+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:32:05.328+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:32:05.327+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:32:05.345+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.837 seconds
[2025-04-14T21:32:05.563+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:32:05.568+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:32:05.568+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:32:05.702+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:32:05.702+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:32:05.723+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.579 seconds
[2025-04-14T21:34:50.154+0200] {processor.py:186} INFO - Started process (PID=994) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:34:50.156+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:34:50.158+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:34:50.158+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:34:50.847+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:34:50.920+0200] {processor.py:186} INFO - Started process (PID=996) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:34:50.921+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:34:50.923+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:34:50.922+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:34:51.071+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:34:51.071+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:34:51.126+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:34:51.125+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:34:51.150+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.001 seconds
[2025-04-14T21:34:51.387+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:34:51.392+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:34:51.392+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:34:51.568+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:34:51.567+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:34:51.586+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.672 seconds
[2025-04-14T21:37:31.197+0200] {processor.py:186} INFO - Started process (PID=4851) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:37:31.199+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:37:31.201+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:37:31.201+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:37:31.359+0200] {processor.py:186} INFO - Started process (PID=4852) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:37:31.360+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:37:31.362+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:37:31.362+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:37:31.644+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:37:31.783+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:37:31.783+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:37:31.836+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:37:31.835+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:37:31.839+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:37:31.855+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.663 seconds
[2025-04-14T21:37:31.970+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:37:31.970+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:37:32.026+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:37:32.026+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:37:32.043+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.689 seconds
[2025-04-14T21:39:57.394+0200] {processor.py:186} INFO - Started process (PID=8410) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:39:57.396+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:39:57.397+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:57.397+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:39:57.951+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:39:58.133+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:58.133+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:39:58.179+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:58.179+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:39:58.195+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.806 seconds
[2025-04-14T21:39:58.916+0200] {processor.py:186} INFO - Started process (PID=8420) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:39:58.918+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:39:58.920+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:58.919+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:39:59.317+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:39:59.322+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:59.321+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:39:59.447+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:39:59.447+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:39:59.467+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.556 seconds
[2025-04-14T21:42:28.857+0200] {processor.py:186} INFO - Started process (PID=12192) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:42:28.859+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:42:28.861+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:42:28.860+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:42:29.457+0200] {processor.py:186} INFO - Started process (PID=12193) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:42:29.459+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:42:29.460+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:42:29.460+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:42:29.494+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:42:29.624+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:42:29.623+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:42:29.691+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:42:29.690+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:42:29.711+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.860 seconds
[2025-04-14T21:42:29.902+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:42:30.007+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:42:30.006+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:42:30.063+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:42:30.063+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:42:30.083+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.632 seconds
[2025-04-14T21:45:05.824+0200] {processor.py:186} INFO - Started process (PID=15837) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:45:05.826+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:45:05.827+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:45:05.827+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:45:06.126+0200] {processor.py:186} INFO - Started process (PID=15840) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:45:06.127+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:45:06.128+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:45:06.128+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:45:06.432+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:45:06.581+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:45:06.656+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:45:06.656+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:45:06.702+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:45:06.702+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:45:06.720+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.902 seconds
[2025-04-14T21:45:06.787+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:45:06.786+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:45:06.837+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:45:06.836+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:45:07.121+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:45:07.118+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 19:45:06.679666', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:45:07.122+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:45:07.122+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:45:07.124+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('example_workday_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py', 53672645747625511, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1154 characters truncated) ... sk_module": "airflow.operators.empty", "_is_empty": true, "start_trigger_args": null}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-04-14 19:45:06.679666', '662550a0c46d4dc376ed747d86dd0769', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:47:43.591+0200] {processor.py:186} INFO - Started process (PID=19530) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:47:43.592+0200] {processor.py:186} INFO - Started process (PID=19536) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:47:43.594+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:47:43.594+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:47:43.596+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:47:43.595+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:47:43.596+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:47:43.595+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:47:44.030+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:47:44.030+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:47:44.133+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:47:44.133+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:47:44.135+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:47:44.135+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:47:44.180+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:47:44.180+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:47:44.180+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:47:44.180+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:47:44.198+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.612 seconds
[2025-04-14T21:47:44.202+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.616 seconds
[2025-04-14T21:50:21.715+0200] {processor.py:186} INFO - Started process (PID=23394) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:50:21.716+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:50:21.718+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:50:21.717+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:50:22.368+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:50:22.605+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:50:22.604+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:50:22.652+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:50:22.652+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:50:22.671+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.961 seconds
[2025-04-14T21:50:23.473+0200] {processor.py:186} INFO - Started process (PID=23404) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:50:23.475+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:50:23.476+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:50:23.475+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:50:23.896+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:50:23.902+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:50:23.901+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:50:24.034+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:50:24.034+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:50:24.052+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.584 seconds
[2025-04-14T21:53:02.167+0200] {processor.py:186} INFO - Started process (PID=27236) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:53:02.169+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:53:02.170+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:53:02.170+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:53:02.782+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:53:02.888+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:53:02.888+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:53:02.926+0200] {processor.py:186} INFO - Started process (PID=27250) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:53:02.927+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:53:02.928+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:53:02.928+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:53:02.943+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:53:02.942+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:53:02.960+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.798 seconds
[2025-04-14T21:53:03.376+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:53:03.477+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:53:03.477+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:53:03.523+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:53:03.522+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:53:03.539+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.619 seconds
[2025-04-14T21:55:44.289+0200] {processor.py:186} INFO - Started process (PID=30914) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:55:44.295+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:55:44.317+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:55:44.316+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:55:44.769+0200] {processor.py:186} INFO - Started process (PID=30915) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:55:44.789+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py for tasks to queue
[2025-04-14T21:55:44.809+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:55:44.808+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:55:45.052+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:55:45.303+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:55:45.303+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:55:45.324+0200] {processor.py:925} INFO - DAG(s) 'example_workday_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py
[2025-04-14T21:55:45.361+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:55:45.361+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:55:45.400+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 1.117 seconds
[2025-04-14T21:55:45.446+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:55:45.445+0200] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-14T21:55:45.525+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:55:45.525+0200] {dag.py:4180} INFO - Setting next_dagrun for example_workday_timetable to 2021-01-04 00:00:00+00:00, run_after=2021-01-05 00:00:00+00:00
[2025-04-14T21:55:45.606+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_workday_timetable.py took 0.844 seconds
