[2025-04-14T18:22:58.874+0200] {processor.py:186} INFO - Started process (PID=30993) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:22:58.876+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:22:58.877+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:58.877+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:22:58.939+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:22:59.316+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.315+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_never_scheduled
[2025-04-14T18:22:59.329+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.329+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_consumes_1_never_scheduled
[2025-04-14T18:22:59.338+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.338+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_never_scheduled
[2025-04-14T18:22:59.350+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.350+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_consumes_1_never_scheduled
[2025-04-14T18:22:59.358+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.358+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_1_never_scheduled
[2025-04-14T18:22:59.366+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.365+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_consumes_1_never_scheduled
[2025-04-14T18:22:59.373+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.372+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_1_never_scheduled
[2025-04-14T18:22:59.388+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.388+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_produces_2
[2025-04-14T18:22:59.396+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.396+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_produces_2
[2025-04-14T18:22:59.405+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.404+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_produces_2
[2025-04-14T18:22:59.417+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.417+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_produces_2
[2025-04-14T18:22:59.426+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.426+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_produces_2
[2025-04-14T18:22:59.435+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.435+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_produces_2
[2025-04-14T18:22:59.444+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.443+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_produces_2
[2025-04-14T18:22:59.460+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.460+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:consume_1_or_2_with_dataset_expressions
[2025-04-14T18:22:59.468+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.468+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:consume_1_or_2_with_dataset_expressions
[2025-04-14T18:22:59.477+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.477+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:consume_1_or_2_with_dataset_expressions
[2025-04-14T18:22:59.489+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.489+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-04-14T18:22:59.498+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.497+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-04-14T18:22:59.506+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.506+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-04-14T18:22:59.515+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.515+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-04-14T18:22:59.533+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.532+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:conditional_dataset_and_time_based_timetable
[2025-04-14T18:22:59.542+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.541+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:conditional_dataset_and_time_based_timetable
[2025-04-14T18:22:59.550+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.550+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:conditional_dataset_and_time_based_timetable
[2025-04-14T18:22:59.561+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.561+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:conditional_dataset_and_time_based_timetable
[2025-04-14T18:22:59.569+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.569+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:conditional_dataset_and_time_based_timetable
[2025-04-14T18:22:59.576+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.576+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:conditional_dataset_and_time_based_timetable
[2025-04-14T18:22:59.584+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.584+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:conditional_dataset_and_time_based_timetable
[2025-04-14T18:22:59.600+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.600+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_consumes_unknown_never_scheduled
[2025-04-14T18:22:59.608+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.608+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_consumes_unknown_never_scheduled
[2025-04-14T18:22:59.616+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.615+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_consumes_unknown_never_scheduled
[2025-04-14T18:22:59.625+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.625+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-04-14T18:22:59.636+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.636+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-04-14T18:22:59.642+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.642+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-04-14T18:22:59.648+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.648+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-04-14T18:22:59.661+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.661+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_and_2
[2025-04-14T18:22:59.667+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.667+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_consumes_1_and_2
[2025-04-14T18:22:59.673+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.673+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_and_2
[2025-04-14T18:22:59.683+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.683+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_consumes_1_and_2
[2025-04-14T18:22:59.689+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.689+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_1_and_2
[2025-04-14T18:22:59.696+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.696+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_consumes_1_and_2
[2025-04-14T18:22:59.702+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.702+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_1_and_2
[2025-04-14T18:22:59.714+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.714+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:consume_1_and_2_with_dataset_expressions
[2025-04-14T18:22:59.720+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.720+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:consume_1_and_2_with_dataset_expressions
[2025-04-14T18:22:59.726+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.726+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:consume_1_and_2_with_dataset_expressions
[2025-04-14T18:22:59.736+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.736+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-04-14T18:22:59.744+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.743+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-04-14T18:22:59.750+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.750+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-04-14T18:22:59.756+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.756+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-04-14T18:22:59.768+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.768+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_consumes_1
[2025-04-14T18:22:59.774+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.774+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_consumes_1
[2025-04-14T18:22:59.780+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.779+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_consumes_1
[2025-04-14T18:22:59.788+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.787+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_consumes_1
[2025-04-14T18:22:59.795+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.794+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_1
[2025-04-14T18:22:59.800+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.800+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_consumes_1
[2025-04-14T18:22:59.806+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.806+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_1
[2025-04-14T18:22:59.819+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.818+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_produces_1
[2025-04-14T18:22:59.825+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.825+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_produces_1
[2025-04-14T18:22:59.831+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.831+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_produces_1
[2025-04-14T18:22:59.839+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.839+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_produces_1
[2025-04-14T18:22:59.846+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.846+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_produces_1
[2025-04-14T18:22:59.852+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.851+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_produces_1
[2025-04-14T18:22:59.858+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.858+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_produces_1
[2025-04-14T18:22:59.871+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.871+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T18:22:59.879+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.878+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T18:22:59.886+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.886+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T18:22:59.894+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.894+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T18:22:59.900+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.900+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T18:22:59.906+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.906+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T18:22:59.913+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.912+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T18:22:59.913+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.913+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:22:59.925+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.925+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_1_never_scheduled
[2025-04-14T18:22:59.926+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.926+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_1_and_2
[2025-04-14T18:22:59.926+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.926+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_unknown_never_scheduled
[2025-04-14T18:22:59.927+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.927+0200] {dag.py:3262} INFO - Creating ORM DAG for consume_1_or_2_with_dataset_expressions
[2025-04-14T18:22:59.927+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.927+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_produces_2
[2025-04-14T18:22:59.928+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.928+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_1
[2025-04-14T18:22:59.929+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.928+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_produces_1
[2025-04-14T18:22:59.929+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.929+0200] {dag.py:3262} INFO - Creating ORM DAG for conditional_dataset_and_time_based_timetable
[2025-04-14T18:22:59.930+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.930+0200] {dag.py:3262} INFO - Creating ORM DAG for consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T18:22:59.930+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.930+0200] {dag.py:3262} INFO - Creating ORM DAG for consume_1_and_2_with_dataset_expressions
[2025-04-14T18:22:59.939+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.938+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:22:59.939+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.939+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:22:59.940+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.940+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:22:59.940+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.940+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:22:59.941+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.940+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:22:59.941+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.941+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:22:59.942+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.942+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:22:59.942+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.942+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:22:59.944+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.944+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:22:59.945+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:22:59.945+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:23:00.482+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 1.615 seconds
[2025-04-14T18:23:39.757+0200] {processor.py:186} INFO - Started process (PID=32076) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:23:39.759+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:23:39.760+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:39.760+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:23:39.854+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:23:40.010+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.009+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:23:40.103+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.102+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:23:40.107+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.107+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:23:40.108+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.108+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:23:40.109+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.109+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:23:40.110+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.110+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:23:40.112+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.112+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:23:40.113+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.113+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:23:40.114+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.114+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:23:40.117+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.117+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:23:40.118+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:40.118+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:23:40.155+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.406 seconds
[2025-04-14T18:24:43.880+0200] {processor.py:186} INFO - Started process (PID=33780) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:24:43.885+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:24:43.886+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:43.886+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:24:43.956+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:24:44.082+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.082+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:24:44.158+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.158+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:24:44.162+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.161+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:24:44.163+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.162+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:24:44.164+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.163+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:24:44.165+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.164+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:24:44.166+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.165+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:24:44.167+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.166+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:24:44.168+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.167+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:24:44.170+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.170+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:24:44.171+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:44.171+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:24:44.201+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.327 seconds
[2025-04-14T18:27:01.083+0200] {processor.py:186} INFO - Started process (PID=37259) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:27:01.085+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:27:01.087+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.086+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:27:01.133+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:27:01.262+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.262+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:27:01.337+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.337+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:27:01.340+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.340+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:27:01.341+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.341+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:27:01.342+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.342+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:27:01.343+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.343+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:27:01.344+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.344+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:27:01.345+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.345+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:27:01.347+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.346+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:27:01.350+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.350+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:27:01.352+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.351+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:27:01.381+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.304 seconds
[2025-04-14T18:27:01.457+0200] {processor.py:186} INFO - Started process (PID=37260) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:27:01.458+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:27:01.460+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.459+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:27:01.506+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:27:01.627+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.627+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:27:01.700+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.700+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:27:01.703+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.703+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:27:01.704+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.704+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:27:01.705+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.705+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:27:01.706+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.706+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:27:01.707+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.707+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:27:01.708+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.708+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:27:01.709+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.708+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:27:01.711+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.711+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:27:01.712+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:01.712+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:27:01.739+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.287 seconds
[2025-04-14T18:27:39.605+0200] {processor.py:186} INFO - Started process (PID=39288) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:27:39.607+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:27:39.608+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.608+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:27:39.682+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:27:39.855+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.854+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:27:39.940+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.940+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:27:39.943+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.943+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:27:39.944+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.944+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:27:39.945+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.945+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:27:39.946+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.946+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:27:39.951+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.950+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:27:39.952+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.951+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:27:39.953+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.953+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:27:39.955+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.955+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:27:39.956+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:39.956+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:27:39.987+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.388 seconds
[2025-04-14T18:28:34.290+0200] {processor.py:186} INFO - Started process (PID=40714) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:28:34.291+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:28:34.293+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.292+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:28:34.375+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:28:34.499+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.499+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:28:34.578+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.578+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:28:34.581+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.581+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:28:34.582+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.582+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:28:34.583+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.583+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:28:34.584+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.584+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:28:34.585+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.585+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:28:34.586+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.586+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:28:34.587+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.587+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:28:34.590+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.589+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:28:34.591+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:34.590+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:28:34.618+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.334 seconds
[2025-04-14T18:30:23.267+0200] {processor.py:186} INFO - Started process (PID=43995) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:30:23.269+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:30:23.271+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.270+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:30:23.341+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:30:23.485+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.484+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:30:23.576+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.576+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:30:23.580+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.579+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:30:23.581+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.580+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:30:23.582+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.582+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:30:23.583+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.583+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:30:23.585+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.584+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:30:23.586+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.586+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:30:23.588+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.587+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:30:23.591+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.591+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:30:23.592+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:23.592+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:30:23.626+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.365 seconds
[2025-04-14T18:30:48.081+0200] {processor.py:186} INFO - Started process (PID=44635) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:30:48.084+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:30:48.086+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.085+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:30:48.146+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:30:48.282+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.282+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:30:48.369+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.369+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:30:48.373+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.372+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:30:48.374+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.374+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:30:48.375+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.375+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:30:48.376+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.376+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:30:48.377+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.377+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:30:48.378+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.378+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:30:48.379+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.379+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:30:48.382+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.381+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:30:48.383+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:48.383+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:30:48.419+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.343 seconds
[2025-04-14T18:34:09.338+0200] {processor.py:186} INFO - Started process (PID=49242) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:34:09.340+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:34:09.342+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.342+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:34:09.446+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:34:09.654+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.653+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:34:09.766+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.766+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:34:09.772+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.771+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:34:09.773+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.773+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:34:09.775+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.775+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:34:09.777+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.776+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:34:09.778+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.778+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:34:09.780+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.780+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:34:09.782+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.782+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:34:09.786+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.785+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:34:09.787+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:09.787+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:34:09.835+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.503 seconds
[2025-04-14T18:35:31.256+0200] {processor.py:186} INFO - Started process (PID=50765) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:35:31.258+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:35:31.260+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.260+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:35:31.358+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:35:31.579+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.579+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:35:31.723+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.723+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:35:31.728+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.727+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:35:31.729+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.729+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:35:31.731+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.731+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:35:31.732+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.732+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:35:31.734+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.734+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:35:31.736+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.735+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:35:31.737+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.737+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:35:31.741+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.741+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:35:31.743+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:31.742+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:35:31.787+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.537 seconds
[2025-04-14T18:36:34.064+0200] {processor.py:186} INFO - Started process (PID=51980) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:36:34.066+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:36:34.068+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.067+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:36:34.162+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:36:34.358+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.358+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:36:34.467+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.467+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:36:34.472+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.471+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:36:34.473+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.473+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:36:34.475+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.475+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:36:34.477+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.476+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:36:34.478+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.478+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:36:34.480+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.479+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:36:34.481+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.481+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:36:34.485+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.485+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:36:34.487+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:34.486+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:36:34.530+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.473 seconds
[2025-04-14T18:37:47.120+0200] {processor.py:186} INFO - Started process (PID=53715) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:37:47.122+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:37:47.124+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.124+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:37:47.258+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:37:47.473+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.472+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:37:47.606+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.606+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:37:47.628+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.628+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:37:47.644+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.644+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:37:47.664+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.664+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:37:47.682+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.682+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:37:47.700+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.700+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:37:47.702+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.702+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:37:47.720+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.720+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:37:47.742+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.741+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:37:47.759+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:37:47.758+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:37:47.873+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.760 seconds
[2025-04-14T18:38:19.406+0200] {processor.py:186} INFO - Started process (PID=54866) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:38:19.426+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:38:19.427+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.427+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:38:19.522+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:38:19.745+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.745+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:38:19.882+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.882+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:38:19.887+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.887+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:38:19.889+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.889+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:38:19.926+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.926+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:38:19.928+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.927+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:38:19.929+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.929+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:38:19.931+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.930+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:38:19.932+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.932+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:38:19.936+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.936+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:38:19.955+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:19.955+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:38:20.020+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.620 seconds
[2025-04-14T18:42:09.145+0200] {processor.py:186} INFO - Started process (PID=61306) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:09.147+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:42:09.149+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.148+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:09.258+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:09.534+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.534+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:42:09.680+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.679+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:42:09.686+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.685+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:09.688+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.687+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:09.689+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.689+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:09.691+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.691+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:42:09.693+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.693+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:42:09.695+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.695+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:42:09.697+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.696+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:42:09.701+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.701+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:42:09.703+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:09.703+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:42:09.755+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.617 seconds
[2025-04-14T18:42:11.033+0200] {processor.py:186} INFO - Started process (PID=61319) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:11.035+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:42:11.037+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.036+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:11.116+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:11.310+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.309+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:42:11.432+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.431+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:42:11.437+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.437+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:11.439+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.439+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:11.441+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.440+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:11.442+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.442+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:42:11.444+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.444+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:42:11.446+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.445+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:42:11.447+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.447+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:42:11.452+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.452+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:42:11.454+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:11.453+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:42:11.502+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.478 seconds
[2025-04-14T18:42:34.043+0200] {processor.py:186} INFO - Started process (PID=61954) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:34.045+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:42:34.047+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.046+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:34.121+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:34.318+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.318+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:42:34.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.433+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:42:34.438+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.438+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:34.440+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.439+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:34.442+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.441+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:34.444+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.443+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:42:34.446+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.445+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:42:34.447+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.447+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:42:34.449+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.449+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:42:34.453+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.452+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:42:34.455+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:34.454+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:42:34.494+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.458 seconds
[2025-04-14T18:42:41.526+0200] {processor.py:186} INFO - Started process (PID=62101) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:41.528+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:42:41.530+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.530+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:41.603+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:42:41.803+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.803+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:42:41.904+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.904+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:42:41.909+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.909+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:41.910+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.910+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:41.912+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.912+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:42:41.914+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.913+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:42:41.915+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.915+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:42:41.917+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.917+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:42:41.918+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.918+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:42:41.922+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.922+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:42:41.924+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:41.924+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:42:41.971+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.450 seconds
[2025-04-14T18:43:52.042+0200] {processor.py:186} INFO - Started process (PID=63679) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:43:52.045+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:43:52.047+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:52.046+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:43:52.251+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:43:52.802+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:52.801+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:43:53.073+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.071+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:43:53.082+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.082+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:43:53.091+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.090+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:43:53.093+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.092+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:43:53.095+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.094+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:43:53.098+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.096+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:43:53.100+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.099+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:43:53.102+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.101+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:43:53.107+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.107+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:43:53.110+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:43:53.109+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:43:53.200+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 1.167 seconds
[2025-04-14T18:46:51.258+0200] {processor.py:186} INFO - Started process (PID=68045) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:46:51.260+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:46:51.262+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.261+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:46:51.329+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:46:51.488+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.488+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:46:51.590+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.589+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:46:51.594+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.594+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:46:51.596+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.596+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:46:51.598+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.597+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:46:51.599+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.599+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:46:51.601+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.600+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:46:51.602+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.602+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:46:51.604+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.603+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:46:51.607+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.607+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:46:51.609+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:51.609+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:46:51.652+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.400 seconds
[2025-04-14T18:50:21.056+0200] {processor.py:186} INFO - Started process (PID=72920) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:50:21.058+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:50:21.060+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.060+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:50:21.117+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:50:21.717+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.717+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:50:21.741+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.741+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:50:21.744+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.744+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:50:21.746+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.746+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:50:21.747+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.747+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:50:21.748+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.748+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:50:21.749+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.749+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:50:21.750+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.750+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:50:21.751+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.751+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:50:21.754+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.754+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:50:21.755+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:21.755+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:50:21.793+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.743 seconds
[2025-04-14T18:50:34.863+0200] {processor.py:186} INFO - Started process (PID=73196) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:50:34.865+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:50:34.867+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:34.866+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:50:34.944+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:50:34.958+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:34.958+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:50:35.220+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.219+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:50:35.226+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.226+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:50:35.228+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.228+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:50:35.230+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.229+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:50:35.231+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.231+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:50:35.233+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.232+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:50:35.234+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.234+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:50:35.236+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.235+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:50:35.240+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.239+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:50:35.241+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:35.241+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:50:35.284+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.427 seconds
[2025-04-14T18:50:37.929+0200] {processor.py:186} INFO - Started process (PID=73383) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:50:37.931+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:50:37.933+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:37.932+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:50:37.978+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:50:37.988+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:37.987+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:50:38.161+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.161+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:50:38.164+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.164+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:50:38.165+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.165+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:50:38.166+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.166+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:50:38.167+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.167+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:50:38.169+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.168+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:50:38.170+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.169+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:50:38.171+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.170+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:50:38.173+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.173+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:50:38.174+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.174+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:50:38.202+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.278 seconds
[2025-04-14T18:51:40.805+0200] {processor.py:186} INFO - Started process (PID=74721) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:51:40.807+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:51:40.809+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:40.808+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:51:40.892+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:51:41.063+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.062+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:51:41.166+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.166+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:51:41.171+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.171+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:51:41.172+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.172+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:51:41.174+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.174+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:51:41.176+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.175+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:51:41.177+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.177+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:51:41.179+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.179+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:51:41.180+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.180+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:51:41.184+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.184+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:51:41.185+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:41.185+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:51:41.218+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.419 seconds
[2025-04-14T18:57:19.188+0200] {processor.py:186} INFO - Started process (PID=81946) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:57:19.190+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:57:19.192+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:19.192+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:57:19.276+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:57:20.162+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.162+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:57:20.199+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.198+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:57:20.203+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.202+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:57:20.204+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.204+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:57:20.206+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.206+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:57:20.208+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.208+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:57:20.210+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.210+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:57:20.212+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.212+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:57:20.213+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.213+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:57:20.217+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.217+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:57:20.219+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:20.219+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:57:20.372+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 1.193 seconds
[2025-04-14T18:57:22.376+0200] {processor.py:186} INFO - Started process (PID=82069) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:57:22.378+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:57:22.380+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:22.379+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:57:22.512+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:57:22.645+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:22.645+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:57:23.004+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.004+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:57:23.009+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.009+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:57:23.011+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.011+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:57:23.012+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.012+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:57:23.014+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.013+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:57:23.015+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.015+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:57:23.017+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.016+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:57:23.018+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.018+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:57:23.022+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.022+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:57:23.025+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:23.025+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:57:23.071+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.702 seconds
[2025-04-14T18:57:41.788+0200] {processor.py:186} INFO - Started process (PID=82560) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:57:41.790+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:57:41.792+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:41.791+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:57:41.903+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:57:41.918+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:41.918+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:57:42.241+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.240+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:57:42.246+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.246+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:57:42.248+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.248+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:57:42.250+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.250+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:57:42.252+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.252+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:57:42.254+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.254+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:57:42.256+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.256+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:57:42.258+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.257+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:57:42.263+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.262+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:57:42.265+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:42.265+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:57:42.328+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.547 seconds
[2025-04-14T18:59:04.974+0200] {processor.py:186} INFO - Started process (PID=84417) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:59:04.976+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T18:59:04.980+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:04.979+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:59:05.092+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T18:59:05.632+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.632+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T18:59:05.670+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.670+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T18:59:05.674+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.673+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:59:05.676+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.675+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T18:59:05.678+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.678+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T18:59:05.681+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.680+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T18:59:05.682+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.682+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T18:59:05.684+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.684+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T18:59:05.686+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.685+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T18:59:05.690+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.690+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T18:59:05.691+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:05.691+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T18:59:05.741+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.775 seconds
[2025-04-14T19:02:56.075+0200] {processor.py:186} INFO - Started process (PID=89300) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:02:56.076+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:02:56.078+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.078+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:02:56.165+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:02:56.360+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.360+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:02:56.472+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.472+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:02:56.478+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.478+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:02:56.479+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.479+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:02:56.481+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.480+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:02:56.482+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.482+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:02:56.483+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.483+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:02:56.485+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.485+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:02:56.486+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.486+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:02:56.490+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.490+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:02:56.492+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:02:56.492+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:02:56.530+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.461 seconds
[2025-04-14T19:04:54.735+0200] {processor.py:186} INFO - Started process (PID=91828) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:04:54.737+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:04:54.739+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:54.739+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:04:54.812+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:04:54.934+0200] {processor.py:186} INFO - Started process (PID=91829) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:04:54.936+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:04:54.938+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:54.937+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:04:55.007+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:04:55.302+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.302+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:04:55.324+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.323+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:04:55.327+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.326+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:04:55.328+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.328+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:04:55.329+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.329+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:04:55.330+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.330+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:04:55.331+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.331+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:04:55.332+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.332+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:04:55.333+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.333+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:04:55.337+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.336+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:04:55.338+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.337+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:04:55.365+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.365+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:04:55.374+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.645 seconds
[2025-04-14T19:04:55.395+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.394+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:04:55.397+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.397+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:04:55.398+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.398+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:04:55.399+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.399+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:04:55.401+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.400+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:04:55.402+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.402+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:04:55.403+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.403+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:04:55.404+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.404+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:04:55.407+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.407+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:04:55.408+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.408+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:04:55.924+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.920+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.927+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.926+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.929+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.928+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.931+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.930+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.933+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.932+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.935+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.934+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.937+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.936+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.938+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.938+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.940+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.939+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.941+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.941+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:04:55.942+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:55.942+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:04:55.944+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.154634', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 17:04:55.330244', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 17:04:55.345038', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T19:05:10.125+0200] {processor.py:186} INFO - Started process (PID=92116) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:05:10.127+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:05:10.129+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.128+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:05:10.190+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:05:10.200+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.200+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:05:10.389+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.389+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:05:10.393+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.392+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:05:10.394+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.394+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:05:10.395+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.395+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:05:10.396+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.396+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:05:10.397+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.397+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:05:10.398+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.398+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:05:10.400+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.399+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:05:10.403+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.403+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:05:10.404+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:10.404+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:05:10.441+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.322 seconds
[2025-04-14T19:10:51.284+0200] {processor.py:186} INFO - Started process (PID=2312) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:10:51.287+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:10:51.289+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.288+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:10:51.348+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:10:51.634+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.633+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_consumes_unknown_never_scheduled
[2025-04-14T19:10:51.643+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.643+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_consumes_unknown_never_scheduled
[2025-04-14T19:10:51.652+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.651+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_consumes_unknown_never_scheduled
[2025-04-14T19:10:51.662+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.662+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-04-14T19:10:51.669+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.669+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-04-14T19:10:51.676+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.675+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-04-14T19:10:51.682+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.682+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_consumes_unknown_never_scheduled
[2025-04-14T19:10:51.694+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.694+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:consume_1_or_2_with_dataset_expressions
[2025-04-14T19:10:51.701+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.700+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:consume_1_or_2_with_dataset_expressions
[2025-04-14T19:10:51.708+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.707+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:consume_1_or_2_with_dataset_expressions
[2025-04-14T19:10:51.799+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.798+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-04-14T19:10:51.806+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.806+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-04-14T19:10:51.814+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.813+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-04-14T19:10:51.826+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.826+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:consume_1_or_2_with_dataset_expressions
[2025-04-14T19:10:51.845+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.844+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_consumes_1
[2025-04-14T19:10:51.854+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.853+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_consumes_1
[2025-04-14T19:10:51.863+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.862+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_consumes_1
[2025-04-14T19:10:51.873+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.873+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_1
[2025-04-14T19:10:51.883+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.883+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_consumes_1
[2025-04-14T19:10:51.893+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.892+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_1
[2025-04-14T19:10:51.902+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.902+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_consumes_1
[2025-04-14T19:10:51.923+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.922+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_never_scheduled
[2025-04-14T19:10:51.933+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.933+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_never_scheduled
[2025-04-14T19:10:51.943+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.943+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_consumes_1_never_scheduled
[2025-04-14T19:10:51.957+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.957+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_1_never_scheduled
[2025-04-14T19:10:51.967+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.967+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_consumes_1_never_scheduled
[2025-04-14T19:10:51.977+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.977+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_1_never_scheduled
[2025-04-14T19:10:51.986+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:51.985+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_consumes_1_never_scheduled
[2025-04-14T19:10:52.005+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.005+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:consume_1_and_2_with_dataset_expressions
[2025-04-14T19:10:52.014+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.014+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:consume_1_and_2_with_dataset_expressions
[2025-04-14T19:10:52.024+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.023+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:consume_1_and_2_with_dataset_expressions
[2025-04-14T19:10:52.036+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.036+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-04-14T19:10:52.046+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.045+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-04-14T19:10:52.054+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.054+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-04-14T19:10:52.062+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.062+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:consume_1_and_2_with_dataset_expressions
[2025-04-14T19:10:52.078+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.077+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T19:10:52.086+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.085+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T19:10:52.092+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.092+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T19:10:52.104+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.104+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T19:10:52.112+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.112+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T19:10:52.121+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.121+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T19:10:52.131+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.130+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T19:10:52.148+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.148+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_produces_1
[2025-04-14T19:10:52.157+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.156+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_produces_1
[2025-04-14T19:10:52.165+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.164+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_produces_1
[2025-04-14T19:10:52.176+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.176+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_produces_1
[2025-04-14T19:10:52.186+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.185+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_produces_1
[2025-04-14T19:10:52.193+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.193+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_produces_1
[2025-04-14T19:10:52.203+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.202+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_produces_1
[2025-04-14T19:10:52.224+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.223+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_produces_2
[2025-04-14T19:10:52.234+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.233+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_produces_2
[2025-04-14T19:10:52.243+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.243+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_produces_2
[2025-04-14T19:10:52.258+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.257+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_produces_2
[2025-04-14T19:10:52.267+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.267+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_produces_2
[2025-04-14T19:10:52.276+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.275+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_produces_2
[2025-04-14T19:10:52.285+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.285+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_produces_2
[2025-04-14T19:10:52.302+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.302+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:conditional_dataset_and_time_based_timetable
[2025-04-14T19:10:52.310+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.309+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:conditional_dataset_and_time_based_timetable
[2025-04-14T19:10:52.318+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.318+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:conditional_dataset_and_time_based_timetable
[2025-04-14T19:10:52.330+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.330+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:conditional_dataset_and_time_based_timetable
[2025-04-14T19:10:52.339+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.338+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:conditional_dataset_and_time_based_timetable
[2025-04-14T19:10:52.349+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.348+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:conditional_dataset_and_time_based_timetable
[2025-04-14T19:10:52.357+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.357+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:conditional_dataset_and_time_based_timetable
[2025-04-14T19:10:52.373+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.373+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_and_2
[2025-04-14T19:10:52.380+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.380+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_and_2
[2025-04-14T19:10:52.386+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.386+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_consumes_1_and_2
[2025-04-14T19:10:52.394+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.394+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_consumes_1_and_2
[2025-04-14T19:10:52.400+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.400+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_consumes_1_and_2
[2025-04-14T19:10:52.407+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.407+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_consumes_1_and_2
[2025-04-14T19:10:52.415+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.414+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_consumes_1_and_2
[2025-04-14T19:10:52.415+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.415+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:10:52.429+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.429+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_1_never_scheduled
[2025-04-14T19:10:52.429+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.429+0200] {dag.py:3262} INFO - Creating ORM DAG for conditional_dataset_and_time_based_timetable
[2025-04-14T19:10:52.430+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.430+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_produces_1
[2025-04-14T19:10:52.431+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.431+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_produces_2
[2025-04-14T19:10:52.431+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.431+0200] {dag.py:3262} INFO - Creating ORM DAG for consume_1_or_both_2_and_3_with_dataset_expressions
[2025-04-14T19:10:52.432+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.432+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_1
[2025-04-14T19:10:52.432+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.432+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_1_and_2
[2025-04-14T19:10:52.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.433+0200] {dag.py:3262} INFO - Creating ORM DAG for consume_1_or_2_with_dataset_expressions
[2025-04-14T19:10:52.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.433+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_consumes_unknown_never_scheduled
[2025-04-14T19:10:52.434+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.434+0200] {dag.py:3262} INFO - Creating ORM DAG for consume_1_and_2_with_dataset_expressions
[2025-04-14T19:10:52.443+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.442+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:10:52.443+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.443+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:10:52.443+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.443+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:10:52.444+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.444+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:10:52.444+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.444+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:10:52.445+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.445+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:10:52.445+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.445+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:10:52.446+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.446+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:10:52.448+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.447+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:10:52.448+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:10:52.448+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:10:52.482+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 1.204 seconds
[2025-04-14T19:12:53.825+0200] {processor.py:186} INFO - Started process (PID=4759) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:12:53.827+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:12:53.829+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:53.828+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:12:53.923+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:12:54.164+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.164+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:12:54.259+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.259+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:12:54.263+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.263+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:12:54.264+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.264+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:12:54.265+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.265+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:12:54.266+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.266+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:12:54.268+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.267+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:12:54.269+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.269+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:12:54.271+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.271+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:12:54.275+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.275+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:12:54.276+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:54.276+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:12:54.313+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.495 seconds
[2025-04-14T19:12:55.213+0200] {processor.py:186} INFO - Started process (PID=4872) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:12:55.214+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:12:55.216+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.216+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:12:55.283+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:12:55.474+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.474+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:12:55.574+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.574+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:12:55.580+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.579+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:12:55.581+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.581+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:12:55.583+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.582+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:12:55.585+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.584+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:12:55.586+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.586+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:12:55.588+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.588+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:12:55.589+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.589+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:12:55.593+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.592+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:12:55.594+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.594+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:12:55.615+0200] {processor.py:186} INFO - Started process (PID=4873) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:12:55.616+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:12:55.618+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.618+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:12:55.632+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.425 seconds
[2025-04-14T19:12:55.677+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:12:55.827+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.826+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:12:55.922+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.921+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:12:55.926+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.926+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:12:55.928+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.927+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:12:55.929+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.929+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:12:55.930+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.930+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:12:55.932+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.932+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:12:55.933+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.933+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:12:55.935+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.935+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:12:55.939+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.939+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:12:55.940+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:55.940+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:12:55.985+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.377 seconds
[2025-04-14T19:18:48.910+0200] {processor.py:186} INFO - Started process (PID=12792) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:18:48.911+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:18:48.913+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:48.913+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:18:48.968+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:18:49.407+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.406+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:18:49.427+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.427+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:18:49.430+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.430+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:18:49.431+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.431+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:18:49.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.432+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:18:49.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.433+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:18:49.434+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.434+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:18:49.435+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.435+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:18:49.436+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.436+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:18:49.439+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.439+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:18:49.440+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:18:49.440+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:18:49.472+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.567 seconds
[2025-04-14T19:20:05.667+0200] {processor.py:186} INFO - Started process (PID=14668) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:20:05.668+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:20:05.670+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:05.670+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:20:05.744+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:20:06.261+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.260+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:20:06.289+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.289+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:20:06.293+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.292+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:20:06.295+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.294+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:20:06.296+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.296+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:20:06.297+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.297+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:20:06.298+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.298+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:20:06.300+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.300+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:20:06.301+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.301+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:20:06.305+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.305+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:20:06.307+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:20:06.306+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:20:06.352+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.691 seconds
[2025-04-14T19:24:40.840+0200] {processor.py:186} INFO - Started process (PID=20724) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:24:40.842+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:24:40.844+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:40.844+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:24:40.901+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:24:41.320+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.320+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:24:41.345+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.344+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:24:41.347+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.347+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:24:41.348+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.348+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:24:41.349+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.349+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:24:41.350+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.350+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:24:41.351+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.351+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:24:41.352+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.352+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:24:41.353+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.353+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:24:41.355+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.355+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:24:41.356+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:24:41.356+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:24:41.387+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.553 seconds
[2025-04-14T19:26:18.249+0200] {processor.py:186} INFO - Started process (PID=22808) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:26:18.252+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:26:18.254+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.253+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:26:18.325+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:26:18.542+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.542+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:26:18.654+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.653+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:26:18.659+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.658+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:26:18.660+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.660+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:26:18.661+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.661+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:26:18.662+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.662+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:26:18.664+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.663+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:26:18.665+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.664+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:26:18.666+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.666+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:26:18.670+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.669+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:26:18.671+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:26:18.671+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:26:18.707+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.464 seconds
[2025-04-14T19:31:38.172+0200] {processor.py:186} INFO - Started process (PID=29871) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:31:38.174+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:31:38.176+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.175+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:31:38.263+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:31:38.816+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.816+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:31:38.849+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.848+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:31:38.852+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.852+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:31:38.854+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.854+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:31:38.855+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.855+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:31:38.857+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.857+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:31:38.859+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.859+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:31:38.860+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.860+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:31:38.862+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.862+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:31:38.865+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.865+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:31:38.866+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:31:38.866+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:31:38.909+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.744 seconds
[2025-04-14T19:33:00.902+0200] {processor.py:186} INFO - Started process (PID=31705) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:33:00.904+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:33:00.905+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:00.905+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:33:00.976+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:33:01.106+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.106+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:33:01.190+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.190+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:33:01.194+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.194+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:33:01.195+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.195+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:33:01.196+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.196+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:33:01.197+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.197+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:33:01.199+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.198+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:33:01.200+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.200+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:33:01.201+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.201+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:33:01.203+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.203+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:33:01.204+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:33:01.204+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:33:01.234+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.337 seconds
[2025-04-14T19:38:12.577+0200] {processor.py:186} INFO - Started process (PID=38407) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:38:12.579+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:38:12.582+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:12.581+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:38:12.642+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:38:13.152+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.152+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:38:13.172+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.172+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:38:13.175+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.175+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:38:13.176+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.176+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:38:13.177+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.177+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:38:13.179+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.178+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:38:13.180+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.180+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:38:13.181+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.181+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:38:13.182+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.182+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:38:13.184+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.184+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:38:13.185+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:38:13.185+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:38:13.218+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.648 seconds
[2025-04-14T19:39:12.661+0200] {processor.py:186} INFO - Started process (PID=39893) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:39:12.663+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:39:12.664+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:12.664+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:39:12.735+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:39:12.916+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:12.915+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:39:12.998+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:12.998+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:39:13.002+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:13.001+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:39:13.003+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:13.002+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:39:13.004+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:13.003+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:39:13.005+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:13.004+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:39:13.006+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:13.006+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:39:13.007+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:13.006+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:39:13.008+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:13.007+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:39:13.010+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:13.010+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:39:13.011+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:39:13.011+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:39:13.040+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.385 seconds
[2025-04-14T19:44:38.540+0200] {processor.py:186} INFO - Started process (PID=47217) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:44:38.542+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:44:38.544+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:38.544+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:44:38.596+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:44:38.981+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:38.980+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:44:39.002+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.001+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:44:39.004+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.004+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:44:39.006+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.005+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:44:39.007+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.006+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:44:39.007+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.007+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:44:39.008+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.008+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:44:39.009+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.009+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:44:39.011+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.010+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:44:39.013+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.013+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:44:39.014+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:44:39.014+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:44:39.046+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.513 seconds
[2025-04-14T19:45:35.532+0200] {processor.py:186} INFO - Started process (PID=48594) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:45:35.534+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:45:35.536+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.536+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:45:35.635+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:45:35.801+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.800+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:45:35.902+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.901+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:45:35.906+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.905+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:45:35.907+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.907+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:45:35.909+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.909+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:45:35.910+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.910+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:45:35.911+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.911+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:45:35.913+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.912+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:45:35.914+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.914+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:45:35.916+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.916+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:45:35.917+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:45:35.917+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:45:35.958+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.433 seconds
[2025-04-14T19:51:00.233+0200] {processor.py:186} INFO - Started process (PID=55759) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:51:00.235+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:51:00.236+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.236+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:51:00.304+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:51:00.780+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.780+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:51:00.801+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.801+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:51:00.804+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.804+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:51:00.805+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.805+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:51:00.806+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.806+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:51:00.807+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.807+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:51:00.808+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.808+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:51:00.809+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.809+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:51:00.810+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.810+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:51:00.812+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.812+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:51:00.813+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:00.813+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:51:00.845+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.618 seconds
[2025-04-14T19:51:56.525+0200] {processor.py:186} INFO - Started process (PID=57058) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:51:56.527+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:51:56.529+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.529+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:51:56.594+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:51:56.783+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.783+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:51:56.877+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.876+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:51:56.880+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.880+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:51:56.881+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.881+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:51:56.882+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.882+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:51:56.883+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.883+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:51:56.884+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.884+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:51:56.885+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.885+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:51:56.886+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.886+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:51:56.890+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.889+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:51:56.891+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:51:56.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:51:56.922+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.404 seconds
[2025-04-14T19:56:55.147+0200] {processor.py:186} INFO - Started process (PID=64194) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:56:55.149+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:56:55.150+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.150+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:56:55.204+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:56:55.599+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.598+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:56:55.620+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.620+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:56:55.623+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.623+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:56:55.624+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.624+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:56:55.625+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.625+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:56:55.626+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.626+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:56:55.627+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.627+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:56:55.628+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.628+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:56:55.629+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.629+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:56:55.631+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.631+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:56:55.632+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:56:55.632+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:56:55.666+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.524 seconds
[2025-04-14T19:57:47.240+0200] {processor.py:186} INFO - Started process (PID=65455) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:57:47.242+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T19:57:47.244+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.243+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:57:47.325+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T19:57:47.460+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.460+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T19:57:47.546+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.546+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T19:57:47.549+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.549+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:57:47.551+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.550+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T19:57:47.552+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.552+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T19:57:47.553+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.553+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T19:57:47.554+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.554+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T19:57:47.555+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.555+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T19:57:47.556+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.556+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T19:57:47.558+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.558+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T19:57:47.559+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:57:47.559+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T19:57:47.591+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.357 seconds
[2025-04-14T20:03:24.016+0200] {processor.py:186} INFO - Started process (PID=72693) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:03:24.018+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:03:24.020+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.020+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:03:24.098+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:03:24.579+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.579+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:03:24.604+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.603+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:03:24.606+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.606+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:03:24.608+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.608+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:03:24.609+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.609+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:03:24.610+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.610+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:03:24.611+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.611+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:03:24.612+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.612+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:03:24.613+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.613+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:03:24.615+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.615+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:03:24.616+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:03:24.616+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:03:24.650+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.640 seconds
[2025-04-14T20:04:13.433+0200] {processor.py:186} INFO - Started process (PID=73661) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:04:13.434+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:04:13.436+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.436+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:04:13.548+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:04:13.781+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.781+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:04:13.880+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.879+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:04:13.884+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.883+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:04:13.885+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.885+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:04:13.886+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.886+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:04:13.888+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.887+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:04:13.889+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.889+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:04:13.891+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:04:13.893+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.892+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:04:13.896+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.896+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:04:13.898+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:04:13.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:04:13.943+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.517 seconds
[2025-04-14T20:09:58.373+0200] {processor.py:186} INFO - Started process (PID=81425) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:09:58.375+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:09:58.377+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:58.376+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:09:58.454+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:09:58.974+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:58.974+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:09:58.994+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:58.994+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:09:58.997+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:58.997+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:09:58.998+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:58.998+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:09:58.999+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:58.999+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:09:59.000+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:59.000+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:09:59.001+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:59.001+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:09:59.002+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:59.002+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:09:59.003+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:59.003+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:09:59.005+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:59.005+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:09:59.006+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:09:59.006+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:09:59.037+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.671 seconds
[2025-04-14T20:10:27.289+0200] {processor.py:186} INFO - Started process (PID=82213) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:10:27.290+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:10:27.292+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.291+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:10:27.340+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:10:27.350+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.350+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:10:27.531+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.530+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:10:27.537+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.537+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:10:27.538+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.538+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:10:27.540+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.539+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:10:27.542+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.541+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:10:27.543+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.543+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:10:27.545+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.545+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:10:27.546+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.546+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:10:27.550+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.550+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:10:27.552+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:10:27.552+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:10:27.603+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.319 seconds
[2025-04-14T20:15:55.424+0200] {processor.py:186} INFO - Started process (PID=89491) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:15:55.426+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:15:55.427+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.427+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:15:55.479+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:15:55.907+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.907+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:15:55.949+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.949+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:15:55.951+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.951+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:15:55.952+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.952+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:15:55.953+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.953+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:15:55.954+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.954+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:15:55.955+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.955+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:15:55.956+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.956+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:15:55.957+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.957+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:15:55.960+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.960+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:15:55.962+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:15:55.962+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:15:56.001+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.582 seconds
[2025-04-14T20:16:16.158+0200] {processor.py:186} INFO - Started process (PID=90012) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:16:16.160+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:16:16.161+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.161+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:16:16.249+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:16:16.261+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.260+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:16:16.458+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.458+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:16:16.461+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.461+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:16:16.463+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.462+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:16:16.463+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.463+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:16:16.464+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.464+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:16:16.466+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.465+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:16:16.467+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.467+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:16:16.468+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.468+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:16:16.471+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.470+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:16:16.472+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:16:16.471+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:16:16.501+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.349 seconds
[2025-04-14T20:21:35.808+0200] {processor.py:186} INFO - Started process (PID=97281) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:21:35.810+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:21:35.811+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:35.811+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:21:35.885+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:21:36.360+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.360+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:21:36.381+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.381+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:21:36.384+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.384+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:21:36.385+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.385+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:21:36.386+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.386+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:21:36.387+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.387+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:21:36.388+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.388+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:21:36.389+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.389+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:21:36.390+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.390+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:21:36.392+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.392+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:21:36.394+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:36.394+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:21:36.425+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.624 seconds
[2025-04-14T20:21:56.852+0200] {processor.py:186} INFO - Started process (PID=97770) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:21:56.854+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:21:56.856+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:56.856+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:21:56.959+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:21:56.973+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:56.973+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:21:57.239+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.238+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:21:57.244+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.244+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:21:57.246+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.246+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:21:57.247+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.247+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:21:57.249+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.249+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:21:57.251+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.251+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:21:57.252+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.252+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:21:57.254+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.254+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:21:57.258+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.258+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:21:57.260+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:21:57.260+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:21:57.308+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.464 seconds
[2025-04-14T20:27:58.392+0200] {processor.py:186} INFO - Started process (PID=6265) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:27:58.395+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:27:58.397+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.396+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:27:58.437+0200] {processor.py:186} INFO - Started process (PID=6266) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:27:58.438+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:27:58.440+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.440+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:27:58.462+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:27:58.495+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:27:58.859+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.859+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:27:58.871+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.870+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:27:58.877+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.876+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:27:58.879+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.879+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:27:58.880+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.880+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:27:58.881+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.881+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:27:58.882+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.881+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:27:58.882+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.882+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:27:58.883+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.883+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:27:58.884+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.884+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:27:58.886+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.886+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:27:58.887+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.887+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:27:58.888+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.888+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:27:58.891+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.890+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:27:58.892+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.891+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:27:58.892+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.892+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:27:58.893+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.893+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:27:58.894+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.894+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:27:58.895+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.895+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:27:58.896+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.896+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:27:58.898+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:27:58.899+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:58.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:27:58.914+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.528 seconds
[2025-04-14T20:27:59.347+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.342+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.349+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.349+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.351+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.351+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.354+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.353+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.356+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.355+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.358+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.357+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.359+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.358+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.361+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.360+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.362+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.362+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.364+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.363+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:27:59.364+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:27:59.364+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:27:59.366+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": null, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.591056', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.760125', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.772647', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 18:27:58.785502', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["produces", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "schedule_interval": "@daily", "_dag_id": "da ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.797251', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var":  ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.809394', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.simple.Datase ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.821456', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["dataset-time-based-timetable"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.da ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 18:27:58.836155', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 18:27:58.848007', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "timezone": "UTC", "edge_info": {}, "timetable": {"__type": "airflow.timetables.s ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:27:58.859272', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:33:11.972+0200] {processor.py:186} INFO - Started process (PID=13652) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:33:11.974+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:33:11.975+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:11.975+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:33:12.024+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:33:12.434+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.434+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:33:12.459+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.459+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:33:12.463+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.462+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:33:12.464+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.464+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:33:12.466+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.465+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:33:12.467+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.466+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:33:12.468+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.468+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:33:12.469+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.469+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:33:12.471+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.470+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:33:12.474+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.473+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:33:12.475+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:12.475+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:33:12.515+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.548 seconds
[2025-04-14T20:33:13.928+0200] {processor.py:186} INFO - Started process (PID=13665) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:33:13.930+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:33:13.932+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:13.931+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:33:13.994+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:33:14.005+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.005+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:33:14.215+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.215+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:33:14.219+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.218+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:33:14.220+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.220+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:33:14.221+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.220+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:33:14.222+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.221+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:33:14.222+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.222+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:33:14.223+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.223+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:33:14.224+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.224+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:33:14.226+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.226+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:33:14.227+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:33:14.227+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:33:14.253+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.331 seconds
[2025-04-14T20:38:35.672+0200] {processor.py:186} INFO - Started process (PID=21179) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:38:35.674+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:38:35.676+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:35.675+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:38:35.724+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:38:35.959+0200] {processor.py:186} INFO - Started process (PID=21188) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:38:35.960+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:38:35.961+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:35.961+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:38:36.005+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:38:36.071+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.071+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:38:36.088+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.088+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:38:36.090+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.090+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:38:36.092+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.091+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:38:36.092+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.092+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:38:36.093+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.093+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:38:36.094+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.094+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:38:36.095+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.095+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:38:36.096+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.096+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:38:36.098+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.098+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:38:36.099+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.099+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:38:36.126+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.459 seconds
[2025-04-14T20:38:36.241+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.240+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:38:36.259+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.259+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:38:36.262+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.261+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:38:36.262+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.262+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:38:36.263+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.263+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:38:36.264+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.264+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:38:36.265+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.265+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:38:36.266+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.266+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:38:36.267+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.266+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:38:36.269+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.268+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:38:36.270+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.269+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:38:36.417+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.412+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.418+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.417+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.419+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.418+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.421+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.420+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.422+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.421+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.423+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.422+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.424+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.424+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.425+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.425+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.426+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.426+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.428+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.427+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:38:36.429+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:38:36.429+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:38:36.430+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 18:38:36.088584', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T20:43:52.975+0200] {processor.py:186} INFO - Started process (PID=28540) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:43:52.977+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:43:52.979+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:52.979+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:43:53.039+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:43:53.415+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.414+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:43:53.435+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.435+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:43:53.437+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.437+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:43:53.438+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.438+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:43:53.439+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.439+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:43:53.440+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.440+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:43:53.441+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.441+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:43:53.443+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.442+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:43:53.444+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.444+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:43:53.447+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.447+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:43:53.448+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:53.448+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:43:53.482+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.512 seconds
[2025-04-14T20:43:54.610+0200] {processor.py:186} INFO - Started process (PID=28551) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:43:54.611+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:43:54.612+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.612+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:43:54.654+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:43:54.662+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.662+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:43:54.813+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.813+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:43:54.816+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.816+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:43:54.817+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.817+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:43:54.818+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.818+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:43:54.819+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.819+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:43:54.820+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.820+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:43:54.821+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.821+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:43:54.822+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.822+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:43:54.824+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.824+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:43:54.825+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:43:54.825+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:43:54.852+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.247 seconds
[2025-04-14T20:49:06.174+0200] {processor.py:186} INFO - Started process (PID=35822) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:49:06.175+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:49:06.177+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.176+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:49:06.222+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:49:06.552+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.552+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:49:06.570+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.570+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:49:06.573+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.573+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:49:06.574+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.574+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:49:06.575+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.575+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:49:06.575+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.575+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:49:06.576+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.576+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:49:06.577+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.577+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:49:06.578+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.578+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:49:06.580+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.580+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:49:06.581+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:06.581+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:49:06.610+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.442 seconds
[2025-04-14T20:49:07.250+0200] {processor.py:186} INFO - Started process (PID=35831) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:49:07.251+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:49:07.252+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.252+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:49:07.300+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:49:07.315+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.315+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:49:07.501+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.501+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:49:07.504+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.504+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:49:07.505+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.505+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:49:07.506+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.506+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:49:07.508+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.507+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:49:07.509+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.509+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:49:07.510+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.510+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:49:07.511+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.511+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:49:07.514+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.514+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:49:07.515+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:49:07.515+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:49:07.544+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.300 seconds
[2025-04-14T20:54:17.347+0200] {processor.py:186} INFO - Started process (PID=43006) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:54:17.349+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:54:17.351+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.350+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:54:17.405+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:54:17.789+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.789+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:54:17.813+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.812+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:54:17.815+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.815+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:54:17.816+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.816+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:54:17.817+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.817+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:54:17.818+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.818+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:54:17.819+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.819+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:54:17.820+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.820+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:54:17.821+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.821+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:54:17.823+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.823+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:54:17.824+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.824+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:54:17.836+0200] {processor.py:186} INFO - Started process (PID=43097) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:54:17.837+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:54:17.839+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.838+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:54:17.857+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.516 seconds
[2025-04-14T20:54:17.889+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:54:17.899+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:17.899+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:54:18.088+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.088+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:54:18.091+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.091+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:54:18.092+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.092+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:54:18.093+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.093+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:54:18.094+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.094+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:54:18.095+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.095+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:54:18.096+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.096+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:54:18.097+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.097+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:54:18.099+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.099+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:54:18.101+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:54:18.100+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:54:18.128+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.298 seconds
[2025-04-14T20:59:25.912+0200] {processor.py:186} INFO - Started process (PID=50357) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:59:25.914+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:59:25.915+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:25.915+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:59:25.961+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:59:26.306+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.306+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:59:26.328+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.328+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:59:26.330+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.330+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:59:26.332+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.331+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:59:26.332+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.332+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:59:26.333+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.333+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:59:26.334+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.334+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:59:26.335+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.335+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:59:26.336+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.336+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:59:26.338+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.338+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:59:26.339+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:26.339+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:59:26.369+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.462 seconds
[2025-04-14T20:59:27.380+0200] {processor.py:186} INFO - Started process (PID=50359) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:59:27.381+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T20:59:27.382+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.382+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:59:27.423+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T20:59:27.432+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.431+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T20:59:27.583+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.583+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T20:59:27.586+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.586+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:59:27.587+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.587+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T20:59:27.588+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.588+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T20:59:27.589+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.589+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T20:59:27.590+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.590+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T20:59:27.591+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.590+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T20:59:27.591+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.591+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T20:59:27.594+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.593+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T20:59:27.594+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:59:27.594+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T20:59:27.620+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.244 seconds
[2025-04-14T21:04:40.923+0200] {processor.py:186} INFO - Started process (PID=57787) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:04:40.925+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:04:40.927+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:40.926+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:04:40.980+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:04:41.028+0200] {processor.py:186} INFO - Started process (PID=57788) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:04:41.029+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:04:41.030+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.030+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:04:41.081+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:04:41.390+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.389+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:04:41.415+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.415+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:04:41.419+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.419+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:04:41.421+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.421+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:04:41.425+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.422+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:04:41.428+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.427+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:04:41.429+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.429+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:04:41.430+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.430+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:04:41.432+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.431+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:04:41.435+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.435+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:04:41.436+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.436+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:04:41.478+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.561 seconds
[2025-04-14T21:04:41.481+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.480+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:04:41.504+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.503+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:04:41.506+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.506+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:04:41.508+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.507+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:04:41.509+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.509+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:04:41.510+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.510+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:04:41.512+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.512+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:04:41.514+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.513+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:04:41.515+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.515+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:04:41.519+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.519+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:04:41.521+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.521+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:04:41.975+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.973+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.978+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.977+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.980+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.979+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.982+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.982+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.984+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.983+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.985+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.985+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.987+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.986+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.989+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.988+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.992+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.991+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.993+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.992+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:04:41.994+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:04:41.993+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:04:41.995+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "timetable": { ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.170546', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTi ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.348499', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "time ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.364057', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type": "airfl ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:04:41.382830', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "catchup": false, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "ed ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.398408', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "catchup": false, "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:04:41.414288', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_1_and_2", "tags": ["consumes", "dataset-scheduled"], "timetable": {"__type":  ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.436141', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "timetable": {"__typ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:04:41.460805', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:22.729+0200] {processor.py:186} INFO - Started process (PID=65669) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:10:22.731+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:10:22.733+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:22.732+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:10:22.806+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:10:22.837+0200] {processor.py:186} INFO - Started process (PID=65678) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:10:22.838+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:10:22.840+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:22.839+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:10:22.911+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:10:23.294+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.294+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:10:23.323+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.323+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:10:23.326+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.325+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:10:23.327+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.327+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:10:23.329+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.329+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:10:23.330+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.330+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:10:23.331+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.331+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:10:23.332+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.332+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:10:23.334+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.334+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:10:23.337+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.337+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:10:23.339+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.338+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:10:23.382+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.658 seconds
[2025-04-14T21:10:23.384+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.384+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:10:23.414+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.414+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:10:23.418+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.418+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:10:23.419+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.419+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:10:23.421+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.421+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:10:23.422+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.422+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:10:23.424+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.423+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:10:23.425+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.425+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:10:23.427+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.426+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:10:23.430+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.429+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:10:23.431+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.431+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:10:23.781+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.776+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.784+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.783+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.786+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.785+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.788+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.787+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.791+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.790+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.793+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.792+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.795+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.794+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.798+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.797+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.800+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.799+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.802+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.801+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:10:23.803+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:10:23.803+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:10:23.805+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.058563', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.236105', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.253497', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:10:23.270050', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:10:23.288176', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.307854', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:10:23.326442', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.343198', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-pack ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:10:23.361953', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:33.504+0200] {processor.py:186} INFO - Started process (PID=73087) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:15:33.505+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:15:33.506+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.506+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:15:33.551+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:15:33.564+0200] {processor.py:186} INFO - Started process (PID=73088) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:15:33.565+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:15:33.566+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.566+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:15:33.607+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:15:33.868+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.868+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:15:33.885+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.884+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:15:33.887+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.886+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:15:33.888+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.887+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:15:33.888+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.888+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:15:33.889+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.889+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:15:33.890+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.890+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:15:33.891+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:15:33.891+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:15:33.893+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.893+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:15:33.894+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.894+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:15:33.916+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.916+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:15:33.921+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.422 seconds
[2025-04-14T21:15:33.934+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.934+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:15:33.936+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.936+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:15:33.937+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.937+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:15:33.938+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.938+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:15:33.939+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.939+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:15:33.940+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.940+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:15:33.941+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.940+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:15:33.941+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.941+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:15:33.943+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.943+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:15:33.944+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:33.944+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:15:34.220+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.216+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.223+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.222+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.225+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.224+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.228+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.227+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.230+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.229+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.233+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.232+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.234+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.234+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.236+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.235+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.238+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.237+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.239+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.238+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:15:34.240+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:15:34.240+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:15:34.241+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": null, "_dag_id": "dataset_produces_2", "tags": ["produces", "dataset-scheduled"], "fileloc": "/Users/us ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.686745', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "tags": ["dataset-scheduled"], "fileloc": "/Users/user/Documents/lear ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.824519', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.835839', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineer ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:15:33.846995', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Documents/learningProg/d ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:15:33.858072', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"schedule_interval": "@daily", "_dag_id": "dataset_produces_1", "tags": ["produces", "dataset-scheduled"], "fileloc": "/User ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.869059', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "tags": ["consumes", "dataset-scheduled"], "fileloc": "/Users/user/Document ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:15:33.879674', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "tags": ["dataset-time-based-timetable"], "fileloc": "/Users/user ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.890615', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_ ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:15:33.901693', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:32.799+0200] {processor.py:186} INFO - Started process (PID=80349) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:20:32.801+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:20:32.802+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:32.802+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:20:32.848+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:20:32.856+0200] {processor.py:186} INFO - Started process (PID=80350) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:20:32.857+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:20:32.858+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:32.858+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:20:32.898+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:20:33.169+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.168+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:20:33.186+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.186+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:20:33.188+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.188+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:20:33.189+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.189+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:20:33.190+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.189+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:20:33.190+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.190+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:20:33.191+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.191+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:20:33.192+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.192+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:20:33.193+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.193+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:20:33.195+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.194+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:20:33.195+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.195+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:20:33.220+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.220+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:20:33.223+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.428 seconds
[2025-04-14T21:20:33.237+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.237+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:20:33.239+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.239+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:20:33.240+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.240+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:20:33.241+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.241+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:20:33.242+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.241+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:20:33.242+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.242+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:20:33.243+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.243+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:20:33.244+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.244+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:20:33.246+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.246+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:20:33.247+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.247+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:20:33.741+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.738+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.743+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.742+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.746+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.745+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.747+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.747+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.749+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.749+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.751+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.750+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.753+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.752+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.754+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.754+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.756+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.755+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.757+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.757+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:20:33.758+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:20:33.758+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:20:33.759+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-time-based-timetable"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "conditi ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:32.976351', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "dataset_consumes_u ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.116177', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:20:33.127438', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:20:33.138547', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_or_2_with_dataset_expressions", "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.149558', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.161216', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.172051', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["produces", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.182741', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"start_date": 1609459200.0, "edge_info": {}, "_dag_id": "consume_1_and_2_with_dataset_expressions", "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:20:33.193718', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"catchup": false, "tags": ["consumes", "dataset-scheduled"], "start_date": 1609459200.0, "edge_info": {}, "_dag_id": "datase ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:20:33.204701', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:25:57.792+0200] {processor.py:186} INFO - Started process (PID=88029) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:25:57.794+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:25:57.795+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:57.795+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:25:57.853+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:25:58.158+0200] {processor.py:186} INFO - Started process (PID=88130) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:25:58.159+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:25:58.160+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.160+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:25:58.203+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.203+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:25:58.203+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:25:58.221+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.220+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:25:58.223+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.223+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:25:58.224+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.224+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:25:58.225+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.224+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:25:58.225+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.225+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:25:58.226+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.226+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:25:58.227+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.227+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:25:58.228+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.228+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:25:58.230+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.230+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:25:58.231+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.231+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:25:58.256+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.469 seconds
[2025-04-14T21:25:58.301+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.301+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:25:58.377+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.377+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:25:58.380+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.380+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:25:58.381+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.381+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:25:58.382+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.382+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:25:58.383+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.383+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:25:58.384+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.384+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:25:58.385+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.385+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:25:58.386+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.386+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:25:58.388+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.388+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:25:58.389+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:25:58.389+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:25:58.416+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.263 seconds
[2025-04-14T21:31:01.314+0200] {processor.py:186} INFO - Started process (PID=95451) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:31:01.316+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:31:01.318+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.318+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:31:01.383+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:31:01.725+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.724+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:31:01.743+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.742+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:31:01.745+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.745+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:31:01.746+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.746+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:31:01.747+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.747+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:31:01.748+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.748+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:31:01.749+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.748+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:31:01.749+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.749+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:31:01.750+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.750+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:31:01.752+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.752+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:31:01.753+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.753+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:31:01.782+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.473 seconds
[2025-04-14T21:31:01.884+0200] {processor.py:186} INFO - Started process (PID=95452) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:31:01.885+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:31:01.886+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.886+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:31:01.929+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:31:01.938+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:01.938+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:31:02.098+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.098+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:31:02.101+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.101+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:31:02.102+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.101+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:31:02.102+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.102+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:31:02.103+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.103+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:31:02.104+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.104+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:31:02.105+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.105+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:31:02.105+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.105+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:31:02.107+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.107+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:31:02.108+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:31:02.108+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:31:02.132+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.254 seconds
[2025-04-14T21:36:26.129+0200] {processor.py:186} INFO - Started process (PID=3122) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:36:26.131+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:36:26.132+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.132+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:36:26.195+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:36:26.653+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.652+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:36:26.672+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.672+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:36:26.675+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.675+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:36:26.676+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.676+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:36:26.677+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.677+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:36:26.678+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.678+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:36:26.679+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.679+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:36:26.680+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.680+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:36:26.681+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.681+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:36:26.684+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.684+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:36:26.685+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:26.685+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:36:26.718+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.594 seconds
[2025-04-14T21:36:27.499+0200] {processor.py:186} INFO - Started process (PID=3136) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:36:27.500+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:36:27.502+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.501+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:36:27.547+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:36:27.560+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.560+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:36:27.744+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.744+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:36:27.747+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.747+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:36:27.748+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.748+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:36:27.749+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.749+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:36:27.750+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.750+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:36:27.751+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.751+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:36:27.753+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.752+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:36:27.754+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.754+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:36:27.757+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.757+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:36:27.758+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:36:27.758+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:36:27.786+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.293 seconds
[2025-04-14T21:41:24.163+0200] {processor.py:186} INFO - Started process (PID=10458) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:41:24.166+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:41:24.168+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.168+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:41:24.245+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:41:24.517+0200] {processor.py:186} INFO - Started process (PID=10459) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:41:24.518+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:41:24.520+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.519+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:41:24.566+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:41:24.657+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.657+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:41:24.677+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.677+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:41:24.679+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.679+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:41:24.680+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.680+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:41:24.681+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.681+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:41:24.682+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.682+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:41:24.683+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.683+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:41:24.684+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.684+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:41:24.686+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.686+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:41:24.689+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.689+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:41:24.690+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.690+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:41:24.719+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.562 seconds
[2025-04-14T21:41:24.808+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.808+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:41:24.828+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.828+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:41:24.831+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.830+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:41:24.832+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.831+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:41:24.832+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.832+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:41:24.833+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.833+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:41:24.834+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.834+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:41:24.835+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.835+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:41:24.836+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.836+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:41:24.838+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.838+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:41:24.839+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:24.839+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:41:25.226+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.223+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.228+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.227+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.230+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.229+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.232+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.231+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.234+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.233+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.235+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.235+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.237+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.236+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.238+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.237+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.239+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.239+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.241+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.240+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:41:25.241+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:41:25.241+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:41:25.242+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "schedule_interval": null, "timezone": "UTC", "catchup": false, "fileloc": "/Users/user/Documents/learningP ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:41:24.656870', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:34.646+0200] {processor.py:186} INFO - Started process (PID=17909) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:46:34.648+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:46:34.650+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:34.650+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:46:34.706+0200] {processor.py:186} INFO - Started process (PID=17910) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:46:34.707+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:46:34.708+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:34.708+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:46:34.729+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:46:34.767+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:46:35.167+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.167+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:46:35.189+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.189+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:46:35.192+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.191+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:46:35.193+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.193+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:46:35.194+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.194+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:46:35.195+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.195+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:46:35.196+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.196+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:46:35.197+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.197+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:46:35.199+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.198+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:46:35.201+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.201+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:46:35.202+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.202+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:46:35.209+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.208+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:46:35.235+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.235+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:46:35.238+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.238+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:46:35.240+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.239+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:46:35.241+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.241+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:46:35.242+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.602 seconds
[2025-04-14T21:46:35.243+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.243+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:46:35.244+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.244+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:46:35.246+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.246+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:46:35.248+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.247+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:46:35.251+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.251+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:46:35.253+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.253+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:46:35.430+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.428+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.432+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.431+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.433+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.435+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.434+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.437+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.436+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.440+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.439+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.442+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.441+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.445+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.444+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.448+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.447+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.450+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.449+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:46:35.451+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:46:35.451+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:46:35.453+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_both_2_and_3_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/U ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:46:34.884725', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Docume ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.059977', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_unknown_never_scheduled", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.075118', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:46:35.089767', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_and_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_and_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/ ... (2132 characters truncated) ... set", "target": "consume_1_and_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.107205', '5b1a15106642fd032be42633079cf725', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "consume_1_or_2_with_dataset_expressions", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/D ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.121891', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_1", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.149533', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "conditional_dataset_and_time_based_timetable", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/u ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.164214', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_produces_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:46:35.179525', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_dag_id": "dataset_consumes_1_and_2", "edge_info": {}, "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learni ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:46:35.193595', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:51:56.380+0200] {processor.py:186} INFO - Started process (PID=25595) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:51:56.382+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:51:56.384+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.383+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:51:56.434+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:51:56.810+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.810+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:51:56.829+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.828+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:51:56.831+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.831+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:51:56.832+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.832+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:51:56.834+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.834+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:51:56.835+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.835+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:51:56.837+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.836+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:51:56.838+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.838+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:51:56.839+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.839+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:51:56.843+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.842+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:51:56.844+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.844+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:51:56.878+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.503 seconds
[2025-04-14T21:51:56.905+0200] {processor.py:186} INFO - Started process (PID=25607) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:51:56.907+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:51:56.909+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.908+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:51:56.963+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:51:56.974+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:56.974+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:51:57.139+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.138+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:51:57.142+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.142+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:51:57.144+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.144+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:51:57.145+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.145+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:51:57.147+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.147+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:51:57.148+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.148+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:51:57.150+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.150+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:51:57.151+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.151+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:51:57.154+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.154+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:51:57.155+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:51:57.155+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:51:57.185+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.285 seconds
[2025-04-14T21:57:15.728+0200] {processor.py:186} INFO - Started process (PID=33103) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:57:15.730+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:57:15.732+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:15.731+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:57:15.773+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:57:15.847+0200] {processor.py:186} INFO - Started process (PID=33104) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:57:15.848+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-14T21:57:15.849+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:15.848+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:57:15.889+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-14T21:57:16.305+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.305+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:57:16.336+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.336+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:57:16.340+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.340+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:57:16.342+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.342+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:57:16.343+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.343+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:57:16.345+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.345+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:57:16.347+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.346+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:57:16.348+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.348+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:57:16.350+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.350+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:57:16.354+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.353+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:57:16.356+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.355+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:57:16.406+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.406+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:57:16.409+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.686 seconds
[2025-04-14T21:57:16.440+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.440+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-14T21:57:16.444+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.444+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:57:16.446+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.446+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-14T21:57:16.448+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.448+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-14T21:57:16.450+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.449+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-14T21:57:16.452+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.451+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-14T21:57:16.453+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.453+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-14T21:57:16.455+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.455+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-14T21:57:16.459+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.458+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-13 00:00:00+00:00, run_after=2025-04-14 00:00:00+00:00
[2025-04-14T21:57:16.460+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.460+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-14T21:57:16.771+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.769+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.774+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.773+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.776+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.775+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.779+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.778+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.783+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.781+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.786+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.785+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.788+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.787+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.790+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.789+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.793+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.792+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.795+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.794+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:57:16.796+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:57:16.796+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-14T21:57:16.798+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-14 19:57:16.033680', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.297464', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-14 19:57:16.317347', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.336891', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-14 19:57:16.357672', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-14 19:57:16.379783', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
