[2025-04-14T18:23:04.044+0200] {processor.py:186} INFO - Started process (PID=31115) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:23:04.045+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:23:04.047+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.047+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:23:04.395+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:23:04.541+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.540+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T18:23:04.555+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.554+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T18:23:04.565+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.565+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T18:23:04.578+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.578+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T18:23:04.588+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.588+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T18:23:04.597+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.597+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T18:23:04.609+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.609+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T18:23:04.627+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.627+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T18:23:04.636+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.636+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T18:23:04.645+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.645+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T18:23:04.657+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.656+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T18:23:04.664+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.663+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T18:23:04.671+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.671+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T18:23:04.678+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.678+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T18:23:04.699+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.699+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T18:23:04.710+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.709+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T18:23:04.717+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.717+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T18:23:04.727+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.727+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T18:23:04.736+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.736+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T18:23:04.745+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.745+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T18:23:04.752+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.752+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T18:23:04.766+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.766+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T18:23:04.774+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.773+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T18:23:04.781+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.781+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T18:23:04.793+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.792+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T18:23:04.799+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.799+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T18:23:04.808+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.807+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T18:23:04.816+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.816+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T18:23:04.817+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.816+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:23:04.829+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.829+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T18:23:04.830+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.830+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T18:23:04.831+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.831+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T18:23:04.831+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.831+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T18:23:04.841+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.841+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:23:04.842+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.842+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:23:04.843+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.843+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:23:04.844+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:04.844+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:23:05.417+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 1.380 seconds
[2025-04-14T18:23:43.968+0200] {processor.py:186} INFO - Started process (PID=32188) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:23:43.970+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:23:43.972+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:43.972+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:23:44.310+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:23:44.347+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:44.347+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:23:44.392+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:44.391+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:23:44.407+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:44.407+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:23:44.409+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:44.409+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:23:44.411+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:23:44.410+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:23:44.444+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.482 seconds
[2025-04-14T18:24:46.959+0200] {processor.py:186} INFO - Started process (PID=33797) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:24:46.962+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:24:46.964+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:46.963+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:24:47.298+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:24:47.336+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:47.336+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:24:47.362+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:47.362+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:24:47.366+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:47.365+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:24:47.367+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:47.367+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:24:47.369+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:24:47.369+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:24:47.404+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.450 seconds
[2025-04-14T18:27:04.574+0200] {processor.py:186} INFO - Started process (PID=37275) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:27:04.575+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:27:04.577+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:04.576+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:27:04.797+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:27:04.824+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:04.823+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:27:04.843+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:04.842+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:04.845+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:04.845+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:04.846+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:04.846+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:04.847+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:04.847+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:04.874+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.305 seconds
[2025-04-14T18:27:05.003+0200] {processor.py:186} INFO - Started process (PID=37277) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:27:05.004+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:27:05.005+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:05.005+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:27:05.258+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:27:05.288+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:05.288+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:27:05.309+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:05.309+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:05.312+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:05.312+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:05.314+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:05.313+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:05.315+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:05.315+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:05.347+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.350 seconds
[2025-04-14T18:27:43.852+0200] {processor.py:186} INFO - Started process (PID=39413) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:27:43.855+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:27:43.857+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:43.856+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:27:44.184+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:27:44.213+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:44.213+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:27:44.231+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:44.231+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:44.234+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:44.234+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:44.236+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:44.235+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:44.237+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:27:44.237+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:27:44.267+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.422 seconds
[2025-04-14T18:28:37.065+0200] {processor.py:186} INFO - Started process (PID=40738) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:28:37.066+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:28:37.068+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:37.067+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:28:37.286+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:28:37.309+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:37.309+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:28:37.327+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:37.327+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:28:37.329+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:37.329+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:28:37.330+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:37.330+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:28:37.331+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:28:37.331+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:28:37.352+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.293 seconds
[2025-04-14T18:30:51.815+0200] {processor.py:186} INFO - Started process (PID=44765) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:30:51.816+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:30:51.818+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:51.818+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:30:52.076+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:30:52.101+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:52.101+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:30:52.127+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:52.126+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:30:52.129+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:52.129+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:30:52.130+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:52.130+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:30:52.131+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:30:52.131+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:30:52.159+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.351 seconds
[2025-04-14T18:33:46.224+0200] {processor.py:186} INFO - Started process (PID=48686) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:33:46.225+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:33:46.227+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:46.227+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:33:46.563+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:33:46.601+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:46.601+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:33:46.628+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:46.628+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:33:46.632+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:46.632+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:33:46.634+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:46.633+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:33:46.635+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:33:46.635+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:33:46.672+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.455 seconds
[2025-04-14T18:34:15.157+0200] {processor.py:186} INFO - Started process (PID=49379) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:34:15.159+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:34:15.161+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:15.161+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:34:15.523+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:34:15.560+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:15.560+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:34:15.589+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:15.589+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:34:15.593+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:15.593+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:34:15.595+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:15.594+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:34:15.596+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:34:15.596+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:34:15.631+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.482 seconds
[2025-04-14T18:35:36.050+0200] {processor.py:186} INFO - Started process (PID=50897) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:35:36.052+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:35:36.054+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:36.054+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:35:36.773+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:35:36.815+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:36.815+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:35:36.873+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:36.873+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:35:36.876+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:36.876+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:35:36.878+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:36.878+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:35:36.880+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:35:36.879+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:35:36.968+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.924 seconds
[2025-04-14T18:36:37.907+0200] {processor.py:186} INFO - Started process (PID=52106) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:36:37.909+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:36:37.911+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:37.911+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:36:38.237+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:36:38.270+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:38.269+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:36:38.297+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:38.297+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:36:38.301+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:38.300+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:36:38.302+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:38.302+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:36:38.304+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:36:38.304+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:36:38.341+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.440 seconds
[2025-04-14T18:38:24.845+0200] {processor.py:186} INFO - Started process (PID=55021) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:38:24.847+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:38:24.849+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:24.848+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:38:25.147+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:38:25.184+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:25.184+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:38:25.212+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:25.212+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:38:25.231+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:25.231+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:38:25.232+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:25.232+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:38:25.233+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:38:25.233+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:38:25.341+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.502 seconds
[2025-04-14T18:42:13.971+0200] {processor.py:186} INFO - Started process (PID=61439) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:42:13.973+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:42:13.975+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:13.975+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:42:14.327+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:42:14.399+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:14.399+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:42:14.431+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:14.431+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:14.435+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:14.435+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:14.437+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:14.437+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:14.439+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:14.438+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:14.482+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.517 seconds
[2025-04-14T18:42:16.159+0200] {processor.py:186} INFO - Started process (PID=61493) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:42:16.161+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:42:16.163+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:16.163+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:42:16.528+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:42:16.561+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:16.560+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:42:16.588+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:16.588+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:16.592+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:16.591+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:16.593+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:16.593+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:16.595+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:16.595+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:16.629+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.478 seconds
[2025-04-14T18:42:38.709+0200] {processor.py:186} INFO - Started process (PID=62076) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:42:38.711+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:42:38.713+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:38.713+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:42:39.224+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:42:39.261+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:39.261+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:42:39.297+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:39.296+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:39.300+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:39.300+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:39.302+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:39.302+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:39.304+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:42:39.303+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:42:39.332+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.628 seconds
[2025-04-14T18:44:00.083+0200] {processor.py:186} INFO - Started process (PID=63937) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:44:00.085+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:44:00.088+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:00.087+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:44:00.558+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:44:00.599+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:00.599+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:44:00.630+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:00.629+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:44:00.633+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:00.633+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:44:00.635+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:00.635+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:44:00.636+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:44:00.636+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:44:00.669+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.593 seconds
[2025-04-14T18:46:52.505+0200] {processor.py:186} INFO - Started process (PID=68137) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:46:52.507+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:46:52.509+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:52.509+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:46:52.734+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:46:52.759+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:52.759+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:46:52.777+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:52.777+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:46:52.779+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:52.779+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:46:52.781+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:52.780+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:46:52.782+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:52.781+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:46:52.804+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.305 seconds
[2025-04-14T18:46:55.045+0200] {processor.py:186} INFO - Started process (PID=68162) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:46:55.047+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:46:55.049+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:55.048+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:46:55.366+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:46:55.401+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:55.400+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:46:55.427+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:55.427+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:46:55.431+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:55.430+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:46:55.432+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:55.432+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:46:55.434+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:46:55.434+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:46:55.462+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.424 seconds
[2025-04-14T18:50:25.399+0200] {processor.py:186} INFO - Started process (PID=72946) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:50:25.401+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:50:25.403+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:25.402+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:50:25.696+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:50:25.931+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:25.931+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:50:25.957+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:25.957+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:50:25.961+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:25.960+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:50:25.962+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:25.962+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:50:25.964+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:25.964+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:50:26.003+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.611 seconds
[2025-04-14T18:50:38.578+0200] {processor.py:186} INFO - Started process (PID=73416) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:50:38.579+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:50:38.580+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.580+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:50:38.781+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:50:38.786+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.786+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:50:38.803+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.803+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:50:38.805+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.805+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:50:38.806+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.806+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:50:38.807+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:50:38.807+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:50:38.828+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.257 seconds
[2025-04-14T18:51:44.554+0200] {processor.py:186} INFO - Started process (PID=74840) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:51:44.556+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:51:44.558+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:44.558+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:51:44.840+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:51:44.873+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:44.872+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:51:44.900+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:44.900+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:51:44.904+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:44.903+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:51:44.905+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:44.905+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:51:44.907+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:51:44.907+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:51:44.937+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.389 seconds
[2025-04-14T18:53:44.173+0200] {processor.py:186} INFO - Started process (PID=77661) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:53:44.175+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:53:44.176+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:44.176+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:53:44.471+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:53:44.726+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:44.725+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:53:44.746+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:44.746+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:53:44.748+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:44.748+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:53:44.750+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:44.749+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:53:44.750+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:53:44.750+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:53:44.777+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.610 seconds
[2025-04-14T18:57:24.398+0200] {processor.py:186} INFO - Started process (PID=82079) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:57:24.400+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:57:24.402+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:24.402+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:57:24.757+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:57:24.801+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:24.801+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:57:24.833+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:24.832+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:57:24.837+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:24.836+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:57:24.839+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:24.839+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:57:24.841+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:24.840+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:57:24.879+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.489 seconds
[2025-04-14T18:57:26.423+0200] {processor.py:186} INFO - Started process (PID=82091) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:57:26.425+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:57:26.427+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:26.427+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:57:26.837+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:57:26.876+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:26.876+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:57:26.906+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:26.906+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:57:26.910+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:26.910+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:57:26.912+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:26.912+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:57:26.914+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:57:26.913+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:57:26.950+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.534 seconds
[2025-04-14T18:59:10.250+0200] {processor.py:186} INFO - Started process (PID=84452) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:59:10.252+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T18:59:10.253+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:10.253+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:59:10.671+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T18:59:10.954+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:10.953+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T18:59:10.980+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:10.980+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:59:10.983+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:10.983+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:59:10.985+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:10.984+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T18:59:10.986+0200] {logging_mixin.py:190} INFO - [2025-04-14T18:59:10.986+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T18:59:11.020+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.777 seconds
[2025-04-14T19:01:44.598+0200] {processor.py:186} INFO - Started process (PID=87601) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:01:44.600+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:01:44.602+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:44.602+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:01:44.996+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:01:45.038+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:45.038+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:01:45.072+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:45.071+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:01:45.077+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:45.077+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:01:45.080+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:45.079+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:01:45.081+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:01:45.081+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:01:45.115+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.523 seconds
[2025-04-14T19:04:59.481+0200] {processor.py:186} INFO - Started process (PID=91853) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:04:59.483+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:04:59.485+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:59.485+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:04:59.778+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:04:59.989+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:04:59.989+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:05:00.017+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.016+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:05:00.020+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.020+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:05:00.021+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.021+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:05:00.023+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.023+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:05:00.055+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.581 seconds
[2025-04-14T19:05:00.115+0200] {processor.py:186} INFO - Started process (PID=91857) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:05:00.116+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:05:00.118+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.118+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:05:00.445+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:05:00.453+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.452+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:05:00.482+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.481+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:05:00.485+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.485+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:05:00.487+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.486+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:05:00.488+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:05:00.488+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:05:00.521+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.413 seconds
[2025-04-14T19:06:48.400+0200] {processor.py:186} INFO - Started process (PID=94882) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:06:48.402+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:06:48.403+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.403+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:06:48.643+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:06:48.756+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.756+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T19:06:48.766+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.766+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T19:06:48.774+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.774+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T19:06:48.784+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.784+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T19:06:48.793+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.792+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T19:06:48.800+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.799+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T19:06:48.807+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.806+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T19:06:48.821+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.821+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T19:06:48.828+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.828+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T19:06:48.836+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.835+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T19:06:48.848+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.848+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T19:06:48.856+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.855+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T19:06:48.863+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.862+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T19:06:48.869+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.869+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T19:06:48.888+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.888+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T19:06:48.897+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.897+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T19:06:48.904+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.904+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T19:06:48.915+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.915+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T19:06:48.922+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.922+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T19:06:48.931+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.931+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T19:06:48.941+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.940+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T19:06:48.954+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.954+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T19:06:48.961+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.961+0200] {override.py:1930} INFO - Created Permission View: can edit on DAG:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T19:06:48.968+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.968+0200] {override.py:1930} INFO - Created Permission View: can read on DAG:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T19:06:48.980+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.980+0200] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T19:06:48.990+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.989+0200] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T19:06:48.997+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:48.997+0200] {override.py:1930} INFO - Created Permission View: can read on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T19:06:49.006+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.006+0200] {override.py:1930} INFO - Created Permission View: can create on DAG Run:dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T19:06:49.007+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.006+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:06:49.026+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.025+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_consumer_with_no_taskflow
[2025-04-14T19:06:49.027+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.026+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_consumer_with_no_taskflow
[2025-04-14T19:06:49.028+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.028+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_s3_bucket_producer_with_no_taskflow
[2025-04-14T19:06:49.029+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.029+0200] {dag.py:3262} INFO - Creating ORM DAG for dataset_alias_example_alias_producer_with_no_taskflow
[2025-04-14T19:06:49.041+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.041+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:06:49.042+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.042+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:06:49.043+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.043+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:06:49.044+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:06:49.044+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:06:49.093+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.699 seconds
[2025-04-14T19:08:52.062+0200] {processor.py:186} INFO - Started process (PID=98513) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:08:52.064+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:08:52.065+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:52.065+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:08:52.338+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:08:52.373+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:52.373+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:08:52.401+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:52.400+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:08:52.404+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:52.404+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:08:52.406+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:52.406+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:08:52.407+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:08:52.407+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:08:52.440+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.384 seconds
[2025-04-14T19:12:59.247+0200] {processor.py:186} INFO - Started process (PID=4893) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:12:59.249+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:12:59.251+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:59.250+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:12:59.563+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:12:59.675+0200] {processor.py:186} INFO - Started process (PID=4941) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:12:59.676+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:12:59.678+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:59.678+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:12:59.764+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:59.764+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:12:59.789+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:59.788+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:12:59.792+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:59.792+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:12:59.794+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:59.793+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:12:59.795+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:59.795+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:12:59.825+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.585 seconds
[2025-04-14T19:12:59.966+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:12:59.974+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:59.974+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:12:59.999+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:12:59.999+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:13:00.003+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:00.002+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:13:00.004+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:00.004+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:13:00.006+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:13:00.005+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:13:00.039+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.370 seconds
[2025-04-14T19:14:58.109+0200] {processor.py:186} INFO - Started process (PID=7607) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:14:58.112+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:14:58.114+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:58.113+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:14:58.491+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:14:58.760+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:58.760+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:14:58.805+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:58.805+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:14:58.809+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:58.808+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:14:58.816+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:58.815+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:14:58.817+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:14:58.817+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:14:58.863+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.760 seconds
[2025-04-14T19:16:40.490+0200] {processor.py:186} INFO - Started process (PID=9922) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:16:40.493+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:16:40.495+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:40.494+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:16:40.807+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:16:40.839+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:40.839+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:16:40.860+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:40.859+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:16:40.862+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:40.862+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:16:40.864+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:40.864+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:16:40.865+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:16:40.865+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:16:40.893+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.409 seconds
[2025-04-14T19:21:42.002+0200] {processor.py:186} INFO - Started process (PID=16879) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:21:42.003+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:21:42.005+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:42.004+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:21:42.209+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:21:42.354+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:42.354+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:21:42.375+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:42.375+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:21:42.378+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:42.378+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:21:42.379+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:42.379+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:21:42.380+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:21:42.380+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:21:42.402+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.406 seconds
[2025-04-14T19:23:09.614+0200] {processor.py:186} INFO - Started process (PID=18645) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:23:09.616+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:23:09.617+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:09.617+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:23:09.861+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:23:09.890+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:09.889+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:23:09.912+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:09.912+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:23:09.915+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:09.915+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:23:09.916+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:09.916+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:23:09.917+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:23:09.917+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:23:09.945+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.336 seconds
[2025-04-14T19:28:16.797+0200] {processor.py:186} INFO - Started process (PID=25385) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:28:16.799+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:28:16.801+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:16.801+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:28:17.105+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:28:17.294+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:17.293+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:28:17.316+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:17.316+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:28:17.320+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:17.320+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:28:17.321+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:17.321+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:28:17.323+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:28:17.323+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:28:17.352+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.561 seconds
[2025-04-14T19:29:54.327+0200] {processor.py:186} INFO - Started process (PID=27569) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:29:54.329+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:29:54.330+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:54.330+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:29:54.578+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:29:54.736+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:54.735+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:29:54.754+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:54.754+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:29:54.756+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:54.756+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:29:54.757+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:54.757+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:29:54.758+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:29:54.758+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:29:54.782+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.460 seconds
[2025-04-14T19:34:47.388+0200] {processor.py:186} INFO - Started process (PID=34239) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:34:47.390+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:34:47.391+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:47.391+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:34:47.653+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:34:47.844+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:47.844+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:34:47.862+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:47.862+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:34:47.866+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:47.865+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:34:47.867+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:47.867+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:34:47.868+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:34:47.868+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:34:47.894+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.512 seconds
[2025-04-14T19:36:07.348+0200] {processor.py:186} INFO - Started process (PID=35762) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:36:07.350+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:36:07.351+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:07.351+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:36:07.600+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:36:07.627+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:07.627+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:36:07.646+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:07.646+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:36:07.649+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:07.649+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:36:07.650+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:07.650+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:36:07.651+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:36:07.651+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:36:07.677+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.335 seconds
[2025-04-14T19:41:44.018+0200] {processor.py:186} INFO - Started process (PID=42978) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:41:44.019+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:41:44.021+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:44.020+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:41:44.276+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:41:44.439+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:44.438+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:41:44.457+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:44.457+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:41:44.460+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:44.459+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:41:44.461+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:44.460+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:41:44.462+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:41:44.462+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:41:44.489+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.477 seconds
[2025-04-14T19:42:43.338+0200] {processor.py:186} INFO - Started process (PID=44371) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:42:43.340+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:42:43.341+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:43.341+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:42:43.585+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:42:43.609+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:43.609+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:42:43.627+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:43.627+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:42:43.629+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:43.629+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:42:43.630+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:43.630+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:42:43.631+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:42:43.631+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:42:43.652+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.321 seconds
[2025-04-14T19:47:50.317+0200] {processor.py:186} INFO - Started process (PID=51391) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:47:50.319+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:47:50.321+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:50.320+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:47:50.550+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:47:50.718+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:50.717+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:47:50.739+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:50.738+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:47:50.741+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:50.741+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:47:50.742+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:50.742+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:47:50.744+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:47:50.743+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:47:50.770+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.459 seconds
[2025-04-14T19:48:45.662+0200] {processor.py:186} INFO - Started process (PID=52852) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:48:45.663+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:48:45.665+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:45.665+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:48:45.923+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:48:45.948+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:45.948+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:48:45.967+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:45.967+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:48:45.970+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:45.969+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:48:45.971+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:45.971+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:48:45.972+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:48:45.972+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:48:45.995+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.339 seconds
[2025-04-14T19:53:55.526+0200] {processor.py:186} INFO - Started process (PID=59931) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:53:55.528+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:53:55.529+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:55.529+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:53:55.781+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:53:55.958+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:55.957+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:53:55.977+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:55.977+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:53:55.979+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:55.979+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:53:55.980+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:55.980+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:53:55.981+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:53:55.981+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:53:56.006+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.486 seconds
[2025-04-14T19:54:55.249+0200] {processor.py:186} INFO - Started process (PID=61327) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:54:55.251+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T19:54:55.253+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:55.253+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:54:55.523+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T19:54:55.682+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:55.682+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T19:54:55.700+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:55.700+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:54:55.703+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:55.702+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:54:55.704+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:55.703+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T19:54:55.705+0200] {logging_mixin.py:190} INFO - [2025-04-14T19:54:55.704+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T19:54:55.726+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.484 seconds
[2025-04-14T20:00:07.353+0200] {processor.py:186} INFO - Started process (PID=68577) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:00:07.356+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:00:07.358+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:07.357+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:00:07.709+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:00:07.958+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:07.957+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:00:07.987+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:07.987+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:00:07.991+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:07.991+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:00:07.992+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:07.992+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:00:07.994+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:00:07.994+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:00:08.030+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.684 seconds
[2025-04-14T20:01:02.266+0200] {processor.py:186} INFO - Started process (PID=69674) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:01:02.268+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:01:02.270+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:02.269+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:01:02.520+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:01:02.544+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:02.544+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:01:02.565+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:02.565+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:01:02.568+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:02.567+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:01:02.569+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:02.569+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:01:02.570+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:01:02.570+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:01:02.593+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.334 seconds
[2025-04-14T20:06:50.854+0200] {processor.py:186} INFO - Started process (PID=77413) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:06:50.856+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:06:50.857+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:50.857+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:06:51.133+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:06:51.360+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:51.360+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:06:51.385+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:51.384+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:06:51.387+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:51.387+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:06:51.389+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:51.389+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:06:51.390+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:06:51.390+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:06:51.423+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.575 seconds
[2025-04-14T20:07:21.734+0200] {processor.py:186} INFO - Started process (PID=78162) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:07:21.736+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:07:21.738+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:21.738+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:07:22.056+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:07:22.087+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:22.087+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:07:22.108+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:22.108+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:07:22.111+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:22.111+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:07:22.113+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:22.113+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:07:22.114+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:07:22.114+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:07:22.145+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.418 seconds
[2025-04-14T20:12:56.278+0200] {processor.py:186} INFO - Started process (PID=85558) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:12:56.280+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:12:56.281+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:56.281+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:12:56.472+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:12:56.605+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:56.605+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:12:56.620+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:56.620+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:12:56.622+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:56.621+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:12:56.622+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:56.622+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:12:56.623+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:12:56.623+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:12:56.645+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.372 seconds
[2025-04-14T20:13:18.042+0200] {processor.py:186} INFO - Started process (PID=86078) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:13:18.044+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:13:18.045+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:18.045+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:13:18.310+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:13:18.315+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:18.315+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:13:18.335+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:18.335+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:13:18.338+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:18.337+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:13:18.339+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:18.339+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:13:18.340+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:13:18.340+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:13:18.362+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.326 seconds
[2025-04-14T20:18:48.503+0200] {processor.py:186} INFO - Started process (PID=93407) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:18:48.505+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:18:48.506+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:48.506+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:18:48.704+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:18:48.842+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:48.842+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:18:48.858+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:48.858+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:18:48.860+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:48.860+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:18:48.861+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:48.861+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:18:48.862+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:18:48.862+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:18:48.881+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.384 seconds
[2025-04-14T20:19:10.831+0200] {processor.py:186} INFO - Started process (PID=93919) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:19:10.833+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:19:10.834+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:10.834+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:19:11.046+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:19:11.051+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:11.050+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:19:11.071+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:11.070+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:19:11.074+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:11.073+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:19:11.075+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:11.075+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:19:11.077+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:19:11.077+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:19:11.103+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.278 seconds
[2025-04-14T20:24:59.351+0200] {processor.py:186} INFO - Started process (PID=2144) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:24:59.352+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:24:59.353+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:24:59.353+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:24:59.603+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:24:59.778+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:24:59.778+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:24:59.800+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:24:59.800+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:24:59.802+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:24:59.802+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:24:59.803+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:24:59.803+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:24:59.804+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:24:59.804+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:24:59.886+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.543 seconds
[2025-04-14T20:25:07.246+0200] {processor.py:186} INFO - Started process (PID=2385) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:25:07.248+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:25:07.250+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:07.250+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:25:07.475+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:25:07.483+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:07.483+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:25:07.509+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:07.508+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:25:07.512+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:07.512+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:25:07.513+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:07.513+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:25:07.514+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:25:07.514+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:25:07.536+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.296 seconds
[2025-04-14T20:30:39.264+0200] {processor.py:186} INFO - Started process (PID=10045) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:30:39.266+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:30:39.267+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:39.267+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:30:39.521+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:30:39.669+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:39.669+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:30:39.687+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:39.687+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:30:39.689+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:39.689+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:30:39.690+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:39.690+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:30:39.691+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:39.691+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:30:39.715+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.457 seconds
[2025-04-14T20:30:40.196+0200] {processor.py:186} INFO - Started process (PID=10151) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:30:40.197+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:30:40.198+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:40.198+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:30:40.390+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:30:40.395+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:40.394+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:30:40.411+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:40.411+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:30:40.413+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:40.413+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:30:40.414+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:40.414+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:30:40.415+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:30:40.415+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:30:40.436+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.246 seconds
[2025-04-14T20:35:53.845+0200] {processor.py:186} INFO - Started process (PID=17532) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:35:53.847+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:35:53.848+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:53.848+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:35:54.038+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:35:54.175+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:54.174+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:35:54.189+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:54.189+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:35:54.191+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:54.191+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:35:54.192+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:54.192+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:35:54.193+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:54.193+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:35:54.211+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.371 seconds
[2025-04-14T20:35:55.710+0200] {processor.py:186} INFO - Started process (PID=17543) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:35:55.711+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:35:55.712+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:55.712+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:35:55.911+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:35:55.916+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:55.916+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:35:55.932+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:55.932+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:35:55.934+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:55.934+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:35:55.935+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:55.935+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:35:55.936+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:35:55.936+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:35:55.958+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.252 seconds
[2025-04-14T20:41:12.979+0200] {processor.py:186} INFO - Started process (PID=24828) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:41:12.982+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:41:12.983+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:12.983+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:41:13.190+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:41:13.324+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:13.324+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:41:13.340+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:13.339+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:41:13.342+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:13.341+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:41:13.343+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:13.342+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:41:13.344+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:13.344+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:41:13.363+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.389 seconds
[2025-04-14T20:41:15.723+0200] {processor.py:186} INFO - Started process (PID=24840) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:41:15.724+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:41:15.726+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:15.725+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:41:15.958+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:41:15.963+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:15.963+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:41:15.984+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:15.984+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:41:15.986+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:15.986+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:41:15.987+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:15.987+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:41:15.990+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:41:15.989+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:41:16.013+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.296 seconds
[2025-04-14T20:46:30.347+0200] {processor.py:186} INFO - Started process (PID=32180) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:46:30.349+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:46:30.350+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:30.350+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:46:30.546+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:46:30.678+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:30.678+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:46:30.695+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:30.694+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:46:30.697+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:30.697+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:46:30.698+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:30.698+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:46:30.699+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:30.699+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:46:30.719+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.378 seconds
[2025-04-14T20:46:31.089+0200] {processor.py:186} INFO - Started process (PID=32285) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:46:31.090+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:46:31.091+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:31.091+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:46:31.273+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:46:31.277+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:31.277+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:46:31.292+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:31.292+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:46:31.294+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:31.293+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:46:31.294+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:31.294+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:46:31.295+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:46:31.295+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:46:31.313+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.229 seconds
[2025-04-14T20:51:43.813+0200] {processor.py:186} INFO - Started process (PID=39585) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:51:43.815+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:51:43.816+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:43.816+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:51:44.011+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:51:44.164+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:44.163+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:51:44.180+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:44.180+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:51:44.182+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:44.182+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:51:44.183+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:44.183+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:51:44.184+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:44.184+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:51:44.206+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.399 seconds
[2025-04-14T20:51:45.864+0200] {processor.py:186} INFO - Started process (PID=39597) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:51:45.865+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:51:45.867+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:45.866+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:51:46.049+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:51:46.053+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:46.053+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:51:46.069+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:46.068+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:51:46.070+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:46.070+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:51:46.071+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:46.071+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:51:46.072+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:51:46.072+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:51:46.090+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.231 seconds
[2025-04-14T20:56:52.523+0200] {processor.py:186} INFO - Started process (PID=46725) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:56:52.524+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:56:52.526+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:52.525+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:56:52.757+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:56:52.944+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:52.943+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:56:52.964+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:52.964+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:56:52.966+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:52.966+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:56:52.967+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:52.967+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:56:52.968+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:52.968+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:56:52.993+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.476 seconds
[2025-04-14T20:56:56.199+0200] {processor.py:186} INFO - Started process (PID=46748) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:56:56.201+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T20:56:56.203+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.202+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:56:56.469+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T20:56:56.474+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.474+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T20:56:56.492+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.491+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:56:56.494+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.493+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:56:56.495+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.494+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T20:56:56.496+0200] {logging_mixin.py:190} INFO - [2025-04-14T20:56:56.495+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T20:56:56.517+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.325 seconds
[2025-04-14T21:02:02.793+0200] {processor.py:186} INFO - Started process (PID=54069) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:02:02.795+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:02:02.796+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:02.796+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:02:02.984+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:02:03.126+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.125+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:02:03.149+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.148+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:02:03.151+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.150+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:02:03.152+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.151+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:02:03.153+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.153+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:02:03.176+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.388 seconds
[2025-04-14T21:02:03.612+0200] {processor.py:186} INFO - Started process (PID=54070) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:02:03.613+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:02:03.614+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.614+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:02:03.800+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:02:03.805+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.805+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:02:03.822+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.822+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:02:03.824+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.824+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:02:03.825+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.825+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:02:03.826+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:02:03.826+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:02:03.844+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.236 seconds
[2025-04-14T21:07:25.986+0200] {processor.py:186} INFO - Started process (PID=61727) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:07:25.988+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:07:25.990+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:25.989+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:07:26.219+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:07:26.391+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.391+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:07:26.413+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.412+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:07:26.415+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.415+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:07:26.417+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.416+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:07:26.418+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.418+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:07:26.445+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.465 seconds
[2025-04-14T21:07:26.593+0200] {processor.py:186} INFO - Started process (PID=61728) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:07:26.595+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:07:26.597+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.596+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:07:26.821+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:07:26.826+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.826+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:07:26.844+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.843+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:07:26.846+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.846+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:07:26.847+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.847+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:07:26.849+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:07:26.848+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:07:26.869+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.282 seconds
[2025-04-14T21:13:07.079+0200] {processor.py:186} INFO - Started process (PID=69530) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:13:07.080+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:13:07.082+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:07.082+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:13:07.322+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:13:07.515+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:07.514+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:13:07.531+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:07.530+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:13:07.533+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:07.533+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:13:07.534+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:07.534+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:13:07.535+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:07.535+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:13:07.559+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.486 seconds
[2025-04-14T21:13:08.536+0200] {processor.py:186} INFO - Started process (PID=69536) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:13:08.537+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:13:08.539+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:08.539+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:13:08.757+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:13:08.763+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:08.763+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:13:08.782+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:08.782+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:13:08.784+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:08.784+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:13:08.785+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:08.785+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:13:08.786+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:13:08.786+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:13:08.809+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.279 seconds
[2025-04-14T21:18:08.961+0200] {processor.py:186} INFO - Started process (PID=76805) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:18:08.962+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:18:08.964+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:08.963+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:18:09.165+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:18:09.259+0200] {processor.py:186} INFO - Started process (PID=76808) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:18:09.260+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:18:09.261+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.261+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:18:09.322+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.322+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:18:09.338+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.337+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:18:09.340+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.340+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:18:09.341+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.341+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:18:09.342+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.342+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:18:09.364+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.408 seconds
[2025-04-14T21:18:09.470+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:18:09.475+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.475+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:18:09.492+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.492+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:18:09.494+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.494+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:18:09.495+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.495+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:18:09.496+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:18:09.495+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:18:09.514+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.261 seconds
[2025-04-14T21:23:14.106+0200] {processor.py:186} INFO - Started process (PID=84358) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:23:14.108+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:23:14.110+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.109+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:23:14.342+0200] {processor.py:186} INFO - Started process (PID=84359) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:23:14.344+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:23:14.346+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.346+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:23:14.415+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:23:14.623+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:23:14.631+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.631+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:23:14.656+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.655+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:23:14.659+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.659+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:23:14.660+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.660+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:23:14.662+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.662+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:23:14.688+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.588 seconds
[2025-04-14T21:23:14.767+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.766+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:23:14.795+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.794+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:23:14.798+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.798+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:23:14.799+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.799+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:23:14.801+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:14.801+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:23:15.139+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:15.135+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "_dag_id": "dataset_alias_example_alias_producer_with_no_taskflow", "tags": ["producer", "dataset-alias"],  ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:23:14.631506', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:23:15.142+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:15.141+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "_dag_id": "dataset_alias_example_alias_producer_with_no_taskflow", "tags": ["producer", "dataset-alias"],  ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:23:14.631506', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:23:15.145+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:15.144+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "_dag_id": "dataset_alias_example_alias_producer_with_no_taskflow", "tags": ["producer", "dataset-alias"],  ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:23:14.631506', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:23:15.148+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:15.146+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "_dag_id": "dataset_alias_example_alias_producer_with_no_taskflow", "tags": ["producer", "dataset-alias"],  ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:23:14.631506', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:23:15.148+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:23:15.148+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:23:15.150+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "_dag_id": "dataset_alias_example_alias_producer_with_no_taskflow", "tags": ["producer", "dataset-alias"],  ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:23:14.631506', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:28:35.018+0200] {processor.py:186} INFO - Started process (PID=91768) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:28:35.020+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:28:35.021+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.021+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:28:35.203+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:28:35.334+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.333+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:28:35.349+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.349+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:28:35.351+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.351+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:28:35.352+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.352+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:28:35.352+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.352+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:28:35.373+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.360 seconds
[2025-04-14T21:28:35.401+0200] {processor.py:186} INFO - Started process (PID=91777) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:28:35.402+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:28:35.404+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.403+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:28:35.598+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:28:35.603+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.603+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:28:35.622+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.621+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:28:35.624+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.624+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:28:35.625+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.625+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:28:35.626+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:28:35.626+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:28:35.649+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.253 seconds
[2025-04-14T21:33:42.133+0200] {processor.py:186} INFO - Started process (PID=99042) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:33:42.135+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:33:42.137+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.136+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:33:42.207+0200] {processor.py:186} INFO - Started process (PID=99044) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:33:42.208+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:33:42.210+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.210+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:33:42.492+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:33:42.528+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:33:42.708+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.707+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:33:42.713+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.687+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.IntegrityError: UNIQUE constraint failed: serialized_dag.dag_id

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1660, in serialize_dag
    dag_deps = [
               ^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1663, in <listcomp>
    for dep in SerializedBaseOperator.detect_dependencies(task)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1465, in detect_dependencies
    deps = set(dependency_detector.detect_task_dependencies(op))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1059, in detect_task_dependencies
    cond = _DatasetAliasCondition(obj.name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/datasets/__init__.py", line 393, in __init__
    self.objects = expand_alias_to_datasets(name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 96, in wrapper
    with create_session() as session:
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 57, in create_session
    session.commit()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 832, in commit
    self._prepare_impl()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 811, in _prepare_impl
    self.session.flush()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3449, in flush
    self._flush(objects)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3588, in _flush
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 3549, in _flush
    flush_context.execute()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 456, in execute
    rec.execute(self)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    _emit_insert_statements(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py", line 1097, in _emit_insert_statements
    c = connection._execute_20(
        ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"schedule_interval": null, "tags": ["producer", "dataset"], "_dag_id": "dataset_s3_bucket_producer_with_no_taskflow", "catch ... (1580 characters truncated) ... ducer_with_no_taskflow", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:33:42.532857', '9f283c851e485e36c30fa33d9d12ccae', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 169, in write_dag
    new_serialized_dag = cls(dag, processor_subdir)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 4, in __init__
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 481, in _initialize_instance
    with util.safe_reraise():
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/state.py", line 479, in _initialize_instance
    return manager.original_init(*mixed[1:], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 116, in __init__
    dag_data = SerializedDAG.to_dict(dag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1773, in to_dict
    json_dict = {"__version": cls.SERIALIZER_VERSION, "dag": cls.serialize_dag(var)}
                                                             ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/serialization/serialized_objects.py", line 1682, in serialize_dag
    raise SerializationError(f"Failed to serialize DAG {dag.dag_id!r}: {e}")
airflow.exceptions.SerializationError: Failed to serialize DAG 'dataset_alias_example_alias_producer_with_no_taskflow': (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_s3_bucket_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"schedule_interval": null, "tags": ["producer", "dataset"], "_dag_id": "dataset_s3_bucket_producer_with_no_taskflow", "catch ... (1580 characters truncated) ... ducer_with_no_taskflow", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:33:42.532857', '9f283c851e485e36c30fa33d9d12ccae', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2025-04-14T21:33:42.728+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.728+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:33:42.731+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.731+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:33:42.732+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.732+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:33:42.733+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.732+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:33:42.734+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.734+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:33:42.758+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.758+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:33:42.761+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.761+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:33:42.763+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.763+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:33:42.765+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:42.764+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:33:42.766+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.640 seconds
[2025-04-14T21:33:43.229+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:43.228+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"tags": ["consumer", "dataset-alias"], "_dag_id": "dataset_alias_example_alias_consumer_with_no_taskflow", "catchup": false, ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:33:42.717294', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:33:43.231+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:43.230+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"tags": ["consumer", "dataset-alias"], "_dag_id": "dataset_alias_example_alias_consumer_with_no_taskflow", "catchup": false, ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:33:42.717294', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:33:43.233+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:43.233+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"tags": ["consumer", "dataset-alias"], "_dag_id": "dataset_alias_example_alias_consumer_with_no_taskflow", "catchup": false, ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:33:42.717294', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:33:43.235+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:43.234+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"tags": ["consumer", "dataset-alias"], "_dag_id": "dataset_alias_example_alias_consumer_with_no_taskflow", "catchup": false, ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:33:42.717294', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:33:43.237+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:33:43.236+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:33:43.238+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"tags": ["consumer", "dataset-alias"], "_dag_id": "dataset_alias_example_alias_consumer_with_no_taskflow", "catchup": false, ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:33:42.717294', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:38:55.957+0200] {processor.py:186} INFO - Started process (PID=6906) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:38:55.958+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:38:55.960+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:55.959+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:38:56.196+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:38:56.336+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:56.335+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:38:56.352+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:56.351+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:38:56.354+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:56.354+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:38:56.355+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:56.355+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:38:56.356+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:56.356+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:38:56.377+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.425 seconds
[2025-04-14T21:38:57.595+0200] {processor.py:186} INFO - Started process (PID=6916) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:38:57.597+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:38:57.599+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:57.598+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:38:57.811+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:38:57.815+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:57.815+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:38:57.832+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:57.832+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:38:57.834+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:57.834+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:38:57.835+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:57.835+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:38:57.836+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:38:57.836+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:38:57.856+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.266 seconds
[2025-04-14T21:43:58.120+0200] {processor.py:186} INFO - Started process (PID=14264) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:43:58.122+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:43:58.123+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:43:58.123+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:43:58.319+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:43:58.455+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:43:58.454+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:43:58.470+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:43:58.470+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:43:58.472+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:43:58.472+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:43:58.473+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:43:58.473+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:43:58.474+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:43:58.474+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:43:58.496+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.381 seconds
[2025-04-14T21:44:00.129+0200] {processor.py:186} INFO - Started process (PID=14275) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:44:00.130+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:44:00.132+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:00.131+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:44:00.395+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:44:00.401+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:00.401+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:44:00.427+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:00.427+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:44:00.430+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:00.430+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:44:00.431+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:00.431+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:44:00.433+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:44:00.432+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:44:00.459+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.336 seconds
[2025-04-14T21:49:20.096+0200] {processor.py:186} INFO - Started process (PID=21866) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:49:20.098+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:49:20.100+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.100+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:49:20.143+0200] {processor.py:186} INFO - Started process (PID=21868) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:49:20.145+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:49:20.146+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.146+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:49:20.329+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:49:20.365+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:49:20.462+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.462+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:49:20.479+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.479+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:49:20.481+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.481+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:49:20.482+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.482+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:49:20.483+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.483+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:49:20.503+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.501+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.332742', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.426336', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1678 characters truncated) ... dataset_s3_bucket_consumer_with_no_taskflow", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.439325', '54b35d3f241109bf680a67dbefef5d59', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1580 characters truncated) ... ducer_with_no_taskflow", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.451017', '9f283c851e485e36c30fa33d9d12ccae', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:49:20.503+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.503+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:49:20.504+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.503+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.332742', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.426336', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1678 characters truncated) ... dataset_s3_bucket_consumer_with_no_taskflow", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.439325', '54b35d3f241109bf680a67dbefef5d59', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1580 characters truncated) ... ducer_with_no_taskflow", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.451017', '9f283c851e485e36c30fa33d9d12ccae', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:49:20.505+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.505+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.332742', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.426336', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1678 characters truncated) ... dataset_s3_bucket_consumer_with_no_taskflow", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.439325', '54b35d3f241109bf680a67dbefef5d59', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1580 characters truncated) ... ducer_with_no_taskflow", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.451017', '9f283c851e485e36c30fa33d9d12ccae', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:49:20.507+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.506+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.332742', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.426336', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1678 characters truncated) ... dataset_s3_bucket_consumer_with_no_taskflow", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.439325', '54b35d3f241109bf680a67dbefef5d59', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1580 characters truncated) ... ducer_with_no_taskflow", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.451017', '9f283c851e485e36c30fa33d9d12ccae', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:49:20.507+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.507+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:49:20.508+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('dataset_alias_example_alias_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1705 characters truncated) ... ucer_with_no_taskflow", "target": "dataset-alias", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.332742', '5e144716fb6232c225ddfa2c1548abad', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_alias_example_alias_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1808 characters truncated) ... et_alias_example_alias_consumer_with_no_taskflow", "dependency_type": "dataset-alias", "dependency_id": "example-alias-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.426336', 'bc2931b9fa8883df831d8ff6a6811593', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_consumer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1678 characters truncated) ... dataset_s3_bucket_consumer_with_no_taskflow", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.439325', '54b35d3f241109bf680a67dbefef5d59', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_s3_bucket_producer_with_no_taskflow', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py', 53896255340660155, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (1580 characters truncated) ... ducer_with_no_taskflow", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://bucket/my-task-with-no-taskflow"}], "params": []}}', None, '2025-04-14 19:49:20.451017', '9f283c851e485e36c30fa33d9d12ccae', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-14T21:49:20.520+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.520+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:49:20.522+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.522+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:49:20.523+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.523+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:49:20.524+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:49:20.524+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:49:20.545+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.408 seconds
[2025-04-14T21:54:33.612+0200] {processor.py:186} INFO - Started process (PID=29404) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:54:33.614+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:54:33.616+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:33.615+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:54:33.828+0200] {processor.py:925} INFO - DAG(s) 'dataset_alias_example_alias_consumer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_producer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:54:33.969+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:33.969+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:54:33.986+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:33.985+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:54:33.988+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:33.988+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:54:33.990+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:33.989+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:54:33.991+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:33.990+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:54:34.011+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.404 seconds
[2025-04-14T21:54:34.282+0200] {processor.py:186} INFO - Started process (PID=29407) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:54:34.283+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py for tasks to queue
[2025-04-14T21:54:34.285+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:34.285+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:54:34.525+0200] {processor.py:925} INFO - DAG(s) 'dataset_s3_bucket_producer_with_no_taskflow', 'dataset_alias_example_alias_producer_with_no_taskflow', 'dataset_s3_bucket_consumer_with_no_taskflow', 'dataset_alias_example_alias_consumer_with_no_taskflow' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py
[2025-04-14T21:54:34.529+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:34.529+0200] {dag.py:3239} INFO - Sync 4 DAGs
[2025-04-14T21:54:34.547+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:34.546+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:54:34.548+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:34.548+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_alias_example_alias_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:54:34.549+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:34.549+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_consumer_with_no_taskflow to None, run_after=None
[2025-04-14T21:54:34.550+0200] {logging_mixin.py:190} INFO - [2025-04-14T21:54:34.550+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_s3_bucket_producer_with_no_taskflow to None, run_after=None
[2025-04-14T21:54:34.570+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_dataset_alias_with_no_taskflow.py took 0.294 seconds
