[2025-04-15T12:22:17.206+0200] {processor.py:186} INFO - Started process (PID=39557) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:22:17.208+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:22:17.211+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.210+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:22:17.288+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:22:17.844+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.844+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:22:17.874+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.873+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:22:17.877+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.877+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:22:17.879+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.879+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:22:17.880+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.880+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:22:17.882+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.881+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:22:17.883+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.883+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:22:17.884+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.884+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:22:17.886+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.885+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:22:17.889+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.889+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:22:17.890+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.890+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:22:17.944+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.748 seconds
[2025-04-15T12:22:17.984+0200] {processor.py:186} INFO - Started process (PID=39558) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:22:17.987+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:22:17.989+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:17.989+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:22:18.071+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:22:18.086+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.086+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:22:18.412+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.412+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:22:18.419+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.419+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:22:18.421+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.421+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:22:18.423+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.423+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:22:18.426+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.426+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:22:18.428+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.428+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:22:18.430+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.430+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:22:18.432+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.432+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:22:18.438+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.437+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:22:18.440+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:22:18.439+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:22:18.503+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.529 seconds
[2025-04-15T12:28:51.199+0200] {processor.py:186} INFO - Started process (PID=47077) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:28:51.204+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:28:51.207+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:51.206+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:28:51.512+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:28:51.707+0200] {processor.py:186} INFO - Started process (PID=47078) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:28:51.710+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:28:51.714+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:51.713+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:28:52.273+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:28:53.534+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.533+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:28:53.623+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.622+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:28:53.628+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.628+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:28:53.631+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.631+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:28:53.634+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.633+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:28:53.636+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.636+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:28:53.640+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.639+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:28:53.660+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.660+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:28:53.665+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.664+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:28:53.670+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.670+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:28:53.673+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.673+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:28:53.766+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.766+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:28:53.784+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 2.596 seconds
[2025-04-15T12:28:53.892+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.891+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:28:53.899+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.899+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:28:53.902+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.901+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:28:53.904+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.904+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:28:53.907+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.906+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:28:53.909+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.909+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:28:53.911+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.911+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:28:53.914+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.913+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:28:53.920+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.919+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:28:53.922+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:53.922+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:28:54.291+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.283+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.296+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.294+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.305+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.303+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.315+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.312+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.323+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.322+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.345+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.343+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.352+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.351+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.356+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.355+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.360+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.358+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.364+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.362+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:28:54.366+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:28:54.366+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:28:54.369+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: (('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 10:28:52.877633', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1451 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.341047', '104ed7b00caa3e9bcdb9158b9fb4d3e8', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_unknown_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2127 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.382164', 'd56b2ed86c0b4f2aec82001b30edd75f', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('conditional_dataset_and_time_based_timetable', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2372 characters truncated) ... , "target": "conditional_dataset_and_time_based_timetable", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.425964', '4d219b0ede8ad7f1df4bfbbfd5daf90d', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.505376', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_produces_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1455 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.551230', '6052049ab87d26336b64f2d8b15bdf55', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:28:53.605876', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('dataset_consumes_1_and_2', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2042 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:28:53.641321', '92ef9592ceb419c98278beb5b1581b24', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'), ('consume_1_or_2_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"_task_group": {"_group_id": null, "prefix_group_id": true, "tooltip": "", "ui_color": "CornflowerBlue", "ui_fgcolor": "#000 ... (2125 characters truncated) ... aset", "target": "consume_1_or_2_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": []}}', None, '2025-04-15 10:28:53.691757', 'a57a4443d0271585f5f0ea632f412fb5', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags'))]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:55.577+0200] {processor.py:186} INFO - Started process (PID=53775) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:34:55.580+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:34:55.584+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:55.583+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:34:55.759+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:34:56.357+0200] {processor.py:186} INFO - Started process (PID=53776) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:34:56.360+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:34:56.364+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.363+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:34:56.543+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:34:56.813+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.812+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:34:56.879+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.879+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:34:56.886+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.885+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:34:56.889+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.889+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:34:56.892+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.891+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:34:56.895+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.894+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:34:56.898+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.897+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:34:56.901+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.900+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:34:56.904+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.903+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:34:56.910+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.909+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:34:56.912+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:56.912+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:34:57.014+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 1.448 seconds
[2025-04-15T12:34:57.394+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.393+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:34:57.470+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.469+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:34:57.478+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.477+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:34:57.481+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.480+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:34:57.483+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.483+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:34:57.487+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.486+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:34:57.491+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.490+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:34:57.494+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.494+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:34:57.501+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.500+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:34:57.517+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.517+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:34:57.523+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:57.523+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:34:58.043+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.036+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.047+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.046+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.051+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.049+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.055+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.053+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.059+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.058+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.063+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.061+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.067+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.065+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.071+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.069+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.075+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.073+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.077+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.076+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:34:58.078+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:34:58.078+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:34:58.081+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"timetable": {"__type": "airflow.timetables.simple.DatasetTriggeredTimetable", "__var": {"dataset_condition": {"__type": "da ... (1794 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": []}}', None, '2025-04-15 10:34:56.815999', '5847decfd80db7856f339d548fed55f0', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:37.898+0200] {processor.py:186} INFO - Started process (PID=60471) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:40:37.900+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:40:37.901+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:37.901+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:40:37.965+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:40:38.136+0200] {processor.py:186} INFO - Started process (PID=60472) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:40:38.137+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:40:38.139+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.139+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:40:38.189+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:40:38.362+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.362+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:40:38.381+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.381+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:40:38.384+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.384+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:40:38.385+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.385+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:40:38.386+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.386+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:40:38.388+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.387+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:40:38.389+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.389+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:40:38.390+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.390+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:40:38.391+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.391+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:40:38.394+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.394+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:40:38.395+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.395+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:40:38.427+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.535 seconds
[2025-04-15T12:40:38.446+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.445+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:40:38.469+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.469+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:40:38.472+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.472+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:40:38.474+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.473+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:40:38.475+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.475+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:40:38.477+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.476+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:40:38.478+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.478+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:40:38.480+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.479+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:40:38.481+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.481+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:40:38.485+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.484+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:40:38.486+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.486+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:40:38.981+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.978+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.983+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.982+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.985+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.984+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.987+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.986+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.989+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.988+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.992+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.991+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.994+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.993+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.995+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.994+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.996+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.996+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.998+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.997+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:40:38.998+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:40:38.998+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:40:38.999+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('dataset_consumes_1_never_scheduled', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "timezone": "UTC", "start_date": 1609459200.0, "fileloc": "/Users/user/Documents/learningProg/dataengineeri ... (2125 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": []}}', None, '2025-04-15 10:40:38.279383', '4008966f6397434690634274d73eb038', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T12:46:46.119+0200] {processor.py:186} INFO - Started process (PID=68787) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:46:46.121+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:46:46.122+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.122+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:46:46.191+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:46:46.758+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.758+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:46:46.787+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.786+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:46:46.789+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.789+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:46:46.791+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.790+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:46:46.792+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.792+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:46:46.793+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.793+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:46:46.794+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.794+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:46:46.795+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.795+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:46:46.797+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.797+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:46:46.801+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.801+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:46:46.803+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:46.802+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:46:46.850+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.737 seconds
[2025-04-15T12:46:48.067+0200] {processor.py:186} INFO - Started process (PID=68860) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:46:48.069+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:46:48.071+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.070+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:46:48.146+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:46:48.161+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.161+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:46:48.446+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.445+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:46:48.451+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.450+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:46:48.452+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.452+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:46:48.454+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.454+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:46:48.455+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.455+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:46:48.457+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.457+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:46:48.459+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.458+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:46:48.460+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.460+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:46:48.465+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.465+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:46:48.468+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:46:48.467+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:46:48.513+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.453 seconds
[2025-04-15T12:49:56.930+0200] {processor.py:186} INFO - Started process (PID=72976) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:49:56.932+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:49:56.934+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:56.934+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:49:56.997+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:49:57.171+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.170+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:49:57.267+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.267+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:49:57.271+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.271+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:49:57.273+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.272+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:49:57.274+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.274+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:49:57.275+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.275+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:49:57.277+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.277+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:49:57.278+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.278+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:49:57.279+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.279+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:49:57.282+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.282+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:49:57.283+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:49:57.283+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:49:57.317+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.392 seconds
[2025-04-15T12:52:40.257+0200] {processor.py:186} INFO - Started process (PID=76472) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:52:40.260+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:52:40.279+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:40.279+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:52:40.376+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:52:40.954+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:40.953+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:52:40.982+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:40.982+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:52:41.002+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:41.002+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:52:41.020+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:41.020+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:52:41.040+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:41.040+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:52:41.059+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:41.058+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:52:41.060+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:41.060+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:52:41.062+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:41.061+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:52:41.063+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:41.063+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:52:41.066+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:41.066+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:52:41.067+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:52:41.067+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:52:41.224+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.973 seconds
[2025-04-15T12:55:37.366+0200] {processor.py:186} INFO - Started process (PID=80407) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:55:37.368+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:55:37.370+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.369+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:55:37.444+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:55:37.581+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.580+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:55:37.655+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.655+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:55:37.658+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.658+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:55:37.659+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.659+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:55:37.660+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.660+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:55:37.661+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.661+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:55:37.662+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.662+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:55:37.663+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.663+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:55:37.664+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.664+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:55:37.666+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.666+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:55:37.667+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:55:37.667+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:55:37.696+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.336 seconds
[2025-04-15T12:58:07.891+0200] {processor.py:186} INFO - Started process (PID=83940) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:58:07.892+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T12:58:07.893+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:07.893+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:58:07.946+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T12:58:08.276+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.276+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T12:58:08.293+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.293+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T12:58:08.295+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.295+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:58:08.297+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.296+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T12:58:08.297+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.297+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T12:58:08.298+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.298+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T12:58:08.299+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.299+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T12:58:08.300+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.300+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T12:58:08.301+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.301+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T12:58:08.303+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.303+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T12:58:08.304+0200] {logging_mixin.py:190} INFO - [2025-04-15T12:58:08.304+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T12:58:08.336+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.450 seconds
[2025-04-15T13:01:08.243+0200] {processor.py:186} INFO - Started process (PID=87757) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:01:08.249+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:01:08.251+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.251+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:01:08.338+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:01:08.461+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.461+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:01:08.547+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.547+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:01:08.554+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.554+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:01:08.571+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.571+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:01:08.590+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.590+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:01:08.592+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.591+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:01:08.593+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.593+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:01:08.611+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.611+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:01:08.631+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.630+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:01:08.651+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.651+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:01:08.669+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:01:08.668+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:01:08.785+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.548 seconds
[2025-04-15T13:03:57.036+0200] {processor.py:186} INFO - Started process (PID=91491) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:03:57.038+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:03:57.039+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.039+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:03:57.112+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:03:57.612+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.612+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:03:57.640+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.640+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:03:57.643+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.642+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:03:57.644+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.644+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:03:57.645+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.645+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:03:57.647+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.647+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:03:57.648+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.648+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:03:57.650+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.649+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:03:57.651+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.651+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:03:57.655+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.654+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:03:57.656+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:03:57.656+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:03:57.697+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.667 seconds
[2025-04-15T13:06:46.918+0200] {processor.py:186} INFO - Started process (PID=95579) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:06:46.920+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:06:46.921+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:46.921+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:06:47.000+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:06:47.153+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.152+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:06:47.232+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.231+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:06:47.235+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.235+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:06:47.236+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.236+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:06:47.237+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.237+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:06:47.238+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.238+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:06:47.239+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.239+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:06:47.240+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.240+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:06:47.241+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.241+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:06:47.244+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.244+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:06:47.245+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:06:47.245+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:06:47.277+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.366 seconds
[2025-04-15T13:09:44.620+0200] {processor.py:186} INFO - Started process (PID=99543) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:09:44.622+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:09:44.624+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:44.623+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:09:44.699+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:09:45.230+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.230+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:09:45.263+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.263+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:09:45.267+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.266+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:09:45.268+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.268+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:09:45.269+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.269+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:09:45.270+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.270+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:09:45.272+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.272+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:09:45.274+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.273+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:09:45.275+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.275+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:09:45.278+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.278+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:09:45.280+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:09:45.279+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:09:45.318+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.704 seconds
[2025-04-15T13:13:01.821+0200] {processor.py:186} INFO - Started process (PID=4109) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:13:01.823+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:13:01.825+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:01.824+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:13:01.924+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:13:02.426+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.425+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:13:02.452+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.451+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:13:02.454+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.454+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:13:02.455+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.455+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:13:02.456+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.456+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:13:02.457+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.457+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:13:02.458+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.458+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:13:02.459+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.459+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:13:02.460+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.460+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:13:02.463+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.462+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:13:02.464+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:13:02.463+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:13:02.496+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.682 seconds
[2025-04-15T13:15:57.653+0200] {processor.py:186} INFO - Started process (PID=7982) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:15:57.655+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:15:57.656+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.656+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:15:57.729+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:15:57.871+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.871+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:15:57.957+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.957+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:15:57.961+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.960+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:15:57.962+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.962+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:15:57.963+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.963+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:15:57.964+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.964+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:15:57.966+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.966+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:15:57.967+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.967+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:15:57.969+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.969+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:15:57.973+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.973+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:15:57.974+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:15:57.974+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:15:58.012+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.365 seconds
[2025-04-15T13:19:33.391+0200] {processor.py:186} INFO - Started process (PID=12256) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:19:33.392+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:19:33.393+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.393+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:19:33.452+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:19:33.622+0200] {processor.py:186} INFO - Started process (PID=12264) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:19:33.624+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:19:33.625+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.625+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:19:33.677+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:19:33.864+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.864+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:19:33.883+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.883+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:19:33.886+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.885+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:19:33.887+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.886+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:19:33.887+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.887+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:19:33.888+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.888+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:19:33.889+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.889+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:19:33.890+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.890+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:19:33.891+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:19:33.893+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.893+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:19:33.894+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.894+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:19:33.922+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.537 seconds
[2025-04-15T13:19:33.952+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.952+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:19:33.973+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.973+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:19:33.976+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.976+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:19:33.977+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.977+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:19:33.978+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.978+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:19:33.979+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.979+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:19:33.980+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.980+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:19:33.981+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.980+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:19:33.982+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.981+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:19:33.984+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.984+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:19:33.985+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:33.985+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:19:34.120+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.115+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.121+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.121+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.123+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.122+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.124+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.124+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.126+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.125+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.127+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.127+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.128+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.128+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.130+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.129+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.131+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.130+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.132+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.132+0200] {dagbag.py:698} ERROR - Failed to write serialized DAG: /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:19:34.133+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:19:34.133+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:19:34.134+0200] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 445, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/tenacity/__init__.py", line 400, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('consume_1_or_both_2_and_3_with_dataset_expressions', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 17032575341781361, '{"__version": 1, "dag": {"edge_info": {}, "fileloc": "/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/pyt ... (2482 characters truncated) ... get": "consume_1_or_both_2_and_3_with_dataset_expressions", "dependency_type": "dataset", "dependency_id": "s3://dag3/output_3.txt"}], "params": []}}', None, '2025-04-15 11:19:33.782120', 'c9dcae27f3d403dcd531741d1d931322', '/Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-04-15T13:26:14.923+0200] {processor.py:186} INFO - Started process (PID=20581) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:26:14.925+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:26:14.926+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:14.926+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:26:14.999+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:26:15.547+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.547+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:26:15.578+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.577+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:26:15.581+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.581+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:26:15.583+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.583+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:26:15.585+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.585+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:26:15.586+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.586+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:26:15.587+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.587+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:26:15.588+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.588+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:26:15.590+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.590+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:26:15.592+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.592+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:26:15.593+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:15.593+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:26:15.634+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.717 seconds
[2025-04-15T13:26:16.515+0200] {processor.py:186} INFO - Started process (PID=20755) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:26:16.516+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:26:16.518+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.518+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:26:16.594+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:26:16.607+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.607+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:26:16.839+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.839+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:26:16.844+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.843+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:26:16.845+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.845+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:26:16.847+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.847+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:26:16.848+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.848+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:26:16.850+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.850+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:26:16.851+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.851+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:26:16.853+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.853+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:26:16.857+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.856+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:26:16.858+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:26:16.858+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:26:16.898+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.390 seconds
[2025-04-15T13:32:16.336+0200] {processor.py:186} INFO - Started process (PID=28646) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:32:16.337+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:32:16.339+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.339+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:32:16.398+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:32:16.794+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.794+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:32:16.813+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.812+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:32:16.815+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.815+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:32:16.816+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.816+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:32:16.817+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.817+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:32:16.818+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.818+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:32:16.819+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.819+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:32:16.820+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.820+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:32:16.821+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.820+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:32:16.823+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.823+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:32:16.824+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.824+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:32:16.852+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.522 seconds
[2025-04-15T13:32:16.982+0200] {processor.py:186} INFO - Started process (PID=28647) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:32:16.983+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:32:16.984+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:16.984+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:32:17.029+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:32:17.038+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.037+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:32:17.211+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.211+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:32:17.215+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.215+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:32:17.216+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.216+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:32:17.217+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.217+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:32:17.218+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.218+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:32:17.220+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.219+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:32:17.221+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.220+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:32:17.221+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.221+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:32:17.224+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.223+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:32:17.225+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:32:17.225+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:32:17.255+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.279 seconds
[2025-04-15T13:37:40.541+0200] {processor.py:186} INFO - Started process (PID=36073) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:37:40.543+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:37:40.545+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:40.545+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:37:40.620+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:37:41.133+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.133+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:37:41.163+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.162+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:37:41.166+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.166+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:37:41.168+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.168+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:37:41.169+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.169+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:37:41.171+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.171+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:37:41.172+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.172+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:37:41.174+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.173+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:37:41.175+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.175+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:37:41.179+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.178+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:37:41.180+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:41.180+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:37:41.219+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.683 seconds
[2025-04-15T13:37:42.149+0200] {processor.py:186} INFO - Started process (PID=36083) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:37:42.151+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:37:42.152+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.152+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:37:42.202+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:37:42.213+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.213+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:37:42.391+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.391+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:37:42.394+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.394+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:37:42.395+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.395+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:37:42.396+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.396+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:37:42.397+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.397+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:37:42.398+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.398+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:37:42.399+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.399+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:37:42.400+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.400+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:37:42.402+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.402+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:37:42.403+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:37:42.403+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:37:42.434+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.290 seconds
[2025-04-15T13:44:29.755+0200] {processor.py:186} INFO - Started process (PID=46572) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:44:29.757+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:44:29.758+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:29.758+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:44:29.829+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:44:29.962+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:29.962+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:44:30.071+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.071+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:44:30.075+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.075+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:44:30.077+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.077+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:44:30.078+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.078+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:44:30.079+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.079+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:44:30.081+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.080+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:44:30.082+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.082+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:44:30.084+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.084+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:44:30.086+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.086+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:44:30.088+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:30.088+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:44:30.123+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.374 seconds
[2025-04-15T13:44:31.256+0200] {processor.py:186} INFO - Started process (PID=46673) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:44:31.257+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:44:31.259+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.258+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:44:31.304+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:44:31.428+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.428+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:44:31.509+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.509+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:44:31.513+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.513+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:44:31.514+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.514+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:44:31.515+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.515+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:44:31.516+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.516+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:44:31.517+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.517+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:44:31.518+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.518+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:44:31.519+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.519+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:44:31.521+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.521+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:44:31.522+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:44:31.522+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:44:31.549+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.298 seconds
[2025-04-15T13:52:00.040+0200] {processor.py:186} INFO - Started process (PID=58001) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:52:00.042+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:52:00.044+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.044+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:52:00.114+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:52:00.315+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.314+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:52:00.338+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.338+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:52:00.342+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.341+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:52:00.343+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.342+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:52:00.344+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.344+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:52:00.345+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.345+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:52:00.346+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.346+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:52:00.348+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.348+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:52:00.349+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.349+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:52:00.352+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.351+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:52:00.353+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:00.353+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:52:00.385+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.349 seconds
[2025-04-15T13:52:07.335+0200] {processor.py:186} INFO - Started process (PID=58141) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:52:07.343+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:52:07.345+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.345+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:52:07.410+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:52:07.640+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.640+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:52:07.686+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.685+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:52:07.699+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.699+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:52:07.716+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.716+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:52:07.735+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.734+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:52:07.753+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.753+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:52:07.772+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.772+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:52:07.791+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.791+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:52:07.811+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.811+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:52:07.832+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.832+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:52:07.848+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:52:07.848+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:52:07.904+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.574 seconds
[2025-04-15T13:59:34.665+0200] {processor.py:186} INFO - Started process (PID=68483) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:59:34.667+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:59:34.669+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:34.669+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:59:34.764+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:59:35.017+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.017+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:59:35.045+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.045+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:59:35.049+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.049+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:59:35.050+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.050+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:59:35.051+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.051+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:59:35.052+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.052+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:59:35.053+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.053+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:59:35.054+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.054+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:59:35.055+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.055+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:59:35.059+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.059+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:59:35.060+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.060+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:59:35.096+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.437 seconds
[2025-04-15T13:59:35.350+0200] {processor.py:186} INFO - Started process (PID=68492) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:59:35.352+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T13:59:35.354+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.354+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:59:35.411+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T13:59:35.606+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.606+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T13:59:35.628+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.628+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T13:59:35.632+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.631+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:59:35.633+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.632+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T13:59:35.634+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.633+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T13:59:35.634+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.634+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T13:59:35.635+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.635+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T13:59:35.636+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.636+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T13:59:35.637+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.637+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T13:59:35.640+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.639+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T13:59:35.640+0200] {logging_mixin.py:190} INFO - [2025-04-15T13:59:35.640+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T13:59:35.670+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.324 seconds
[2025-04-15T14:05:58.910+0200] {processor.py:186} INFO - Started process (PID=77841) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:05:58.912+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:05:58.913+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:58.913+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:05:58.969+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:05:59.154+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.154+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:05:59.177+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.176+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:05:59.180+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.180+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:05:59.181+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.181+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:05:59.182+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.182+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:05:59.183+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.183+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:05:59.184+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.184+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:05:59.185+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.185+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:05:59.186+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.186+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:05:59.188+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.188+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:05:59.189+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.189+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:05:59.219+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.314 seconds
[2025-04-15T14:05:59.379+0200] {processor.py:186} INFO - Started process (PID=77842) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:05:59.391+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:05:59.394+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.394+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:05:59.478+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:05:59.688+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.688+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:05:59.720+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.719+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:05:59.723+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.723+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:05:59.725+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.724+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:05:59.726+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.726+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:05:59.728+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.727+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:05:59.729+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.729+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:05:59.730+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.730+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:05:59.732+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.732+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:05:59.736+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.736+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:05:59.737+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:05:59.737+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:05:59.772+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.397 seconds
[2025-04-15T14:12:25.596+0200] {processor.py:186} INFO - Started process (PID=86216) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:12:25.597+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:12:25.599+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.598+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:12:25.651+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:12:25.858+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.858+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:12:25.885+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.884+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:12:25.888+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.887+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:12:25.889+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.889+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:12:25.890+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.890+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:12:25.892+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:12:25.893+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.893+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:12:25.894+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.894+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:12:25.895+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.895+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:12:25.898+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:12:25.899+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:25.899+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:12:25.930+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.339 seconds
[2025-04-15T14:12:28.252+0200] {processor.py:186} INFO - Started process (PID=86227) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:12:28.254+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:12:28.255+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.255+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:12:28.312+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:12:28.503+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.503+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:12:28.525+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.525+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:12:28.528+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.528+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:12:28.530+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.529+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:12:28.531+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.530+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:12:28.532+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.532+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:12:28.534+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.533+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:12:28.535+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.535+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:12:28.536+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.536+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:12:28.539+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.539+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:12:28.540+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:12:28.540+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:12:28.573+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.325 seconds
[2025-04-15T14:18:08.496+0200] {processor.py:186} INFO - Started process (PID=94241) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:18:08.497+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:18:08.499+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.499+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:18:08.563+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:18:08.760+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.760+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:18:08.782+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.782+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:18:08.786+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.786+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:18:08.788+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.787+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:18:08.789+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.788+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:18:08.790+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.789+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:18:08.791+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.790+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:18:08.792+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.791+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:18:08.793+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.792+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:18:08.795+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.795+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:18:08.797+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:08.796+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:18:08.834+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.343 seconds
[2025-04-15T14:18:12.563+0200] {processor.py:186} INFO - Started process (PID=94262) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:18:12.564+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:18:12.565+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.565+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:18:12.608+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:18:12.772+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.771+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:18:12.791+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.791+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:18:12.794+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.793+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:18:12.794+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.794+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:18:12.795+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.795+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:18:12.796+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.796+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:18:12.797+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.797+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:18:12.797+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.797+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:18:12.798+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.798+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:18:12.800+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.800+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:18:12.801+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:18:12.801+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:18:12.827+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.268 seconds
[2025-04-15T14:24:22.851+0200] {processor.py:186} INFO - Started process (PID=3259) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:24:22.853+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:24:22.855+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:22.855+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:24:22.927+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:24:23.160+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.159+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:24:23.190+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.190+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:24:23.194+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.194+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:24:23.196+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.195+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:24:23.197+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.197+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:24:23.198+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.198+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:24:23.200+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.200+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:24:23.201+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.201+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:24:23.202+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.202+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:24:23.204+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.204+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:24:23.205+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:23.205+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:24:23.252+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.405 seconds
[2025-04-15T14:24:33.613+0200] {processor.py:186} INFO - Started process (PID=3624) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:24:33.614+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:24:33.616+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.615+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:24:33.662+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:24:33.833+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.833+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:24:33.852+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.852+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:24:33.855+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.854+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:24:33.856+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.855+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:24:33.857+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.856+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:24:33.858+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.857+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:24:33.859+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.859+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:24:33.860+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.860+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:24:33.862+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.862+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:24:33.865+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.865+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:24:33.866+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:24:33.866+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:24:33.898+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.290 seconds
[2025-04-15T14:30:09.242+0200] {processor.py:186} INFO - Started process (PID=11497) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:30:09.243+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:30:09.245+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.245+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:30:09.363+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:30:09.633+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.633+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:30:09.662+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.661+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:30:09.665+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.665+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:30:09.666+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.666+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:30:09.667+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.667+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:30:09.668+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.668+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:30:09.669+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.669+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:30:09.670+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.670+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:30:09.671+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.671+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:30:09.673+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.673+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:30:09.674+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:09.674+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:30:09.709+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.472 seconds
[2025-04-15T14:30:17.212+0200] {processor.py:186} INFO - Started process (PID=11726) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:30:17.213+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:30:17.214+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.214+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:30:17.266+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:30:17.442+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.442+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:30:17.463+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.463+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:30:17.466+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.466+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:30:17.467+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.467+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:30:17.468+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.468+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:30:17.469+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.469+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:30:17.470+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.470+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:30:17.471+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.470+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:30:17.471+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.471+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:30:17.473+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.473+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:30:17.474+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:30:17.474+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:30:17.501+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.295 seconds
[2025-04-15T14:35:43.648+0200] {processor.py:186} INFO - Started process (PID=19269) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:35:43.650+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:35:43.651+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.651+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:35:43.719+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:35:43.898+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.898+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:35:43.919+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.919+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:35:43.922+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.922+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:35:43.923+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.923+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:35:43.924+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.924+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:35:43.925+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.925+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:35:43.926+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.926+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:35:43.927+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.927+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:35:43.928+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.928+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:35:43.930+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.930+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:35:43.931+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:43.931+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:35:43.960+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.317 seconds
[2025-04-15T14:35:55.508+0200] {processor.py:186} INFO - Started process (PID=19542) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:35:55.510+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:35:55.511+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.511+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:35:55.590+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:35:55.867+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.867+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:35:55.900+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.900+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:35:55.905+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.905+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:35:55.907+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.906+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:35:55.908+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.908+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:35:55.910+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.909+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:35:55.911+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.911+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:35:55.913+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.913+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:35:55.914+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.914+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:35:55.918+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.918+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:35:55.920+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:35:55.919+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:35:55.964+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.461 seconds
[2025-04-15T14:41:11.095+0200] {processor.py:186} INFO - Started process (PID=26706) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:41:11.097+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:41:11.099+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.098+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:41:11.161+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:41:11.363+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.362+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:41:11.389+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.388+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:41:11.392+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.392+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:41:11.393+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.393+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:41:11.395+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.394+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:41:11.396+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.396+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:41:11.397+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.397+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:41:11.398+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.398+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:41:11.399+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.399+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:41:11.401+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.401+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:41:11.402+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:11.402+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:41:11.439+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.348 seconds
[2025-04-15T14:41:31.854+0200] {processor.py:186} INFO - Started process (PID=27204) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:41:31.856+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:41:31.858+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:31.857+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:41:31.932+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:41:32.129+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.129+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:41:32.154+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.154+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:41:32.157+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.157+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:41:32.158+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.158+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:41:32.159+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.159+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:41:32.160+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.160+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:41:32.161+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.161+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:41:32.162+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.162+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:41:32.163+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.163+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:41:32.165+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.165+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:41:32.166+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:41:32.166+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:41:32.193+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.344 seconds
[2025-04-15T14:46:36.041+0200] {processor.py:186} INFO - Started process (PID=34484) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:46:36.043+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:46:36.044+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.044+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:46:36.094+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:46:36.281+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.281+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:46:36.303+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.303+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:46:36.308+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.307+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:46:36.309+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.309+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:46:36.310+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.310+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:46:36.311+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.311+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:46:36.312+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.312+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:46:36.313+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.313+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:46:36.315+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.315+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:46:36.317+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.317+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:46:36.319+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:36.318+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:46:36.346+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.309 seconds
[2025-04-15T14:46:49.816+0200] {processor.py:186} INFO - Started process (PID=34751) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:46:49.817+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:46:49.819+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:49.818+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:46:49.864+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:46:50.029+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.029+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:46:50.048+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.048+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:46:50.051+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.051+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:46:50.052+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.051+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:46:50.052+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.052+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:46:50.053+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.053+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:46:50.054+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.054+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:46:50.055+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.054+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:46:50.055+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.055+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:46:50.057+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.057+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:46:50.058+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:46:50.058+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:46:50.083+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.273 seconds
[2025-04-15T14:51:51.764+0200] {processor.py:186} INFO - Started process (PID=41975) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:51:51.769+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:51:51.776+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:51.774+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:51:51.879+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:51:52.186+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.186+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:51:52.207+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.207+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:51:52.210+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.210+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:51:52.211+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.211+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:51:52.212+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.212+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:51:52.213+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.213+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:51:52.214+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.214+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:51:52.215+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.215+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:51:52.216+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.216+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:51:52.218+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.218+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:51:52.219+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:52.219+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:51:52.247+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.497 seconds
[2025-04-15T14:51:56.500+0200] {processor.py:186} INFO - Started process (PID=42110) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:51:56.501+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:51:56.503+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.502+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:51:56.545+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:51:56.712+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.712+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:51:56.731+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.731+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:51:56.734+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.734+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:51:56.735+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.735+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:51:56.736+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.736+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:51:56.737+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.737+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:51:56.738+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.738+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:51:56.739+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.739+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:51:56.740+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.739+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:51:56.742+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.741+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:51:56.743+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:51:56.742+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:51:56.768+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.272 seconds
[2025-04-15T14:57:00.738+0200] {processor.py:186} INFO - Started process (PID=49339) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:57:00.739+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:57:00.740+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:00.740+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:57:00.785+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:57:00.970+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:00.970+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:57:00.991+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:00.991+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:57:00.994+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:00.994+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:57:00.995+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:00.995+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:57:00.996+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:00.996+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:57:00.997+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:00.997+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:57:00.998+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:00.998+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:57:01.000+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:00.999+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:57:01.001+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:01.001+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:57:01.003+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:01.003+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:57:01.004+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:01.004+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:57:01.032+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.299 seconds
[2025-04-15T14:57:05.456+0200] {processor.py:186} INFO - Started process (PID=49460) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:57:05.457+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T14:57:05.458+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.458+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:57:05.505+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T14:57:05.681+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.681+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T14:57:05.707+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.707+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T14:57:05.710+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.710+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:57:05.711+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.711+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T14:57:05.712+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.712+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T14:57:05.713+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.713+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T14:57:05.714+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.714+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T14:57:05.715+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.714+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T14:57:05.716+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.715+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T14:57:05.719+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.718+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T14:57:05.719+0200] {logging_mixin.py:190} INFO - [2025-04-15T14:57:05.719+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T14:57:05.747+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.296 seconds
[2025-04-15T15:02:09.885+0200] {processor.py:186} INFO - Started process (PID=56708) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:02:09.887+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:02:09.889+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:09.888+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:02:09.946+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:02:10.161+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.161+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:02:10.189+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.189+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:02:10.192+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.192+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:02:10.193+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.193+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:02:10.194+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.194+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:02:10.195+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.194+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:02:10.196+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.195+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:02:10.196+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.196+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:02:10.197+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.197+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:02:10.199+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.199+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:02:10.200+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:10.200+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:02:10.229+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.349 seconds
[2025-04-15T15:02:12.150+0200] {processor.py:186} INFO - Started process (PID=56726) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:02:12.151+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:02:12.152+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.152+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:02:12.196+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:02:12.349+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.349+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:02:12.367+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.367+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:02:12.370+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.370+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:02:12.371+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.371+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:02:12.372+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.371+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:02:12.372+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.372+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:02:12.373+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.373+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:02:12.374+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.374+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:02:12.375+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.374+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:02:12.377+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.376+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:02:12.377+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:02:12.377+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:02:12.401+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.255 seconds
[2025-04-15T15:07:52.197+0200] {processor.py:186} INFO - Started process (PID=64732) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:07:52.198+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:07:52.199+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.199+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:07:52.282+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:07:52.501+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.501+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:07:52.528+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.528+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:07:52.532+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.532+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:07:52.534+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.534+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:07:52.535+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.535+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:07:52.536+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.535+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:07:52.537+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.536+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:07:52.538+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.537+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:07:52.539+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.538+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:07:52.541+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.541+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:07:52.542+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:52.542+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:07:52.570+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.378 seconds
[2025-04-15T15:07:53.931+0200] {processor.py:186} INFO - Started process (PID=64743) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:07:53.933+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:07:53.934+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:53.934+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:07:53.980+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:07:54.147+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.147+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:07:54.167+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.167+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:07:54.170+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.170+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:07:54.171+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.171+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:07:54.172+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.172+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:07:54.173+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.172+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:07:54.173+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.173+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:07:54.174+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.174+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:07:54.175+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.175+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:07:54.177+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.177+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:07:54.178+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:07:54.178+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:07:54.203+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.277 seconds
[2025-04-15T15:13:30.119+0200] {processor.py:186} INFO - Started process (PID=72623) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:13:30.119+0200] {processor.py:186} INFO - Started process (PID=72624) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:13:30.120+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:13:30.121+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:13:30.122+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.122+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:13:30.123+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.122+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:13:30.193+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:13:30.193+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:13:30.357+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.357+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:13:30.357+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.357+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:13:30.375+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.375+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:13:30.376+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.375+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:13:30.378+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.378+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:13:30.378+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.378+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:13:30.379+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.379+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:13:30.379+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.379+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:13:30.380+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.380+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:13:30.380+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.380+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:13:30.380+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.380+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:13:30.381+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.381+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:13:30.381+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.381+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:13:30.382+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.381+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:13:30.382+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.382+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:13:30.382+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.382+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:13:30.383+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.383+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:13:30.383+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.383+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:13:30.385+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.385+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:13:30.385+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.385+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:13:30.385+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.385+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:13:30.386+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:13:30.386+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:13:30.409+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.294 seconds
[2025-04-15T15:13:30.431+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.316 seconds
[2025-04-15T15:19:09.870+0200] {processor.py:186} INFO - Started process (PID=80371) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:19:09.871+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:19:09.873+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:09.872+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:19:09.940+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:19:10.109+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.109+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:19:10.129+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.129+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:19:10.132+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.132+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:19:10.133+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.133+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:19:10.134+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.134+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:19:10.135+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.135+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:19:10.136+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.136+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:19:10.137+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.137+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:19:10.138+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.137+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:19:10.140+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.140+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:19:10.141+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:10.140+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:19:10.168+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.302 seconds
[2025-04-15T15:19:11.022+0200] {processor.py:186} INFO - Started process (PID=80382) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:19:11.023+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:19:11.024+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.024+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:19:11.072+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:19:11.246+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.246+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:19:11.271+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.271+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:19:11.274+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.274+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:19:11.275+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.275+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:19:11.276+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.276+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:19:11.277+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.277+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:19:11.278+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.278+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:19:11.279+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.279+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:19:11.280+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.280+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:19:11.282+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.282+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:19:11.283+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:19:11.283+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:19:11.311+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.294 seconds
[2025-04-15T15:24:15.607+0200] {processor.py:186} INFO - Started process (PID=87750) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:24:15.609+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:24:15.611+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.610+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:24:15.686+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:24:15.861+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.860+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:24:15.880+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.880+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:24:15.883+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.883+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:24:15.884+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.884+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:24:15.885+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.885+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:24:15.886+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.885+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:24:15.886+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.886+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:24:15.887+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.887+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:24:15.888+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.888+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:24:15.890+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.890+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:24:15.891+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:15.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:24:15.917+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.315 seconds
[2025-04-15T15:24:19.933+0200] {processor.py:186} INFO - Started process (PID=87862) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:24:19.934+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:24:19.935+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:19.935+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:24:19.981+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:24:20.138+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.138+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:24:20.157+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.157+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:24:20.160+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.160+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:24:20.161+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.161+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:24:20.162+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.161+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:24:20.162+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.162+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:24:20.163+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.163+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:24:20.164+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.164+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:24:20.165+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.164+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:24:20.166+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.166+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:24:20.167+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:24:20.167+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:24:20.195+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.267 seconds
[2025-04-15T15:29:27.589+0200] {processor.py:186} INFO - Started process (PID=95299) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:29:27.591+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:29:27.592+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.592+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:29:27.657+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:29:27.829+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.829+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:29:27.849+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.849+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:29:27.852+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.852+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:29:27.853+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.853+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:29:27.854+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.854+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:29:27.855+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.854+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:29:27.855+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.855+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:29:27.856+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.856+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:29:27.857+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.857+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:29:27.859+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.859+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:29:27.860+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:27.860+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:29:27.885+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.301 seconds
[2025-04-15T15:29:29.036+0200] {processor.py:186} INFO - Started process (PID=95309) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:29:29.038+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:29:29.039+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.038+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:29:29.081+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:29:29.253+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.253+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:29:29.273+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.272+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:29:29.276+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.275+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:29:29.277+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.276+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:29:29.277+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.277+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:29:29.278+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.278+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:29:29.279+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.279+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:29:29.280+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.280+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:29:29.281+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.280+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:29:29.282+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.282+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:29:29.283+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:29:29.283+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:29:29.309+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.278 seconds
[2025-04-15T15:35:32.124+0200] {processor.py:186} INFO - Started process (PID=3761) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:35:32.127+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:35:32.129+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.129+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:35:32.293+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:35:32.488+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.488+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:35:32.511+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.511+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:35:32.515+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.514+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:35:32.516+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.516+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:35:32.517+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.517+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:35:32.518+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.518+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:35:32.520+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.519+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:35:32.521+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.521+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:35:32.522+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.522+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:35:32.524+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.524+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:35:32.525+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.525+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:35:32.558+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.440 seconds
[2025-04-15T15:35:32.911+0200] {processor.py:186} INFO - Started process (PID=3770) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:35:32.912+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:35:32.913+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:32.913+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:35:32.978+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:35:33.159+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.158+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:35:33.181+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.181+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:35:33.184+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.184+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:35:33.185+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.185+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:35:33.186+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.186+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:35:33.187+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.187+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:35:33.188+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.188+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:35:33.189+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.189+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:35:33.190+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.190+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:35:33.193+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.192+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:35:33.194+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:35:33.193+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:35:33.222+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.318 seconds
[2025-04-15T15:41:28.039+0200] {processor.py:186} INFO - Started process (PID=11645) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:41:28.040+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:41:28.041+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.041+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:41:28.089+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:41:28.285+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.284+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:41:28.309+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.309+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:41:28.312+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.312+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:41:28.314+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.313+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:41:28.315+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.315+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:41:28.316+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.316+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:41:28.317+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.317+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:41:28.318+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.318+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:41:28.319+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.318+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:41:28.321+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.321+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:41:28.322+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:28.322+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:41:28.360+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.326 seconds
[2025-04-15T15:41:29.855+0200] {processor.py:186} INFO - Started process (PID=11747) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:41:29.856+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:41:29.858+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:29.858+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:41:29.907+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:41:30.076+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.076+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:41:30.099+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.099+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:41:30.102+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.102+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:41:30.103+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.103+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:41:30.104+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.104+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:41:30.105+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.105+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:41:30.106+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.106+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:41:30.107+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.107+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:41:30.108+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.107+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:41:30.110+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.109+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:41:30.111+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:41:30.110+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:41:30.139+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.289 seconds
[2025-04-15T15:46:34.502+0200] {processor.py:186} INFO - Started process (PID=19171) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:46:34.504+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:46:34.505+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.505+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:46:34.550+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:46:34.718+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.718+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:46:34.737+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.737+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:46:34.740+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.739+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:46:34.740+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.740+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:46:34.741+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.741+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:46:34.742+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.742+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:46:34.743+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.742+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:46:34.743+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.743+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:46:34.744+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.744+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:46:34.746+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.746+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:46:34.747+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:34.747+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:46:34.771+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.274 seconds
[2025-04-15T15:46:36.661+0200] {processor.py:186} INFO - Started process (PID=19182) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:46:36.662+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:46:36.664+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.663+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:46:36.708+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:46:36.863+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.863+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:46:36.882+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.882+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:46:36.885+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.885+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:46:36.886+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.886+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:46:36.887+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.887+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:46:36.888+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.888+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:46:36.889+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.888+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:46:36.889+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.889+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:46:36.890+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.890+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:46:36.892+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.892+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:46:36.893+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:46:36.893+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:46:36.918+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.261 seconds
[2025-04-15T15:52:06.990+0200] {processor.py:186} INFO - Started process (PID=26606) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:52:06.991+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:52:06.993+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:06.993+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:52:07.071+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:52:07.327+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.327+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:52:07.362+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.362+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:52:07.367+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.367+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:52:07.368+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.368+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:52:07.370+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.370+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:52:07.371+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.371+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:52:07.373+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.373+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:52:07.374+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.374+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:52:07.376+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.375+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:52:07.378+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.378+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:52:07.379+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.379+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:52:07.418+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.433 seconds
[2025-04-15T15:52:07.422+0200] {processor.py:186} INFO - Started process (PID=26619) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:52:07.424+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:52:07.426+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.425+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:52:07.490+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:52:07.684+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.684+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:52:07.706+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.706+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:52:07.710+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.710+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:52:07.711+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.711+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:52:07.713+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.713+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:52:07.714+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.714+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:52:07.715+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.715+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:52:07.716+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.716+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:52:07.718+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.717+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:52:07.720+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.720+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:52:07.721+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:52:07.721+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:52:07.753+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.336 seconds
[2025-04-15T15:57:58.128+0200] {processor.py:186} INFO - Started process (PID=34192) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:57:58.130+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:57:58.131+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.131+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:57:58.201+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:57:58.376+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.376+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:57:58.407+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.407+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:57:58.411+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.410+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:57:58.412+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.412+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:57:58.413+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.413+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:57:58.414+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.414+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:57:58.415+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.415+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:57:58.416+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.415+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:57:58.417+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.416+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:57:58.420+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.419+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:57:58.421+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.420+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:57:58.458+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.335 seconds
[2025-04-15T15:57:58.993+0200] {processor.py:186} INFO - Started process (PID=34193) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:57:58.994+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T15:57:58.996+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:58.995+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:57:59.047+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T15:57:59.231+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.231+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T15:57:59.254+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.254+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T15:57:59.257+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.257+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:57:59.258+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.258+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T15:57:59.259+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.259+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T15:57:59.260+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.260+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T15:57:59.261+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.260+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T15:57:59.262+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.261+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T15:57:59.262+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.262+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T15:57:59.265+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.264+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T15:57:59.266+0200] {logging_mixin.py:190} INFO - [2025-04-15T15:57:59.266+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T15:57:59.292+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.304 seconds
[2025-04-15T16:03:17.386+0200] {processor.py:186} INFO - Started process (PID=41615) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:03:17.387+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:03:17.388+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.388+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:03:17.450+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:03:17.626+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.626+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:03:17.646+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.645+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:03:17.648+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.648+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:03:17.649+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.649+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:03:17.650+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.650+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:03:17.651+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.651+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:03:17.652+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.652+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:03:17.653+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.653+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:03:17.654+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.654+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:03:17.656+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.656+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:03:17.657+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:17.657+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:03:17.686+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.305 seconds
[2025-04-15T16:03:19.877+0200] {processor.py:186} INFO - Started process (PID=41631) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:03:19.878+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:03:19.880+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:19.879+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:03:19.930+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:03:20.134+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.134+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:03:20.156+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.156+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:03:20.159+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.159+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:03:20.160+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.160+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:03:20.161+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.161+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:03:20.162+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.162+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:03:20.163+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.163+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:03:20.164+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.164+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:03:20.165+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.165+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:03:20.168+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.167+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:03:20.169+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:03:20.168+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:03:20.194+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.322 seconds
[2025-04-15T16:09:04.279+0200] {processor.py:186} INFO - Started process (PID=49476) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:09:04.281+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:09:04.282+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.282+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:09:04.357+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:09:04.604+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.604+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:09:04.641+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.640+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:09:04.646+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.646+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:09:04.647+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.647+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:09:04.649+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.649+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:09:04.650+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.650+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:09:04.652+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.652+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:09:04.654+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.654+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:09:04.656+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.656+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:09:04.660+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.659+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:09:04.661+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:04.661+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:09:04.714+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.439 seconds
[2025-04-15T16:09:11.473+0200] {processor.py:186} INFO - Started process (PID=49709) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:09:11.475+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:09:11.477+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.476+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:09:11.560+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:09:11.840+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.839+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:09:11.871+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.871+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:09:11.877+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.876+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:09:11.878+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.878+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:09:11.879+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.879+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:09:11.880+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.880+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:09:11.882+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.881+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:09:11.883+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.883+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:09:11.885+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.884+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:09:11.890+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.889+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:09:11.891+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:09:11.891+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:09:11.932+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.465 seconds
[2025-04-15T16:15:45.230+0200] {processor.py:186} INFO - Started process (PID=58087) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:15:45.232+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:15:45.235+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.235+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:15:45.319+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:15:45.595+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.595+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:15:45.623+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.622+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:15:45.626+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.626+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:15:45.627+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.627+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:15:45.628+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.628+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:15:45.629+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.629+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:15:45.630+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.630+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:15:45.631+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.631+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:15:45.632+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.632+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:15:45.636+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.636+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:15:45.637+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:45.637+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:15:45.676+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.450 seconds
[2025-04-15T16:15:51.288+0200] {processor.py:186} INFO - Started process (PID=58202) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:15:51.290+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:15:51.291+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.291+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:15:51.363+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:15:51.656+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.656+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:15:51.697+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.696+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:15:51.703+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.702+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:15:51.704+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.704+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:15:51.706+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.706+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:15:51.708+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.707+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:15:51.709+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.709+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:15:51.714+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.714+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:15:51.717+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.716+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:15:51.737+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.737+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:15:51.748+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:15:51.744+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:15:51.796+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.513 seconds
[2025-04-15T16:21:52.003+0200] {processor.py:186} INFO - Started process (PID=66299) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:21:52.004+0200] {processor.py:186} INFO - Started process (PID=66300) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:21:52.005+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:21:52.006+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:21:52.007+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.006+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:21:52.007+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.007+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:21:52.097+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:21:52.098+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:21:52.373+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.372+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:21:52.384+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.384+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:21:52.408+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.408+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:21:52.413+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.413+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:21:52.414+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.414+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:21:52.416+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.415+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:21:52.417+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.416+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:21:52.417+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.417+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:21:52.418+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.418+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:21:52.419+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.419+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:21:52.420+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.420+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:21:52.421+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.420+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:21:52.422+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.422+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:21:52.423+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.423+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:21:52.424+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.423+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:21:52.424+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.424+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:21:52.425+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.425+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:21:52.426+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.426+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:21:52.428+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.427+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:21:52.429+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.429+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:21:52.432+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.431+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:21:52.433+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:21:52.432+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:21:52.472+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.474 seconds
[2025-04-15T16:21:52.474+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.478 seconds
[2025-04-15T16:27:55.184+0200] {processor.py:186} INFO - Started process (PID=74440) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:27:55.186+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:27:55.188+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:55.187+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:27:55.333+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:27:55.849+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:55.849+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:27:55.961+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:55.960+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:27:55.989+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:55.988+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:27:55.999+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:55.999+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:27:56.011+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:56.011+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:27:56.016+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:56.016+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:27:56.023+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:56.022+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:27:56.028+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:56.027+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:27:56.031+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:56.030+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:27:56.045+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:56.044+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:27:56.053+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:27:56.052+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:27:56.144+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.965 seconds
[2025-04-15T16:28:01.436+0200] {processor.py:186} INFO - Started process (PID=74567) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:28:01.438+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:28:01.439+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.439+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:28:01.490+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:28:01.671+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.671+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:28:01.692+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.692+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:28:01.695+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.695+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:28:01.696+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.696+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:28:01.697+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.697+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:28:01.698+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.698+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:28:01.699+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.699+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:28:01.700+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.700+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:28:01.701+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.701+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:28:01.704+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.703+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:28:01.705+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:28:01.705+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:28:01.733+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.302 seconds
[2025-04-15T16:34:12.883+0200] {processor.py:186} INFO - Started process (PID=83283) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:34:12.885+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:34:12.887+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:12.886+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:34:12.959+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:34:13.204+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.204+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:34:13.233+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.233+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:34:13.238+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.238+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:34:13.240+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.239+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:34:13.241+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.241+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:34:13.242+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.242+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:34:13.243+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.243+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:34:13.244+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.244+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:34:13.246+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.245+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:34:13.248+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.248+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:34:13.250+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:13.249+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:34:13.291+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.413 seconds
[2025-04-15T16:34:21.555+0200] {processor.py:186} INFO - Started process (PID=83421) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:34:21.557+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:34:21.558+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.558+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:34:21.617+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:34:21.796+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.796+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:34:21.818+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.818+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:34:21.821+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.821+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:34:21.822+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.822+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:34:21.823+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.823+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:34:21.824+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.823+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:34:21.825+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.824+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:34:21.825+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.825+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:34:21.826+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.826+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:34:21.828+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.828+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:34:21.829+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:34:21.829+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:34:21.857+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.307 seconds
[2025-04-15T16:40:49.594+0200] {processor.py:186} INFO - Started process (PID=92465) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:40:49.595+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:40:49.597+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.596+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:40:49.649+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:40:49.829+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.829+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:40:49.851+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.850+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:40:49.854+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.854+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:40:49.855+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.855+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:40:49.856+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.856+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:40:49.857+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.857+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:40:49.858+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.858+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:40:49.859+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.859+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:40:49.860+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.860+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:40:49.862+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.862+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:40:49.863+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:49.863+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:40:49.893+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.304 seconds
[2025-04-15T16:40:51.842+0200] {processor.py:186} INFO - Started process (PID=92478) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:40:51.843+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:40:51.845+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:51.844+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:40:51.901+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:40:52.093+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.093+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:40:52.118+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.117+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:40:52.121+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.121+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:40:52.122+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.122+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:40:52.123+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.123+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:40:52.124+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.124+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:40:52.125+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.125+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:40:52.126+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.126+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:40:52.127+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.127+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:40:52.130+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.129+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:40:52.131+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:40:52.131+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:40:52.163+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.325 seconds
[2025-04-15T16:47:14.839+0200] {processor.py:186} INFO - Started process (PID=1878) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:47:14.841+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:47:14.842+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:14.842+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:47:14.936+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:47:15.296+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.295+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:47:15.334+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.333+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:47:15.339+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.339+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:47:15.340+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.340+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:47:15.342+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.342+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:47:15.344+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.344+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:47:15.345+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.345+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:47:15.347+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.347+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:47:15.349+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.348+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:47:15.355+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.355+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:47:15.357+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:15.356+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:47:15.408+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.577 seconds
[2025-04-15T16:47:20.104+0200] {processor.py:186} INFO - Started process (PID=2013) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:47:20.106+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:47:20.108+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.107+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:47:20.198+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:47:20.471+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.471+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:47:20.505+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.505+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:47:20.509+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.509+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:47:20.510+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.510+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:47:20.512+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.512+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:47:20.513+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.513+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:47:20.515+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.515+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:47:20.516+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.516+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:47:20.517+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.517+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:47:20.522+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.522+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:47:20.524+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:47:20.523+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:47:20.562+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.467 seconds
[2025-04-15T16:50:54.256+0200] {processor.py:186} INFO - Started process (PID=6675) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:50:54.258+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:50:54.260+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.259+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:50:54.337+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:50:54.540+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.539+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:50:54.563+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.563+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:50:54.566+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.566+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:50:54.567+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.567+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:50:54.568+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.568+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:50:54.569+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.569+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:50:54.570+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.570+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:50:54.571+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.571+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:50:54.572+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.572+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:50:54.575+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.574+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:50:54.576+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:50:54.575+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:50:54.605+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.354 seconds
[2025-04-15T16:54:00.513+0200] {processor.py:186} INFO - Started process (PID=10877) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:54:00.515+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:54:00.517+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.516+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:54:00.595+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:54:00.857+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.856+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:54:00.888+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.888+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:54:00.893+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.892+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:54:00.894+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.894+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:54:00.895+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.895+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:54:00.897+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.896+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:54:00.898+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:54:00.899+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.899+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:54:00.900+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.900+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:54:00.903+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.903+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:54:00.905+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:54:00.905+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:54:00.938+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.431 seconds
[2025-04-15T16:57:04.705+0200] {processor.py:186} INFO - Started process (PID=15179) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:57:04.706+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T16:57:04.707+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:04.707+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:57:04.797+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T16:57:05.068+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.068+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T16:57:05.101+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.101+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T16:57:05.105+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.105+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:57:05.107+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.106+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T16:57:05.108+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.107+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T16:57:05.109+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.108+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T16:57:05.110+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.110+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T16:57:05.112+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.112+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T16:57:05.113+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.113+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T16:57:05.116+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.116+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T16:57:05.118+0200] {logging_mixin.py:190} INFO - [2025-04-15T16:57:05.118+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T16:57:05.157+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.457 seconds
[2025-04-15T17:00:41.658+0200] {processor.py:186} INFO - Started process (PID=19784) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:00:41.684+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:00:41.687+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:41.686+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:00:41.779+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:00:42.101+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.100+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:00:42.144+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.143+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:00:42.156+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.155+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:00:42.172+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.171+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:00:42.191+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.191+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:00:42.227+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.227+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:00:42.229+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.228+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:00:42.247+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.247+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:00:42.272+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.271+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:00:42.276+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.275+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:00:42.295+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:00:42.295+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:00:42.409+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.756 seconds
[2025-04-15T17:03:54.329+0200] {processor.py:186} INFO - Started process (PID=24170) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:03:54.331+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:03:54.333+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.332+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:03:54.400+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:03:54.649+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.649+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:03:54.676+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.675+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:03:54.680+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.680+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:03:54.681+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.681+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:03:54.683+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.682+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:03:54.684+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.684+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:03:54.685+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.685+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:03:54.686+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.686+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:03:54.687+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.687+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:03:54.689+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.689+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:03:54.690+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:03:54.690+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:03:54.725+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.401 seconds
[2025-04-15T17:07:13.392+0200] {processor.py:186} INFO - Started process (PID=28572) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:07:13.395+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:07:13.398+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:13.397+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:07:13.657+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:07:14.206+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.205+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:07:14.243+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.243+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:07:14.248+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.248+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:07:14.250+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.249+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:07:14.251+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.251+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:07:14.253+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.253+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:07:14.255+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.254+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:07:14.256+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.256+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:07:14.258+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.258+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:07:14.261+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.261+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:07:14.262+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:07:14.262+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:07:14.311+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.931 seconds
[2025-04-15T17:10:51.235+0200] {processor.py:186} INFO - Started process (PID=33365) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:10:51.236+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:10:51.238+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.237+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:10:51.295+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:10:51.501+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.500+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:10:51.524+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.523+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:10:51.527+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.527+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:10:51.528+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.528+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:10:51.530+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.529+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:10:51.531+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.530+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:10:51.532+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.532+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:10:51.533+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.533+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:10:51.534+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.534+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:10:51.537+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.537+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:10:51.538+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:10:51.538+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:10:51.571+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.341 seconds
[2025-04-15T17:14:07.366+0200] {processor.py:186} INFO - Started process (PID=37915) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:14:07.368+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:14:07.370+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.369+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:14:07.465+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:14:07.716+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.716+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:14:07.745+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.745+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:14:07.749+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.749+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:14:07.750+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.750+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:14:07.751+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.751+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:14:07.752+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.752+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:14:07.753+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.753+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:14:07.754+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.754+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:14:07.755+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.755+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:14:07.758+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.758+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:14:07.759+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:14:07.759+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:14:07.789+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.428 seconds
[2025-04-15T17:17:19.887+0200] {processor.py:186} INFO - Started process (PID=42510) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:17:19.889+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:17:19.890+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:19.890+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:17:19.938+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:17:20.120+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.120+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:17:20.148+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.147+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:17:20.152+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.152+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:17:20.153+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.153+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:17:20.154+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.154+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:17:20.155+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.155+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:17:20.156+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.156+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:17:20.158+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.157+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:17:20.159+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.159+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:17:20.161+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.161+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:17:20.162+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:17:20.162+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:17:20.197+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.314 seconds
[2025-04-15T17:20:38.149+0200] {processor.py:186} INFO - Started process (PID=46993) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:20:38.150+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:20:38.152+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.151+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:20:38.247+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:20:38.476+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.475+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:20:38.507+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.507+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:20:38.511+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.511+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:20:38.512+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.512+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:20:38.513+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.513+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:20:38.514+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.514+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:20:38.515+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.515+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:20:38.516+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.516+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:20:38.518+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.518+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:20:38.520+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.520+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:20:38.521+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:20:38.521+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:20:38.558+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.414 seconds
[2025-04-15T17:22:41.338+0200] {processor.py:186} INFO - Started process (PID=49792) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:22:41.340+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:22:41.342+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.342+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:22:41.435+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:22:41.643+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.643+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:22:41.665+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.665+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:22:41.668+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.668+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:22:41.669+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.669+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:22:41.670+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.670+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:22:41.671+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.671+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:22:41.672+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.672+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:22:41.673+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.673+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:22:41.674+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.674+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:22:41.677+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.677+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:22:41.678+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:22:41.678+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:22:41.706+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.373 seconds
[2025-04-15T17:24:31.343+0200] {processor.py:186} INFO - Started process (PID=52192) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:24:31.345+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:24:31.347+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.346+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:24:31.426+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:24:31.699+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.699+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:24:31.730+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.730+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:24:31.735+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.735+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:24:31.737+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.737+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:24:31.739+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.738+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:24:31.740+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.740+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:24:31.742+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.741+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:24:31.743+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.743+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:24:31.745+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.744+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:24:31.748+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.748+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:24:31.750+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:24:31.749+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:24:31.792+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.454 seconds
[2025-04-15T17:28:02.950+0200] {processor.py:186} INFO - Started process (PID=57152) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:28:02.952+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:28:02.954+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:02.953+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:28:03.025+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:28:03.220+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.220+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:28:03.249+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.248+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:28:03.252+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.252+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:28:03.254+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.253+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:28:03.255+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.255+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:28:03.256+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.256+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:28:03.257+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.257+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:28:03.258+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.258+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:28:03.259+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.259+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:28:03.263+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.263+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:28:03.265+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:28:03.264+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:28:03.307+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.360 seconds
[2025-04-15T17:30:18.005+0200] {processor.py:186} INFO - Started process (PID=60283) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:30:18.007+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:30:18.008+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.008+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:30:18.068+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:30:18.242+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.241+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:30:18.262+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.262+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:30:18.265+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.265+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:30:18.266+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.266+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:30:18.267+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.267+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:30:18.268+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.268+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:30:18.269+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.269+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:30:18.270+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.269+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:30:18.270+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.270+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:30:18.273+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.272+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:30:18.274+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:30:18.273+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:30:18.300+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.300 seconds
[2025-04-15T17:31:41.821+0200] {processor.py:186} INFO - Started process (PID=62164) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:31:41.822+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:31:41.824+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:41.824+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:31:41.874+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:31:42.056+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.056+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:31:42.077+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.077+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:31:42.080+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.080+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:31:42.081+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.081+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:31:42.082+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.082+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:31:42.083+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.083+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:31:42.084+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.083+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:31:42.084+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.084+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:31:42.085+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.085+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:31:42.087+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.087+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:31:42.088+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:31:42.088+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:31:42.115+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.299 seconds
[2025-04-15T17:34:37.784+0200] {processor.py:186} INFO - Started process (PID=66772) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:34:37.785+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:34:37.786+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:37.786+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:34:37.843+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:34:38.033+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.033+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:34:38.056+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.056+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:34:38.059+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.059+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:34:38.061+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.060+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:34:38.062+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.061+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:34:38.063+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.062+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:34:38.064+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.064+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:34:38.065+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.065+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:34:38.066+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.066+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:34:38.068+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.068+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:34:38.069+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:38.069+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:34:38.101+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.322 seconds
[2025-04-15T17:34:59.600+0200] {processor.py:186} INFO - Started process (PID=67288) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:34:59.602+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:34:59.604+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.603+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:34:59.659+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:34:59.854+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.854+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:34:59.878+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.877+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:34:59.881+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.881+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:34:59.882+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.882+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:34:59.883+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.883+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:34:59.884+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.883+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:34:59.885+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.884+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:34:59.885+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.885+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:34:59.886+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.886+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:34:59.889+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.888+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:34:59.890+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:34:59.889+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:34:59.920+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.324 seconds
[2025-04-15T17:35:28.115+0200] {processor.py:186} INFO - Started process (PID=68028) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:35:28.117+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:35:28.119+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.119+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:35:28.223+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:35:28.427+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.427+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:35:28.450+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.449+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:35:28.453+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.453+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:35:28.454+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.454+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:35:28.455+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.455+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:35:28.456+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.456+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:35:28.457+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.457+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:35:28.458+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.458+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:35:28.459+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.459+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:35:28.462+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.461+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:35:28.463+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:35:28.462+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:35:28.492+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.382 seconds
[2025-04-15T17:42:35.494+0200] {processor.py:186} INFO - Started process (PID=77820) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:42:35.496+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:42:35.498+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.498+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:42:35.591+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:42:35.876+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.876+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:42:35.909+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.908+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:42:35.913+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.913+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:42:35.915+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.915+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:42:35.916+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.916+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:42:35.918+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.918+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:42:35.919+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.919+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:42:35.920+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.920+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:42:35.922+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.922+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:42:35.926+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.925+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:42:35.927+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:35.927+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:42:35.971+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.483 seconds
[2025-04-15T17:42:52.401+0200] {processor.py:186} INFO - Started process (PID=78207) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:42:52.402+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:42:52.404+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.404+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:42:52.467+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:42:52.667+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.667+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:42:52.691+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.691+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:42:52.695+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.694+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:42:52.696+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.695+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:42:52.697+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.696+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:42:52.698+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.697+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:42:52.699+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.699+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:42:52.701+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.700+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:42:52.702+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.702+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:42:52.705+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.704+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:42:52.706+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:42:52.706+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:42:52.745+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.349 seconds
[2025-04-15T17:43:04.076+0200] {processor.py:186} INFO - Started process (PID=78466) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:43:04.078+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:43:04.080+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.079+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:43:04.153+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:43:04.420+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.419+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:43:04.451+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.451+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:43:04.456+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.456+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:43:04.457+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.457+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:43:04.459+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.458+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:43:04.460+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.460+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:43:04.461+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.461+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:43:04.463+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.463+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:43:04.464+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.464+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:43:04.466+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.466+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:43:04.468+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:43:04.467+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:43:04.513+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.442 seconds
[2025-04-15T17:47:12.114+0200] {processor.py:186} INFO - Started process (PID=84721) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:47:12.116+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:47:12.117+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.117+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:47:12.203+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:47:12.422+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.422+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:47:12.448+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.447+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:47:12.453+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.453+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:47:12.455+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.454+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:47:12.456+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.456+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:47:12.458+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.458+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:47:12.459+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.459+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:47:12.460+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.460+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:47:12.462+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.461+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:47:12.464+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.464+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:47:12.466+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:47:12.465+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:47:12.500+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.391 seconds
[2025-04-15T17:49:41.718+0200] {processor.py:186} INFO - Started process (PID=88037) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:49:41.720+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:49:41.722+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.721+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:49:41.778+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:49:41.954+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.954+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:49:41.976+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.975+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:49:41.979+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.978+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:49:41.980+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.979+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:49:41.981+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.980+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:49:41.981+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.981+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:49:41.982+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.982+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:49:41.983+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.983+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:49:41.984+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.984+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:49:41.986+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.986+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:49:41.988+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:41.987+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:49:42.014+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.301 seconds
[2025-04-15T17:49:50.340+0200] {processor.py:186} INFO - Started process (PID=88287) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:49:50.341+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:49:50.343+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.343+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:49:50.404+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:49:50.638+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.637+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:49:50.663+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.662+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:49:50.667+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.667+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:49:50.669+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.669+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:49:50.670+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.670+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:49:50.672+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.671+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:49:50.673+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.672+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:49:50.674+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.674+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:49:50.675+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.675+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:49:50.677+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.677+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:49:50.678+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:49:50.678+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:49:50.716+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.381 seconds
[2025-04-15T17:53:52.480+0200] {processor.py:186} INFO - Started process (PID=93835) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:53:52.482+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:53:52.483+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.483+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:53:52.552+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:53:52.736+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.736+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:53:52.766+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.765+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:53:52.770+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.770+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:53:52.771+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.771+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:53:52.772+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.772+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:53:52.773+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.773+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:53:52.774+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.774+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:53:52.775+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.775+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:53:52.776+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.776+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:53:52.778+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.778+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:53:52.779+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:53:52.779+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:53:52.808+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.332 seconds
[2025-04-15T17:56:11.014+0200] {processor.py:186} INFO - Started process (PID=96829) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:56:11.016+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:56:11.017+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.017+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:56:11.091+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:56:11.304+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.303+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:56:11.329+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.329+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:56:11.333+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.333+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:56:11.334+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.334+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:56:11.335+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.335+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:56:11.336+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.336+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:56:11.337+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.337+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:56:11.338+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.338+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:56:11.340+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.339+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:56:11.342+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.342+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:56:11.343+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:11.343+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:56:11.374+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.366 seconds
[2025-04-15T17:56:12.699+0200] {processor.py:186} INFO - Started process (PID=96838) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:56:12.701+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T17:56:12.703+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:12.702+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:56:12.768+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T17:56:13.012+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.011+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T17:56:13.038+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.038+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T17:56:13.041+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.041+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:56:13.042+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.042+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T17:56:13.043+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.043+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T17:56:13.045+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.044+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T17:56:13.046+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.045+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T17:56:13.047+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.046+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T17:56:13.048+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.047+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T17:56:13.050+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.050+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T17:56:13.051+0200] {logging_mixin.py:190} INFO - [2025-04-15T17:56:13.051+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T17:56:13.081+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.387 seconds
[2025-04-15T18:01:33.386+0200] {processor.py:186} INFO - Started process (PID=5137) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:01:33.388+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:01:33.390+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.390+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:01:33.513+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:01:33.774+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.774+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:01:33.803+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.803+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:01:33.820+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.820+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:01:33.835+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.835+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:01:33.855+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.854+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:01:33.877+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.877+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:01:33.897+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.896+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:01:33.898+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:01:33.900+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.900+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:01:33.905+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.905+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:01:33.907+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:01:33.907+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:01:33.954+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.573 seconds
[2025-04-15T18:03:18.966+0200] {processor.py:186} INFO - Started process (PID=7697) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:03:18.972+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:03:18.974+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:18.973+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:03:19.109+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:03:19.370+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.369+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:03:19.407+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.407+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:03:19.412+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.412+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:03:19.413+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.413+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:03:19.415+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.415+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:03:19.417+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.416+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:03:19.418+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.418+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:03:19.420+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.420+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:03:19.422+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.421+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:03:19.425+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.425+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:03:19.427+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:19.427+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:03:19.471+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.512 seconds
[2025-04-15T18:03:24.766+0200] {processor.py:186} INFO - Started process (PID=7848) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:03:24.770+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:03:24.772+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:24.771+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:03:24.843+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:03:25.060+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.060+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:03:25.093+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.093+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:03:25.098+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.098+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:03:25.100+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.099+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:03:25.101+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.101+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:03:25.104+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.104+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:03:25.105+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.105+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:03:25.107+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.106+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:03:25.108+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.108+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:03:25.111+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.111+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:03:25.113+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:03:25.112+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:03:25.155+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.393 seconds
[2025-04-15T18:07:10.400+0200] {processor.py:186} INFO - Started process (PID=13390) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:07:10.402+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:07:10.404+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.403+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:07:10.458+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:07:10.650+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.650+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:07:10.672+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.672+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:07:10.676+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.675+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:07:10.677+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.677+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:07:10.678+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.678+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:07:10.679+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.679+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:07:10.680+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.680+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:07:10.681+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.681+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:07:10.682+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.681+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:07:10.684+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.684+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:07:10.685+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:07:10.684+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:07:10.715+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.320 seconds
[2025-04-15T18:11:11.337+0200] {processor.py:186} INFO - Started process (PID=18433) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:11:11.339+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:11:11.340+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.340+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:11:11.410+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:11:11.673+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.673+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:11:11.709+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.708+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:11:11.712+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.712+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:11:11.713+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.713+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:11:11.714+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.714+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:11:11.715+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.715+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:11:11.717+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.717+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:11:11.718+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.718+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:11:11.719+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.719+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:11:11.722+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.722+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:11:11.723+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:11:11.723+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:11:11.756+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.425 seconds
[2025-04-15T18:17:47.757+0200] {processor.py:186} INFO - Started process (PID=28644) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:17:47.759+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:17:47.761+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:47.760+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:17:47.853+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:17:48.085+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.085+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:17:48.107+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.107+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:17:48.110+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.110+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:17:48.112+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.111+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:17:48.113+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.113+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:17:48.114+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.114+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:17:48.116+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.115+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:17:48.117+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.117+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:17:48.118+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.118+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:17:48.121+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.121+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:17:48.122+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:17:48.122+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:17:48.152+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.399 seconds
[2025-04-15T18:21:52.487+0200] {processor.py:186} INFO - Started process (PID=33974) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:21:52.488+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:21:52.489+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.489+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:21:52.538+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:21:52.715+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.715+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:21:52.733+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.733+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:21:52.736+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.736+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:21:52.737+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.737+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:21:52.738+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.738+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:21:52.738+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.738+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:21:52.739+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.739+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:21:52.740+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.740+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:21:52.741+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.741+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:21:52.744+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.744+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:21:52.745+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:21:52.745+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:21:52.773+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.290 seconds
[2025-04-15T18:28:35.967+0200] {processor.py:186} INFO - Started process (PID=42840) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:28:35.969+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:28:35.970+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:35.970+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:28:36.038+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:28:36.215+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.214+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:28:36.232+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.232+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:28:36.235+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.235+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:28:36.236+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.236+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:28:36.237+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.236+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:28:36.237+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.237+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:28:36.238+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.238+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:28:36.239+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.239+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:28:36.240+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.239+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:28:36.241+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.241+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:28:36.242+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:28:36.242+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:28:36.266+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.302 seconds
[2025-04-15T18:33:30.639+0200] {processor.py:186} INFO - Started process (PID=49755) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:33:30.641+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:33:30.642+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.642+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:33:30.686+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:33:30.871+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.870+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:33:30.891+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.891+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:33:30.894+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.894+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:33:30.894+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.894+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:33:30.895+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.895+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:33:30.896+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.896+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:33:30.897+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.896+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:33:30.897+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.897+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:33:30.898+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.898+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:33:30.900+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.900+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:33:30.900+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:33:30.900+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:33:30.936+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.301 seconds
[2025-04-15T18:38:41.645+0200] {processor.py:186} INFO - Started process (PID=56628) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:38:41.647+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:38:41.648+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.648+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:38:41.689+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:38:41.847+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.847+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:38:41.866+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.866+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:38:41.868+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.868+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:38:41.869+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.869+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:38:41.870+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.870+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:38:41.871+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.870+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:38:41.871+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.871+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:38:41.872+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.872+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:38:41.873+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.872+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:38:41.874+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.874+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:38:41.875+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:38:41.875+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:38:41.898+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.256 seconds
[2025-04-15T18:43:45.786+0200] {processor.py:186} INFO - Started process (PID=63467) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:43:45.788+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:43:45.789+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:45.789+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:43:45.853+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:43:46.030+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.029+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:43:46.051+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.051+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:43:46.054+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.054+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:43:46.055+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.054+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:43:46.056+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.056+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:43:46.057+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.057+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:43:46.058+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.057+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:43:46.058+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.058+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:43:46.059+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.059+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:43:46.061+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.061+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:43:46.062+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:43:46.062+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:43:46.087+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.306 seconds
[2025-04-15T18:48:53.111+0200] {processor.py:186} INFO - Started process (PID=70549) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:48:53.113+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:48:53.114+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.114+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:48:53.210+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:48:53.390+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.390+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:48:53.413+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.413+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:48:53.416+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.415+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:48:53.416+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.416+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:48:53.417+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.417+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:48:53.418+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.418+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:48:53.418+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.418+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:48:53.419+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.419+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:48:53.420+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.420+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:48:53.422+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.421+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:48:53.422+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:48:53.422+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:48:53.457+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.350 seconds
[2025-04-15T18:54:22.943+0200] {processor.py:186} INFO - Started process (PID=77363) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:54:22.945+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:54:22.946+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:22.945+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:54:23.015+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:54:23.174+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.174+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:54:23.193+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.193+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:54:23.196+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.196+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:54:23.197+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.196+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:54:23.197+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.197+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:54:23.198+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.198+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:54:23.199+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.199+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:54:23.200+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.199+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:54:23.200+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.200+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:54:23.202+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.202+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:54:23.203+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:54:23.203+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:54:23.227+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.288 seconds
[2025-04-15T18:59:45.740+0200] {processor.py:186} INFO - Started process (PID=84721) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:59:45.742+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T18:59:45.743+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:45.742+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:59:45.816+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_1', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T18:59:45.981+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:45.981+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T18:59:46.004+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.003+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T18:59:46.007+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.006+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:59:46.008+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.008+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T18:59:46.009+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.008+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T18:59:46.009+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.009+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T18:59:46.010+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.010+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T18:59:46.011+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.011+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T18:59:46.012+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.012+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T18:59:46.014+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.014+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T18:59:46.015+0200] {logging_mixin.py:190} INFO - [2025-04-15T18:59:46.014+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T18:59:46.039+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.303 seconds
[2025-04-15T19:05:00.482+0200] {processor.py:186} INFO - Started process (PID=91878) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:05:00.484+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:05:00.485+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.485+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:05:00.566+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:05:00.819+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.818+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:05:00.849+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.849+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:05:00.853+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.852+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:05:00.854+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.854+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:05:00.856+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.855+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:05:00.857+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.857+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:05:00.859+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.858+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:05:00.860+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.860+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:05:00.862+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.861+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:05:00.865+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.865+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:05:00.867+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:05:00.866+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:05:00.906+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.428 seconds
[2025-04-15T19:10:44.358+0200] {processor.py:186} INFO - Started process (PID=99065) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:10:44.360+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:10:44.361+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.361+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:10:44.424+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:10:44.579+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.579+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:10:44.598+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.598+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:10:44.600+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.600+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:10:44.601+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.601+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:10:44.602+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.602+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:10:44.603+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.602+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:10:44.603+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.603+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:10:44.604+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.604+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:10:44.605+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.605+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:10:44.607+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.607+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:10:44.607+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:10:44.607+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:10:44.631+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.277 seconds
[2025-04-15T19:15:47.283+0200] {processor.py:186} INFO - Started process (PID=6348) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:15:47.296+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:15:47.299+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.298+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:15:47.407+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:15:47.615+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.615+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:15:47.638+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.638+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:15:47.642+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.642+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:15:47.660+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.659+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:15:47.680+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.679+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:15:47.700+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.700+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:15:47.719+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.719+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:15:47.739+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.739+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:15:47.759+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.759+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:15:47.779+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.778+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:15:47.797+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:15:47.796+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:15:47.876+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.597 seconds
[2025-04-15T19:20:54.915+0200] {processor.py:186} INFO - Started process (PID=13280) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:20:54.917+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:20:54.918+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:54.918+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:20:54.977+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:20:55.126+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.126+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:20:55.144+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.144+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:20:55.146+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.146+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:20:55.147+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.147+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:20:55.148+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.148+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:20:55.149+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.149+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:20:55.149+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.149+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:20:55.150+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.150+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:20:55.151+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.151+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:20:55.153+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.152+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:20:55.153+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:20:55.153+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:20:55.179+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.268 seconds
[2025-04-15T19:26:03.228+0200] {processor.py:186} INFO - Started process (PID=19786) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:26:03.231+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:26:03.232+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.231+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:26:03.275+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:26:03.439+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.439+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:26:03.456+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.456+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:26:03.459+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.459+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:26:03.460+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.460+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:26:03.460+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.460+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:26:03.461+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.461+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:26:03.462+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.462+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:26:03.463+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.462+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:26:03.463+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.463+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:26:03.465+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.465+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:26:03.466+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:26:03.466+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:26:03.493+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.269 seconds
[2025-04-15T19:31:26.110+0200] {processor.py:186} INFO - Started process (PID=26892) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:31:26.112+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:31:26.113+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.113+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:31:26.186+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:31:26.404+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.403+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:31:26.429+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.429+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:31:26.433+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.433+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:31:26.435+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.434+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:31:26.437+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.436+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:31:26.438+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.438+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:31:26.440+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.439+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:31:26.441+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.441+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:31:26.442+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.442+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:31:26.444+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.444+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:31:26.445+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:31:26.445+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:31:26.480+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.374 seconds
[2025-04-15T19:37:07.695+0200] {processor.py:186} INFO - Started process (PID=34721) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:37:07.697+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:37:07.698+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.698+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:37:07.742+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:37:07.905+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.905+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:37:07.925+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.925+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:37:07.929+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.928+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:37:07.930+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.930+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:37:07.931+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.931+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:37:07.932+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.932+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:37:07.933+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.933+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:37:07.934+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.934+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:37:07.935+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.935+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:37:07.937+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.937+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:37:07.957+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:37:07.957+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:37:07.995+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.304 seconds
[2025-04-15T19:42:41.739+0200] {processor.py:186} INFO - Started process (PID=42065) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:42:41.741+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:42:41.743+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:41.742+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:42:41.793+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:42:41.977+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:41.976+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:42:42.001+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.000+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:42:42.005+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.005+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:42:42.006+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.006+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:42:42.008+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.008+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:42:42.009+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.009+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:42:42.010+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.010+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:42:42.011+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.011+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:42:42.013+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.013+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:42:42.015+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.015+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:42:42.016+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:42:42.016+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:42:42.048+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.314 seconds
[2025-04-15T19:48:30.417+0200] {processor.py:186} INFO - Started process (PID=49336) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:48:30.424+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:48:30.428+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.427+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:48:30.529+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:48:30.798+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.797+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:48:30.833+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.832+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:48:30.852+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.852+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:48:30.870+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.870+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:48:30.889+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.889+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:48:30.909+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.908+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:48:30.911+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.910+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:48:30.912+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.912+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:48:30.914+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.914+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:48:30.936+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.936+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:48:30.937+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:48:30.937+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:48:31.002+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.589 seconds
[2025-04-15T19:54:13.411+0200] {processor.py:186} INFO - Started process (PID=56610) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:54:13.413+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:54:13.414+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.414+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:54:13.460+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:54:13.611+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.611+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:54:13.629+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.629+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:54:13.631+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.631+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:54:13.632+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.632+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:54:13.632+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.632+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:54:13.633+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.633+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:54:13.634+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.634+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:54:13.634+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.634+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:54:13.635+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.635+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:54:13.637+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.637+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:54:13.637+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:54:13.637+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:54:13.662+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.255 seconds
[2025-04-15T19:59:28.813+0200] {processor.py:186} INFO - Started process (PID=63840) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:59:28.815+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T19:59:28.816+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:28.816+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:59:28.862+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1', 'consume_1_or_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T19:59:29.021+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.020+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T19:59:29.040+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.040+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T19:59:29.044+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.043+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:59:29.045+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.044+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T19:59:29.045+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.045+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T19:59:29.046+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.046+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T19:59:29.047+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.047+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T19:59:29.047+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.047+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T19:59:29.048+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.048+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T19:59:29.050+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.050+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T19:59:29.051+0200] {logging_mixin.py:190} INFO - [2025-04-15T19:59:29.051+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T19:59:29.076+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.267 seconds
[2025-04-15T20:04:51.574+0200] {processor.py:186} INFO - Started process (PID=71037) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:04:51.576+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T20:04:51.577+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.577+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:04:51.691+0200] {processor.py:925} INFO - DAG(s) 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:04:51.891+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.891+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T20:04:51.911+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.911+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T20:04:51.914+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.914+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:04:51.915+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.915+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:04:51.916+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.916+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T20:04:51.917+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.917+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T20:04:51.918+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.918+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T20:04:51.919+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.919+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T20:04:51.920+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.919+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T20:04:51.922+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.921+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T20:04:51.922+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:04:51.922+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T20:04:51.950+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.381 seconds
[2025-04-15T20:10:24.199+0200] {processor.py:186} INFO - Started process (PID=78704) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:10:24.201+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T20:10:24.202+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.202+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:10:24.285+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:10:24.509+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.509+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T20:10:24.533+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.533+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T20:10:24.536+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.536+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:10:24.537+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.537+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:10:24.539+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.538+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T20:10:24.540+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.539+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T20:10:24.540+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.540+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T20:10:24.542+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.542+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T20:10:24.543+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.543+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T20:10:24.546+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.546+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T20:10:24.547+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:10:24.547+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T20:10:24.577+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.384 seconds
[2025-04-15T20:16:10.504+0200] {processor.py:186} INFO - Started process (PID=86343) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:16:10.505+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T20:16:10.507+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.506+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:16:10.548+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:16:10.709+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.708+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T20:16:10.729+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.729+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T20:16:10.732+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.732+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:16:10.733+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.733+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:16:10.733+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.733+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T20:16:10.734+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.734+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T20:16:10.735+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.735+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T20:16:10.736+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.736+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T20:16:10.738+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.738+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T20:16:10.740+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.740+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T20:16:10.741+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:16:10.740+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T20:16:10.764+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.264 seconds
[2025-04-15T20:21:05.362+0200] {processor.py:186} INFO - Started process (PID=93012) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:21:05.364+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T20:21:05.365+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.365+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:21:05.428+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_1', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'conditional_dataset_and_time_based_timetable', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:21:05.582+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.582+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T20:21:05.601+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.600+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T20:21:05.603+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.603+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:21:05.604+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.604+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:21:05.604+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.604+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T20:21:05.605+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.605+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T20:21:05.606+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.606+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T20:21:05.606+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.606+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T20:21:05.607+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.607+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T20:21:05.609+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.608+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T20:21:05.609+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:21:05.609+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T20:21:05.645+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.287 seconds
[2025-04-15T20:25:56.314+0200] {processor.py:186} INFO - Started process (PID=99827) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:25:56.316+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T20:25:56.318+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.317+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:25:56.362+0200] {processor.py:925} INFO - DAG(s) 'consume_1_or_2_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:25:56.518+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.518+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T20:25:56.537+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.536+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T20:25:56.539+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.539+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:25:56.540+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.540+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:25:56.541+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.541+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T20:25:56.542+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.542+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T20:25:56.543+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.543+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T20:25:56.544+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.544+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T20:25:56.545+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.545+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T20:25:56.547+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.547+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T20:25:56.548+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:25:56.547+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T20:25:56.572+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.262 seconds
[2025-04-15T20:31:17.333+0200] {processor.py:186} INFO - Started process (PID=7333) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:31:17.335+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T20:31:17.337+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.336+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:31:17.413+0200] {processor.py:925} INFO - DAG(s) 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_and_2', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'conditional_dataset_and_time_based_timetable' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:31:17.611+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.610+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T20:31:17.633+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.633+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T20:31:17.637+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.636+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:31:17.638+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.637+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:31:17.639+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.639+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T20:31:17.640+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.640+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T20:31:17.641+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.641+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T20:31:17.643+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.642+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T20:31:17.644+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.644+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T20:31:17.646+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.646+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T20:31:17.647+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:31:17.647+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T20:31:17.678+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.350 seconds
[2025-04-15T20:36:52.668+0200] {processor.py:186} INFO - Started process (PID=17019) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:36:52.670+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T20:36:52.671+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.671+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:36:52.747+0200] {processor.py:925} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_produces_2', 'dataset_produces_1', 'consume_1_and_2_with_dataset_expressions', 'conditional_dataset_and_time_based_timetable', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:36:52.942+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.941+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T20:36:52.969+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.969+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T20:36:52.972+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.972+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:36:52.973+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.973+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:36:52.974+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.974+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T20:36:52.975+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.975+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T20:36:52.976+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.976+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T20:36:52.977+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.976+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T20:36:52.977+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.977+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T20:36:52.980+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.979+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T20:36:52.980+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:36:52.980+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T20:36:53.007+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.344 seconds
[2025-04-15T20:42:45.590+0200] {processor.py:186} INFO - Started process (PID=25095) to work on /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:42:45.592+0200] {processor.py:914} INFO - Processing file /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-04-15T20:42:45.593+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.593+0200] {dagbag.py:588} INFO - Filling up the DagBag from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:42:45.648+0200] {processor.py:925} INFO - DAG(s) 'conditional_dataset_and_time_based_timetable', 'consume_1_or_both_2_and_3_with_dataset_expressions', 'dataset_consumes_unknown_never_scheduled', 'consume_1_or_2_with_dataset_expressions', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'consume_1_and_2_with_dataset_expressions', 'dataset_consumes_1' retrieved from /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-04-15T20:42:45.814+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.813+0200] {dag.py:3239} INFO - Sync 10 DAGs
[2025-04-15T20:42:45.833+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.832+0200] {dag.py:4180} INFO - Setting next_dagrun for conditional_dataset_and_time_based_timetable to 2025-04-09 01:00:00+00:00, run_after=2025-04-09 01:00:00+00:00
[2025-04-15T20:42:45.835+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.835+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_and_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:42:45.836+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.836+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_2_with_dataset_expressions to None, run_after=None
[2025-04-15T20:42:45.837+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.837+0200] {dag.py:4180} INFO - Setting next_dagrun for consume_1_or_both_2_and_3_with_dataset_expressions to None, run_after=None
[2025-04-15T20:42:45.838+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.837+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-04-15T20:42:45.838+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.838+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-04-15T20:42:45.839+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.839+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-04-15T20:42:45.840+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.840+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-04-15T20:42:45.842+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.841+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_1 to 2025-04-14 00:00:00+00:00, run_after=2025-04-15 00:00:00+00:00
[2025-04-15T20:42:45.842+0200] {logging_mixin.py:190} INFO - [2025-04-15T20:42:45.842+0200] {dag.py:4180} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-04-15T20:42:45.869+0200] {processor.py:208} INFO - Processing /Users/user/Documents/learningProg/dataengineering/de_dbt_snowflake_airflow/airflow-env/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.282 seconds
